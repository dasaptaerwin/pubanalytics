Authors,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Correspondence Address,Editors,Publisher,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Access Type,Source,EID
"Anaya J.","OncoLnc: Linking TCGA survival data to mRNAs, miRNAs, and lncRNAs",2016,"PeerJ Computer Science","2016","6", e67,"","",,44,10.7717/peerj-cs.67,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026652296&doi=10.7717%2fpeerj-cs.67&partnerID=40&md5=15c0638bc3484758dfb59da6a00195dd","Omnesres.com, Charlottesville, United States","Anaya, J., Omnesres.com, Charlottesville, United States","OncoLnc is a tool for interactively exploring survival correlations, and for downloading clinical data coupled to expression data for mRNAs, miRNAs, or long noncoding RNAs (lncRNAs). OncoLnc contains survival data for 8,647 patients from 21 cancer studies performed by The Cancer Genome Atlas (TCGA), along with RNA-SEQ expression for mRNAs and miRNAs from TCGA, and lncRNA expression from MiTranscriptome beta. Storing this data gives users the ability to separate patients by gene expression, and then create publication-quality Kaplan-Meier plots or download the data for further analyses. OncoLnc also stores precomputed survival analyses, allowing users to quickly explore survival correlations for up to 21 cancers in a single click. This resource allows researchers studying a specific gene to quickly investigate if it may have a role in cancer, and the supporting data allows researchers studying a specific cancer to identify the mRNAs, miRNAs, and lncRNAs most correlated with survival, and researchers looking for a novel lncRNA involved with cancer lists of potential candidates. © 2016 Anaya.","Cancer; Cox regression; Database; Kaplan-Meier; LncRNA; MiRNA; MRNA; RNA-SEQ; TCGA",,"Anaya, J.; Omnesres.comUnited States; email: omnesresnetwork@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85026652296
"Salvatier J., Wiecki T.V., Fonnesbeck C.","Probabilistic programming in Python using PyMC3",2016,"PeerJ Computer Science","2016","4", e55,"","",,36,10.7717/peerj-cs.55,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990201464&doi=10.7717%2fpeerj-cs.55&partnerID=40&md5=422eb6c9d9421af8f87a8e457f78ac05","AI Impacts, Berkeley, CA, United States; Quantopian Inc, Boston, MA, United States; Department of Biostatistics, Vanderbilt University, Nashville, TN, United States","Salvatier, J., AI Impacts, Berkeley, CA, United States; Wiecki, T.V., Quantopian Inc, Boston, MA, United States; Fonnesbeck, C., Department of Biostatistics, Vanderbilt University, Nashville, TN, United States","Probabilistic programming allows for automatic Bayesian inference on user-defined probabilistic models. Recent advances in Markov chain Monte Carlo (MCMC) sampling allow inference on increasingly complex models. This class of MCMC, known as Hamiltonian Monte Carlo, requires gradient information which is often not readily available. PyMC3 is a new open source probabilistic programming framework written in Python that uses Theano to compute gradients via automatic differentiation as well as compile probabilistic programs on-the-fly to C for increased speed. Contrary to other probabilistic programming languages, PyMC3 allows model specification directly in Python code. The lack of a domain specific language allows for great flexibility and direct interaction with the model. This paper is a tutorial-style introduction to this software package. © 2016 Salvatier et al.","Bayesian statistic; Markov chain Monte Carlo; Probabilistic Programming; Python; Statistical modeling",,"Wiecki, T.V.; Quantopian IncUnited States; email: thomas.wiecki@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84990201464
"Aletras N., Tsarapatsanis D., Preoţiuc-Pietro D., Lampos V.","Predicting judicial decisions of the European court of human rights: A natural language processing perspective",2016,"PeerJ Computer Science","2016","10", e93,"","",,10,10.7717/peerj-cs.93,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016265063&doi=10.7717%2fpeerj-cs.93&partnerID=40&md5=94f2c93d7f506c6b991dbc7ba2db1551","Amazon.com, Cambridge, United Kingdom; Department of Computer Science, University College London, University of London, London, United Kingdom; School of Law, University of Sheffield, Sheffield, United Kingdom; Positive Psychology Center, University of Pennsylvania, Philadelphia, United States; Computer and Information Science, University of Pennsylvania, Philadelphia, United States","Aletras, N., Amazon.com, Cambridge, United Kingdom, Department of Computer Science, University College London, University of London, London, United Kingdom; Tsarapatsanis, D., School of Law, University of Sheffield, Sheffield, United Kingdom; Preoţiuc-Pietro, D., Positive Psychology Center, University of Pennsylvania, Philadelphia, United States, Computer and Information Science, University of Pennsylvania, Philadelphia, United States; Lampos, V., Department of Computer Science, University College London, University of London, London, United Kingdom","Recent advances in Natural Language Processing and Machine Learning provide us with the tools to build predictive models that can be used to unveil patterns driving judicial decisions. This can be useful, for both lawyers and judges, as an assisting tool to rapidly identify cases and extract patterns which lead to certain decisions. This paper presents the first systematic study on predicting the outcome of cases tried by the European Court of Human Rights based solely on textual content. We formulate a binary classification task where the input of our classifiers is the textual content extracted from a case and the target output is the actual judgment as to whether there has been a violation of an article of the convention of human rights. Textual information is represented using contiguous word sequences, i.e., N-grams, and topics. Our models can predict the court's decisions with a strong accuracy (79% on average). Our empirical analysis indicates that the formal facts of a case are the most important predictive factor. This is consistent with the theory of legal realism suggesting that judicial decision-making is significantly affected by the stimulus of the facts. We also observe that the topical content of a case is another important feature in this classification task and explore this relationship further by conducting a qualitative analysis. © 2016 Aletras et al.","Artificial intelligence; Judicial decisions; Legal science; Machine learning; Natural language processing; Text mining",,"Aletras, N.; Amazon.comUnited Kingdom; email: nikos.aletras@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85016265063
"Xiao B., Huang C., Imel Z.E., Atkins D.C., Georgiou P., Narayanan S.S.","A technology prototype system for rating therapist empathy from audio recordings in addiction counseling",2016,"PeerJ Computer Science","2016","4", e59,"","",,8,10.7717/peerj-cs.59,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994306642&doi=10.7717%2fpeerj-cs.59&partnerID=40&md5=f8c89c6c268a06378cfb39ad9243c60e","Department of Electrical Engineering, University of Southern California, Los Angeles, CA, United States; Department of Educational Psychology, University of Utah, Salt Lake City, UT, United States; Department of Psychiatry and Behavioral Sciences, University of Washington, Seattle, WA, United States","Xiao, B., Department of Electrical Engineering, University of Southern California, Los Angeles, CA, United States; Huang, C., Department of Electrical Engineering, University of Southern California, Los Angeles, CA, United States; Imel, Z.E., Department of Educational Psychology, University of Utah, Salt Lake City, UT, United States; Atkins, D.C., Department of Psychiatry and Behavioral Sciences, University of Washington, Seattle, WA, United States; Georgiou, P., Department of Electrical Engineering, University of Southern California, Los Angeles, CA, United States; Narayanan, S.S., Department of Electrical Engineering, University of Southern California, Los Angeles, CA, United States","Scaling up psychotherapy services such as for addiction counseling is a critical societal need. One challenge is ensuring quality of therapy, due to the heavy cost of manual observational assessment. This work proposes a speech technology-based system to automate the assessment of therapist empathy-a key therapy quality index- from audio recordings of the psychotherapy interactions. We designed a speech processing system that includes voice activity detection and diarization modules, and an automatic speech recognizer plus a speaker role matching module to extract the therapist's language cues. We employed Maximum Entropy models, Maximum Likelihood language models, and a Lattice Rescoring method to characterize high vs. low empathic language. We estimated therapy-session level empathy codes using utterance level evidence obtained from these models. Our experiments showed that the fully automated system achieved a correlation of 0.643 between expert annotated empathy codes and machine-derived estimations, and an accuracy of 81% in classifying high vs. low empathy, in comparison to a 0.721 correlation and 86% accuracy in the oracle setting using manual transcripts. The results show that the system provides useful information that can contribute to automatic quality insurance and therapist training. © 2016 Xiao et al.","Addiction counseling; Automatic speech recognition; Empathy modeling; Language modeling; Prototype system; Speech processing",,"Xiao, B.; Department of Electrical Engineering, University of Southern CaliforniaUnited States; email: xiaobothu@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84994306642
"Nugent T., Plachouras V., Leidner J.L.","Computational drug repositioning based on side-effects mined fromsocial media",2016,"PeerJ Computer Science","2016","2", e46,"","",,8,10.7717/peerj-cs.46,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987658065&doi=10.7717%2fpeerj-cs.46&partnerID=40&md5=843b05430e22b69b7a36183d80e3c75a","Thomson Reuters, Corporate Research and Development, London, United Kingdom","Nugent, T., Thomson Reuters, Corporate Research and Development, London, United Kingdom; Plachouras, V., Thomson Reuters, Corporate Research and Development, London, United Kingdom; Leidner, J.L., Thomson Reuters, Corporate Research and Development, London, United Kingdom","Drug repositioning methods attempt to identify novel therapeutic indications for marketed drugs. Strategies include the use of side-effects to assign new disease indications, based on the premise that both therapeutic effects and side-effects are measurable physiological changes resulting from drug intervention. Drugs with similar side-effects might share a common mechanism of action linking side-effects with disease treatment, or may serve as a treatment by ""rescuing"" a disease phenotype on the basis of their side-effects; therefore it may be possible to infer new indications based on the similarity of side-effect profiles.While existing methods leverage side-effect data from clinical studies and drug labels, evidence suggests this information is often incomplete due to under-reporting. Here, we describe a novel computational method that uses side-effect data mined from social media to generate a sparse undirected graphical model using inverse covariance estimation with l1-norm regularization. Results show that known indications are well recovered while current trial indications can also be identified, suggesting that sparse graphical models generated using side-effect data mined from social media may be useful for computational drug repositioning. © 2016 Nugent et al.","Adverse drug reaction; Drug repositioning; Drug repurposing; Graphical lasso; Graphical model; Inverse covariance estimation; Side-effect; Social media",,"Nugent, T.; Thomson Reuters, Corporate Research and DevelopmentUnited Kingdom; email: timnugent@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84987658065
"Jonnalagedda N., Gauch S., Labille K., Alfarhood S.","Incorporating popularity in a personalized news recommender system",2016,"PeerJ Computer Science","2016","6", e63,"","",,8,10.7717/peerj-cs.63,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018404653&doi=10.7717%2fpeerj-cs.63&partnerID=40&md5=053b42774ae2b4a54b33b55748ea980b","Computer Science and Computer Engineering, University of, Fayetteville, AR, United States","Jonnalagedda, N., Computer Science and Computer Engineering, University of, Fayetteville, AR, United States; Gauch, S., Computer Science and Computer Engineering, University of, Fayetteville, AR, United States; Labille, K., Computer Science and Computer Engineering, University of, Fayetteville, AR, United States; Alfarhood, S., Computer Science and Computer Engineering, University of, Fayetteville, AR, United States","Online news reading has become a widely popular way to read news articles from news sources around the globe. With the enormous amount of news articles available, users are easily overwhelmed by information of little interest to them. News recommender systems help users manage this flood by recommending articles based on user interests rather than presenting articles in order of their occurrence. We present our research on developing personalized news recommendation system with the help of a popular micro-blogging service, ""Twitter."" News articles are ranked based on the popularity of the article identified from Twitter's public timeline. In addition, users construct profiles based on their interests and news articles are also ranked based on their match to the user profile. By integrating these two approaches, we present a hybrid news recommendation model that recommends interesting news articles to the user based on their popularity as well as their relevance to the user profile. © 2016 Jonnalagedda et al.","News recommender systems; Personalized news recommendation; Twitter; User profile",,"Gauch, S.; Computer Science and Computer Engineering, University ofUnited States; email: sgauch@uark.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85018404653
"Kuhrmann M., Diebold P., Münch J.","Software process improvement: A systematic mapping study on the state of the art",2016,"PeerJ Computer Science","2016","5", e62,"","",,8,10.7717/peerj-cs.62,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998806453&doi=10.7717%2fpeerj-cs.62&partnerID=40&md5=5395d441eb55903154d669666c9459ab","Maersk Mc-Kinney Moller Institute-Software Engineering, University of Southern Denmark, Odense, Denmark; Process Engineering, Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Herman Hollerith Center, Böblingen and Reutlingen University, Böblingen, Germany; Department of Computer Science, University of Helsinki, Helsinki, Finland","Kuhrmann, M., Maersk Mc-Kinney Moller Institute-Software Engineering, University of Southern Denmark, Odense, Denmark; Diebold, P., Process Engineering, Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Münch, J., Herman Hollerith Center, Böblingen and Reutlingen University, Böblingen, Germany, Department of Computer Science, University of Helsinki, Helsinki, Finland","Software process improvement (SPI) has been around for decades: frameworks are proposed, success factors are studied, and experiences have been reported. However, the sheer mass of concepts, approaches, and standards published over the years overwhelms practitioners as well as researchers. What is out there? Are there new trends and emerging approaches? What are open issues? Still, we struggle to answer these questions about the current state of SPI and related research. In this article, we present results from an updated systematic mapping study to shed light on the field of SPI, to develop a big picture of the state of the art, and to draw conclusions for future research directions. An analysis of 769 publications draws a big picture of SPI-related research of the past quarter-century. Our study shows a high number of solution proposals, experience reports, and secondary studies, but only few theories and models on SPI in general. In particular, standard SPI models likeCMMIand ISO/IEC 15,504 are analyzed, enhanced, and evaluated for applicability in practice, but these standards are also critically discussed, e.g., from the perspective of SPI in small-to-medium-sized companies, which leads to new specialized frameworks. New and specialized frameworks account for the majority of the contributions found (approx. 38%). Furthermore, we find a growing interest in success factors (approx. 16%) to aid companies in conducting SPI and in adapting agile principles and practices for SPI (approx. 10%). Beyond these specific topics, the study results also show an increasing interest into secondary studies with the purpose of aggregating and structuring SPI-related knowledge. Finally, the present study helps directing future research by identifying under-researched topics awaiting further investigation. © 2016 Kuhrmann et al.","Software process; Software process improvement; SPI; Systematic mapping study",,"Kuhrmann, M.; Maersk Mc-Kinney Moller Institute-Software Engineering, University of Southern DenmarkDenmark; email: kuhrmann@mmmi.sdu.dk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84998806453
"Destefanis G., Ortu M., Counsell S., Swift S., Marchesi M., Tonelli R.","Software development: Do good manners matter?",2016,"PeerJ Computer Science","2016","7", e73,"","",,7,10.7717/peerj-cs.73,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030094455&doi=10.7717%2fpeerj-cs.73&partnerID=40&md5=5bf5b5125738aa53723210b535599673","Department of Computer Science, Brunel University, London, United Kingdom; Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy","Destefanis, G., Department of Computer Science, Brunel University, London, United Kingdom; Ortu, M., Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy; Counsell, S., Department of Computer Science, Brunel University, London, United Kingdom; Swift, S., Department of Computer Science, Brunel University, London, United Kingdom; Marchesi, M., Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy; Tonelli, R., Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy","A successful software project is the result of a complex process involving, above all, people. Developers are the key factors for the success of a software development process, not merely as executors of tasks, but as protagonists and core of the whole development process. This paper investigates social aspects among developers working on software projects developed with the support of Agile tools. We studied 22 opensource software projects developed using the Agile board of the JIRA repository. All comments committed by developers involved in the projects were analyzed and we explored whether the politeness of comments affected the number of developers involved and the time required to fix any given issue. Our results showed that the level of politeness in the communication process among developers does have an effect on the time required to fix issues and, in the majority of the analysed projects, it had a positive correlation with attractiveness of the project to both active and potential developers. The more polite developers were, the less time it took to fix an issue. © 2016 Destefanis et al.","Issue fixing time; Mining software repositories; Politeness; Social and human aspects; Software development",,"Destefanis, G.; Department of Computer Science, Brunel UniversityUnited Kingdom; email: giuseppe.destefanis@brunel.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030094455
"Izquierdo J.L.C., Cabot J.","Collaboro: A collaborative (meta) modeling tool",2016,"PeerJ Computer Science","2016","10", e84,"","",,6,10.7717/peerj-cs.84,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030100587&doi=10.7717%2fpeerj-cs.84&partnerID=40&md5=9dd8fb7648a4191e9680665af3430acf","Universitat Oberta de Catalunya (UOC), Barcelona, Spain; Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain","Izquierdo, J.L.C., Universitat Oberta de Catalunya (UOC), Barcelona, Spain; Cabot, J., Universitat Oberta de Catalunya (UOC), Barcelona, Spain, Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain","Software development is becoming more and more collaborative, emphasizing the role of end-users in the development process to make sure the final product will satisfy customer needs. This is especially relevant when developing Domain-Specific Modeling Languages (DSMLs), which are modeling languages specifically designed to carry out the tasks of a particular domain.While end-users are actually the experts of the domain for which a DSML is developed, their participation in the DSML specification process is still rather limited nowadays. In this paper, we propose a more community-aware language development process by enabling the active participation of all community members (both developers and end-users) from the very beginning. Our proposal, called Collaboro, is based on a DSML itself enabling the representation of change proposals during the language design and the discussion (and trace back) of possible solutions, comments and decisions arisen during the collaboration. Collaboro also incorporates a metric-based recommender system to help community members to define high-quality notations for the DSMLs.We also show how Collaboro can be used at the model-level to facilitate the collaborative specification of software models. Tool support is available both as an Eclipse plug-in a web-based solution. © 2016 Cánovas Izquierdo and Cabot.","Collaborative development; Domain-specific languages; Model-driven development",,"Izquierdo, J.L.C.; Universitat Oberta de Catalunya (UOC)Spain; email: jcanovasi@uoc.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030100587
"Gacesa R., Barlow D.J., Long P.F.","Machine learning can differentiate venom toxins from other proteins having non-toxic physiological functions",2016,"PeerJ Computer Science","2016","10", e90,"","",,6,10.7717/peerj-cs.90,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024095945&doi=10.7717%2fpeerj-cs.90&partnerID=40&md5=23c7f2483fe3f60f761836f65562ad1f","Institute of Pharmaceutical Science, King's College London, London, United Kingdom; Department of Chemistry, King's College London, London, United Kingdom; Brazil Institute, King's College London, London, United Kingdom; Faculdade de Ciências Farmacêuticas, Universidade de São Paulo, São Paulo, Brazil","Gacesa, R., Institute of Pharmaceutical Science, King's College London, London, United Kingdom; Barlow, D.J., Institute of Pharmaceutical Science, King's College London, London, United Kingdom; Long, P.F., Institute of Pharmaceutical Science, King's College London, London, United Kingdom, Department of Chemistry, King's College London, London, United Kingdom, Brazil Institute, King's College London, London, United Kingdom, Faculdade de Ciências Farmacêuticas, Universidade de São Paulo, São Paulo, Brazil","Ascribing function to sequence in the absence of biological data is an ongoing challenge in bioinformatics. Differentiating the toxins of venomous animals from homologues having other physiological functions is particularly problematic as there are no universally accepted methods by which to attribute toxin function using sequence data alone. Bioinformatics tools that do exist are difficult to implement for researchers with little bioinformatics training. Here we announce a machine learning tool called ToxClassifier' that enables simple and consistent discrimination of toxins from non-toxin sequences with >99% accuracy and compare it to commonly used toxin annotation methods. ToxClassifer' also reports the best-hit annotation allowing placement of a toxin into the most appropriate toxin protein family, or relates it to anon-toxic protein having the closest homology, giving enhanced curation of existing biological databases and new venomics projects. ToxClassifier' is available for free, either to download (https://github.com/rgacesa/ToxClassifier) or to use on a web-based server (http://bioserv7.bioinfo.pbf.hr/ToxClassifier/). © 2016 Gacesa et al.","Animal venom; Automatic annotation; Biological function; Functional prediction; Protein sequences",,"Long, P.F.; Institute of Pharmaceutical Science, King's College LondonUnited Kingdom; email: paul.long@kcl.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85024095945
"Carvalho R.N., Laskey K.B., da Costa P.C.G.","Uncertainty modeling process for semantic technology",2016,"PeerJ Computer Science","2016","8", e77,"","",,5,10.7717/peerj-cs.77,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013252489&doi=10.7717%2fpeerj-cs.77&partnerID=40&md5=64c3c6c40a74fccf46e126fe2d9c7702","Department of Research and Strategic Information, Office of the Comptroller General of Brazil, Brasília, DF, Brazil; Department of Computer Science, Universidade de Brasília, Brasília, DF, Brazil; Department of Systems Engineering and Operations Research, George Mason University, Fairfax, VA, United States","Carvalho, R.N., Department of Research and Strategic Information, Office of the Comptroller General of Brazil, Brasília, DF, Brazil, Department of Computer Science, Universidade de Brasília, Brasília, DF, Brazil; Laskey, K.B., Department of Systems Engineering and Operations Research, George Mason University, Fairfax, VA, United States; da Costa, P.C.G., Department of Systems Engineering and Operations Research, George Mason University, Fairfax, VA, United States","The ubiquity of uncertainty across application domains generates a need for principled support for uncertainty management in semantically aware systems. A probabilistic ontology provides constructs for representing uncertainty in domain ontologies. While the literature has been growing on formalisms for representing uncertainty in ontologies, there remains little guidance in the knowledge engineering literature for how to design probabilistic ontologies. To address the gap, this paper presents the Uncertainty Modeling Process for Semantic Technology (UMP-ST), a new methodology for modeling probabilistic ontologies. To explain how the methodology works and to verify that it can be applied to different scenarios, this paper describes step-by-step the construction of a proof-of-concept probabilistic ontology. The resulting domain model can be used to support identification of fraud in public procurements in Brazil. While the case study illustrates the development of a probabilistic ontology in the PR-OWL probabilistic ontology language, the methodology is applicable to any ontology formalism that properly integrates uncertainty with domain semantics. © 2016 Carvalho et al.","Bayesian networks; MEBN; Methodology; Modeling; PR-OWL; Semantic technology; Semantic web; UMP-ST; Uncertainty; UP",,"Laskey, K.B.; Department of Systems Engineering and Operations Research, George Mason UniversityUnited States; email: klaskey@gmu.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85013252489
"Nikolić D.D.","DAE Tools: Equation-based object-oriented modelling, simulation and optimisation software",2016,"PeerJ Computer Science","2016","4", e54,"","",,5,10.7717/peerj-cs.54,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973538573&doi=10.7717%2fpeerj-cs.54&partnerID=40&md5=cd8f393d6aa9056dfd9bc611f5f068e4","DAE Tools Project, Belgrade, Serbia; MABE, Faculty of Science and Engineering, University of Limerick, Limerick, Ireland","Nikolić, D.D., DAE Tools Project, Belgrade, Serbia, MABE, Faculty of Science and Engineering, University of Limerick, Limerick, Ireland","In this work, DAE Tools modelling, simulation and optimisation software, its programming paradigms and main features are presented. The current approaches to mathematical modelling such as the use of modelling languages and general-purpose programming languages are analysed. The common set of capabilities required by the typical simulation software are discussed, and the shortcomings of the current approaches recognised. A new hybrid approach is introduced, and the modelling languages and the hybrid approach are compared in terms of the grammar, compiler, parser and interpreter requirements, maintainability and portability. The most important characteristics of the new approach are discussed, such as: (1) support for the runtime model generation; (2) support for the runtime simulation set-up; (3) support for complex runtime operating procedures; (4) interoperability with the third party software packages (i.e. NumPy/SciPy); (5) suitability for embedding and use as a web application or software as a service; and (6) code-generation, model exchange and co-simulation capabilities. The benefits of an equation-based approach to modelling, implemented in a fourth generation object-oriented general purpose programming language such as Python are discussed. The architecture and the software implementation details as well as the type of problems that can be solved using DAE Tools software are described. Finally, some applications of the software at different levels of abstraction are presented, and its embedding capabilities and suitability for use as a software as a service is demonstrated. © 2016 Nikolić.","Code generation; DAE; Domain specific languages; Equation-based; Model exchange; Modelling; Modelling languages; Optimisation; Simulation",,"Nikolić, D.D.; DAE Tools ProjectSerbia; email: dnikolic@daetools.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84973538573
"Golden P., Shaw R.","Nanopublication beyond the sciences: The PeriodO period gazetteer",2016,"PeerJ Computer Science","2016","2", e44,"","",,5,10.7717/peerj-cs.44,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966559065&doi=10.7717%2fpeerj-cs.44&partnerID=40&md5=bab4f9b03e21686e7c3d31c220dd238d","School of Information and Library Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States","Golden, P., School of Information and Library Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; Shaw, R., School of Information and Library Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States","The information expressed in humanities datasets is inextricably tied to a wider discursive environment that is irreducible to complete formal representation. Humanities scholars must wrestle with this fact when they attempt to publish or consume structured data. The practice of ""nanopublication,"" which originated in the e-science domain, offers a way to maintain the connection between formal representations of humanities data and its discursive basis. In this paper we describe nanopublication, its potential applicability to the humanities, and our experience curating humanities nanopublications in the PeriodO period gazetteer. © 2016 Golden and Shaw.","JSON-LD; Linked data; Nanopublication; Periodization; Scholarly communication; Time",,"Golden, P.; School of Information and Library Science, University of North Carolina at Chapel HillUnited States; email: ptgolden@email.unc.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84966559065
"Wu Y., Venkatramanan S., Chiu D.M.","Research collaboration and topic trends in Computer Science based on top active authors",2016,"PeerJ Computer Science","2016","1", e41,"","",,5,10.7717/peerj-cs.41,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028486938&doi=10.7717%2fpeerj-cs.41&partnerID=40&md5=1ed1cfb2292e0d2e64dcb03920e933a1","Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong; Virginia Bioinformatics Institute, Virginia Polytechnic Institute and State University (Virginia Tech), United States","Wu, Y., Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong; Venkatramanan, S., Virginia Bioinformatics Institute, Virginia Polytechnic Institute and State University (Virginia Tech), United States; Chiu, D.M., Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong","Academic publication metadata can be used to analyze the collaboration, productivity and hot topic trends of a research community. In this paper, we study a specific group of authors, namely the top active authors. They are defined as the top 1% authors with uninterrupted and continuous presence in scientific publications over a time window. We take the top active authors in the Computer Science (CS) community over different time windows in the past 50 years, and use them to analyze collaboration, productivity and topic trends.We show that (a) the top active authors are representative of the overall population; (b) the community is increasingly moving in the direction of Team Research, with increased level and degree of collaboration; and (c) the research topics are increasingly inter-related. By focusing on the top active authors, it helps visualize these trends better. Besides, the observations from top active authors also shed light on design of better evaluation framework and resource management for policy makers in academia. © 2016 Wu et al.","Research collaboration; Top active author; Topic trends",,"Chiu, D.M.; Department of Information Engineering, The Chinese University of Hong KongHong Kong; email: dmchiu@ie.cuhk.edu.hk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85028486938
"Far I.K., Ferron M., Ibarra F., Baez M., Tranquillini S., Casati F., Doppio N.","The interplay of physical and social wellbeing in older adults: Investigating the relationship between physical training and social interactions with virtual social environments",2015,"PeerJ Computer Science","2015","11", e30,"","",,5,10.7717/peerj-cs.30,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016997614&doi=10.7717%2fpeerj-cs.30&partnerID=40&md5=9696b6f8efbbc7a9c7e173c1127e5dd5","Department of Information Engineering and Computer Science, University of Trento, Trento, Trentino, Italy; Fondazione Bruno Kessler, Trento, Trentino, Italy; Smart Crowds, Trento Rise, Trento, Trentino, Italy","Far, I.K., Department of Information Engineering and Computer Science, University of Trento, Trento, Trentino, Italy; Ferron, M., Fondazione Bruno Kessler, Trento, Trentino, Italy; Ibarra, F., Department of Information Engineering and Computer Science, University of Trento, Trento, Trentino, Italy; Baez, M., Department of Information Engineering and Computer Science, University of Trento, Trento, Trentino, Italy; Tranquillini, S., Department of Information Engineering and Computer Science, University of Trento, Trento, Trentino, Italy; Casati, F., Department of Information Engineering and Computer Science, University of Trento, Trento, Trentino, Italy; Doppio, N., Smart Crowds, Trento Rise, Trento, Trentino, Italy","Background. Regular physical activity can substantially improve the physical wellbeing of older adults, preventing several chronic diseases and increasing cognitive performance and mood. However, research has shown that older adults are the most sedentary segment of society, spending much of their time seated or inactive. A variety of barriers make it difficult for older adults to maintain an active lifestyle, including logistical difficulties in going to a gym(for some adults, leaving home can be challenging), reduced functional abilities, and lack of motivation. In this paper, we report on the design and evaluation of Gymcentral. A training application running on tablet was designed to allow older adults to follow a personalized home-based exercise program while being remotely assisted by a coach. The objective of the study was to assess if a virtual gym that enables virtual presence and social interaction is more motivating for training than the same virtual gymwithout social interaction. Methods. A total of 37 adults aged between 65 and 87 years old (28 females and 9 males, mean age = 71, sd = 5.8) followed a personalized home-based strength and balance training plan for eight weeks. The participants performed the exercises autonomously at home using the Gymcentral application. Participants were assigned to two training groups: the Social group used an application with persuasive and social functionalities, while the Control group used a basic version of the service with no persuasive and social features.We further explored the effects of social facilitation, and in particular of virtual social presence, in user participation to training sessions. Outcome measures were adherence, persistence and co-presence rate. Results. Participants in the Social group attended significantly more exercise sessions than the Control group, providing evidence of a better engagement in the training program. Besides the focus on social persuasion measures, the study also confirms that a virtual gymservice is effective for supporting individually tailored home-based physical training for older adults. The study also confirms that social facilitation tools motivate users to train together in a virtual fitness environment. Discussion. The study confirms that Gymcentral increases the participation of older adults in physical training compare to a similar version of the application without social and persuasive features. In addition, a significant increase in the co-presence of the Social group indicates that social presence motivates the participants to join training sessions at the same time with the other participants. These results are encouraging, as they motivate further research into using home-based training programs as an opportunity to stay physically and socially active, especially for those who for various reasons are bound to stay at home. © 2015 Khaghani Far et al.","Home-based physical intervention; Older adults; Persuasion technology; Physical wellbeing; Social interactions","E-learning; Motivation; Personnel training; Recreational facilities; Cognitive performance; Design and evaluations; Home-based; Home-based exercise programs; Older adults; Social interactions; Training applications; Wellbeing; Application programs","Far, I.K.; Department of Information Engineering and Computer Science, University of TrentoItaly; email: iman.khaghanifar@unitn.it",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85016997614
"Topirceanu A., Udrescu M., Vladutiu M., Marculescu R.","Tolerance-based interaction: A new model targeting opinion formation and diffusion in social networks",2016,"PeerJ Computer Science","2016","1", e42,"","",,4,10.7717/peerj-cs.42,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025711630&doi=10.7717%2fpeerj-cs.42&partnerID=40&md5=60b294265f237304df9a581e4f4c5cf7","Department of Computer and Software Engineering, Politehnica University Timisoara, Timisoara, Romania; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, United States","Topirceanu, A., Department of Computer and Software Engineering, Politehnica University Timisoara, Timisoara, Romania; Udrescu, M., Department of Computer and Software Engineering, Politehnica University Timisoara, Timisoara, Romania; Vladutiu, M., Department of Computer and Software Engineering, Politehnica University Timisoara, Timisoara, Romania; Marculescu, R., Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, United States","One of the main motivations behind social network analysis is the quest for understanding opinion formation and diffusion. Previous models have limitations, as they typically assume opinion interaction mechanisms based on thresholds which are either fixed or evolve according to a random process that is external to the social agent. Indeed, our empirical analysis on large real-world datasets such as Twitter, Meme Tracker, and Yelp, uncovers previously unaccounted for dynamic phenomena at population-level, namely the existence of distinct opinion formation phases and social balancing. We also reveal that a phase transition from an erratic behavior to social balancing can be triggered by network topology and by the ratio of opinion sources. Consequently, in order to build a model that properly accounts for these phenomena, we propose a new (individual-level) opinion interaction model based on tolerance. As opposed to the existing opinion interaction models, the new tolerance model assumes that individual's inner willingness to accept new opinions evolves over time according to basic human traits. Finally, by employing discrete event simulation on diverse social network topologies, we validate our opinion interaction model and show that, although the network size and opinion source ratio are important, the phase transition to social balancing is mainly fostered by the democratic structure of the small-world topology. © 2016 Topirceanu et al.","Discrete event simulation; Opinion diffusion; Phase transition; Social networks; Tolerance",,"Udrescu, M.; Department of Computer and Software Engineering, Politehnica University TimisoaraRomania; email: mudrescu@cs.upt.ro",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85025711630
"Mandli K.T., Ahmadia A.J., Berger M., Calhoun D., George D.L., Hadjimichael Y., Ketcheson D.I., Lemoine G.I., LeVeque R.J.","Clawpack: Building an open source ecosystem for solving hyperbolic PDEs",2016,"PeerJ Computer Science","2016","8", e68,"","",,4,10.7717/peerj-cs.68,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028511093&doi=10.7717%2fpeerj-cs.68&partnerID=40&md5=b1e0dcb92fce23e561fd81cd9aff6417","Department of Applied Physics and Applied Mathematics, Columbia University, New York, NY, United States; Continuum Analytics, Austin, TX, United States; Courant Institute, New York University, New York, NY, United States; Department of Mathematics, Boise State University, Boise, ID, United States; Cascade Volcano Observatory, United States Geological Survey, Vancouver, WA, United States; Applied Mathematics and Computational Science, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; CD-adapco, Bellevue, WA, United States; Department of Applied Mathematics, University of Washington, Seattle, WA, United States","Mandli, K.T., Department of Applied Physics and Applied Mathematics, Columbia University, New York, NY, United States; Ahmadia, A.J., Continuum Analytics, Austin, TX, United States; Berger, M., Courant Institute, New York University, New York, NY, United States; Calhoun, D., Department of Mathematics, Boise State University, Boise, ID, United States; George, D.L., Cascade Volcano Observatory, United States Geological Survey, Vancouver, WA, United States; Hadjimichael, Y., Applied Mathematics and Computational Science, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Ketcheson, D.I., Applied Mathematics and Computational Science, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Lemoine, G.I., CD-adapco, Bellevue, WA, United States; LeVeque, R.J., Department of Applied Mathematics, University of Washington, Seattle, WA, United States","Clawpack is a software package designed to solve nonlinear hyperbolic partial dif- ferential equations using high-resolution finite volume methods based on Riemann solvers and limiters. The package includes a number of variants aimed at different applications and user communities. Clawpack has been actively developed as an open source project for over 20 years. The latest major release, Clawpack 5, introduces a number of new features and changes to the code base and a new development model based on GitHub and Git submodules. This article provides a summary of the most significant changes, the rationale behind some of these changes, and a description of our current development model. © 2016 Mandli et al.","Balance laws; Conservation laws; Finite volume methods; Open source software; Parallel computing; Partial differential equations",,"Mandli, K.T.; Department of Applied Physics and Applied Mathematics, Columbia UniversityUnited States; email: kyle.mandli@columbia.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85028511093
"Wagner S., Abdulkhaleq A., Bogicevic I., Ostberg J.-P., Ramadani J.","How are functionally similar code clones syntactically different? An empirical study and a benchmark",2016,"PeerJ Computer Science","2016","3", e49,"","",,4,10.7717/peerj-cs.49,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988947151&doi=10.7717%2fpeerj-cs.49&partnerID=40&md5=41fd1d71507a048b942d40cb07fb7bcc","Institute of Software Technology, University of Stuttgart, Stuttgart, Germany","Wagner, S., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany; Abdulkhaleq, A., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany; Bogicevic, I., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany; Ostberg, J.-P., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany; Ramadani, J., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany","Background. Today, redundancy in source code, so-called ""clones"" caused by copy &paste can be found reliably using clone detection tools. Redundancy can arise also independently, however, not caused by copy&paste. At present, it is not clear how only functionally similar clones (FSC) differ from clones created by copy&paste. Our aim is to understand and categorise the syntactical differences in FSCs that distinguish them from copy&paste clones in a way that helps clone detection research. Methods. We conducted an experiment using known functionally similar programs in Java and C from coding contests. We analysed syntactic similarity with traditional detection tools and explored whether concolic clone detection can go beyond syntax. We ran all tools on 2,800 programs and manually categorised the differences in a random sample of 70 program pairs. Results. We found no FSCs where complete files were syntactically similar. We could detect a syntactic similarity in a part of the files in <16% of the program pairs. Concolic detection found 1 of the FSCs. The differences between program pairs were in the categories algorithm, data structure, OO design, I/O and libraries. We selected 58 pairs for an openly accessible benchmark representing these categories. Discussion. The majority of differences between functionally similar clones are beyond the capabilities of current clone detection approaches. Yet, our benchmark can help to drive further clone detection research. © 2016 Wagner et al.","Benchmark; Code clone; Empirical study; Functionally similar clone",,"Wagner, S.; Institute of Software Technology, University of StuttgartGermany; email: stefan.wagner@informatik.uni-stuttgart.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84988947151
"Mitchell R., Frank E.","Accelerating the XGBoost algorithm using GPU computing",2017,"PeerJ Computer Science","2017","7", e127,"","",,3,10.7717/peerj-cs.127,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030171970&doi=10.7717%2fpeerj-cs.127&partnerID=40&md5=3af51d2cdb2eb0e408e2fa7202b4bf08","Department of Computer Science, University of Waikato, Hamilton, New Zealand","Mitchell, R., Department of Computer Science, University of Waikato, Hamilton, New Zealand; Frank, E., Department of Computer Science, University of Waikato, Hamilton, New Zealand","We present a CUDA-based implementation of a decision tree construction algorithm within the gradient boosting library XGBoost. The tree construction algorithm is executed entirely on the graphics processing unit (GPU) and shows high performance with a variety of datasets and settings, including sparse input matrices. Individual boosting iterations are parallelised, combining two approaches. An interleaved approach is used for shallow trees, switching to a more conventional radix sort-based approach for larger depths. We show speedups of between 3 × and 6 × using a Titan X compared to a 4 core i7 CPU, and 1.2 × using a Titan X compared to 2 × Xeon CPUs (24 cores).We show that it is possible to process the Higgs dataset (10 million instances, 28 features) entirely within GPU memory. The algorithm is made available as a plug-in within the XGBoost library and fully supports all XGBoost features including classification, regression and ranking tasks. © 2017 Mitchell and Frank.","GPU computing; Gradient boosting; Supervised machine learning",,"Mitchell, R.; Department of Computer Science, University of WaikatoNew Zealand; email: ramitchellnz@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030171970
"Yan X., Teng S.-H., Lerman K., Ghosh R.","Capturing the interplay of dynamics and networks through parameterizations of Laplacian operators",2016,"PeerJ Computer Science","2016","5", e57,"","",,3,10.7717/peerj-cs.57,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020456521&doi=10.7717%2fpeerj-cs.57&partnerID=40&md5=4095de3ebec10af163d7d9f4d552fd3c","School of Informatics and Computing, Indiana University, Bloomington, IN, United States; Computer Science Department, University of Southern California, Marina Del Rey, CA, United States; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, United States; Robert Bosch, LLC, Palo Alto, CA, United States","Yan, X., School of Informatics and Computing, Indiana University, Bloomington, IN, United States; Teng, S.-H., Computer Science Department, University of Southern California, Marina Del Rey, CA, United States; Lerman, K., Information Sciences Institute, University of Southern California, Marina Del Rey, CA, United States; Ghosh, R., Robert Bosch, LLC, Palo Alto, CA, United States","We study the interplay between a dynamical process and the structure of the network on which it unfolds using the parameterized Laplacian framework. This framework allows for defining and characterizing an ensemble of dynamical processes on a network beyond what the traditional Laplacian is capable of modeling. This, in turn, allows for studying the impact of the interaction between dynamics and network topology on the quality-measure of network clusters and centrality, in order to effectively identify important vertices and communities in the network. Specifically, for each dynamical process in this framework, we define a centrality measure that captures a vertex's participation in the dynamical process on a given network and also define a function that measures the quality of every subset of vertices as a potential cluster (or community) with respect to this process. We show that the subset-quality function generalizes the traditional conductance measure for graph partitioning. We partially justify our choice of the quality function by showing that the classic Cheeger's inequality, which relates the conductance of the best cluster in a network with a spectral quantity of its Laplacian matrix, can be extended to the parameterized Laplacian. The parameterized Laplacian framework brings under the same umbrella a surprising variety of dynamical processes and allows us to systematically compare the different perspectives they create on network structure. © 2016 Yan et al.","Centrality; Community structure; Dynamical process; Network; Spectral graph theory",,"Lerman, K.; Information Sciences Institute, University of Southern CaliforniaUnited States; email: lerman@isi.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85020456521
"van Erp J.B.F., Hogervorst M.A., van der Werf Y.D.","Toward physiological indices of emotional state driving future ebook interactivity",2016,"PeerJ Computer Science","2016","5", e60,"","",,3,10.7717/peerj-cs.60,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018688829&doi=10.7717%2fpeerj-cs.60&partnerID=40&md5=13242476b081635c5c25ffb7dbc837c6","Perceptual and Cognitive Systems, TNO, Soesterberg, Netherlands; Human Media Interaction, University of Twente, Enschede, Netherlands; Anatomy and Neurosciences, VU University Medical Center, Amsterdam, Netherlands","van Erp, J.B.F., Perceptual and Cognitive Systems, TNO, Soesterberg, Netherlands, Human Media Interaction, University of Twente, Enschede, Netherlands; Hogervorst, M.A., Perceptual and Cognitive Systems, TNO, Soesterberg, Netherlands; van der Werf, Y.D., Anatomy and Neurosciences, VU University Medical Center, Amsterdam, Netherlands","Ebooks of the future may respond to the emoional experience of the reader. (Neuro-) physiological measures could capture a reader's emotional state and use this to enhance the reading experience by adding matching sounds or to change the storyline therewith creating a hybrid art form in between literature and gaming. We describe the theoretical foundation of the emotional and creative brain and review the neurophysiological indices that can be used to drive future ebook interactivity in a real life situation. As a case study, we report the neurophysiological measurements of a bestselling author during nine days of writing which can potentially be used later to compare them to those of the readers. In designated calibration blocks, the artist wrote emotional paragraphs for emotional (IAPS) pictures. Analyses showed that we can reliably distinguish writing blocks from resting but we found no reliable differences related to the emotional content of the writing. The study shows that measurements of EEG, heart rate (variability), skin conductance, facial expression and subjective ratings can be done over several hours a day and for several days in a row. In follow-up phases, we will measure 300 readers with a similar setup. © 2016 van Erp et al.","Brain-computer interfaces; Creativity; Ebook; EEG; Emotion; Human-computer interaction; Interactivity; Multimedia; Neurophysiology; Reading",,"van Erp, J.B.F.; Perceptual and Cognitive Systems, TNONetherlands; email: jan.vanerp@tno.nl",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85018688829
"Fremantle P., Scott P.","A survey of secure middleware for the internet of things",2017,"PeerJ Computer Science","2017","5", e114,"","",,2,10.7717/peerj-cs.114,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030106840&doi=10.7717%2fpeerj-cs.114&partnerID=40&md5=4119ab3bcfef57e3dd9ba76c38b9ba4d","School of Computing, University of Portsmouth, Portsmouth, United Kingdom","Fremantle, P., School of Computing, University of Portsmouth, Portsmouth, United Kingdom; Scott, P., School of Computing, University of Portsmouth, Portsmouth, United Kingdom","The rapid growth of small Internet connected devices, known as the Internet of Things (IoT), is creating a new set of challenges to create secure, private infrastructures. This paper reviews the current literature on the challenges and approaches to security and privacy in the Internet of Things, with a strong focus on how these aspects are handled in IoT middleware. We focus on IoT middleware because many systems are built from existing middleware and these inherit the underlying security properties of the middleware framework. The paper is composed of three main sections. Firstly, we propose a matrix of security and privacy threats for IoT. This matrix is used as the basis of a widespread literature review aimed at identifying requirements on IoT platforms and middleware. Secondly, we present a structured literature review of the available middleware and how security is handled in these middleware approaches. We utilise the requirements from the first phase to evaluate. Finally, we draw a set of conclusions and identify further work in this area. © 2017 Fremantle and Scott.","Internet of things; IoT; Middleware; Privacy; Security; Survey",,"Fremantle, P.; School of Computing, University of PortsmouthUnited Kingdom; email: paul.fremantle@port.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030106840
"Clark A.M., Litterman N.K., Kranz J.E., Gund P., Gregory K., Bunin B.A.","BioAssay templates for the semantic web",2016,"PeerJ Computer Science","2016","5", e61,"","",,2,10.7717/peerj-cs.61,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979638036&doi=10.7717%2fpeerj-cs.61&partnerID=40&md5=2b01115b1ebabe9157438e89153dfe2c","Collaborative Drug Discovery, Inc., Burlingame, CA, United States","Clark, A.M., Collaborative Drug Discovery, Inc., Burlingame, CA, United States; Litterman, N.K., Collaborative Drug Discovery, Inc., Burlingame, CA, United States; Kranz, J.E., Collaborative Drug Discovery, Inc., Burlingame, CA, United States; Gund, P., Collaborative Drug Discovery, Inc., Burlingame, CA, United States; Gregory, K., Collaborative Drug Discovery, Inc., Burlingame, CA, United States; Bunin, B.A., Collaborative Drug Discovery, Inc., Burlingame, CA, United States","Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable. Protocols are communicated using concise scientific English, which precludes most kinds of analysis by software algorithms. Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated in a multitude of ways, analogous to other segments of drug discovery informatics. The BioAssay Ontology (BAO) has been previously designed for this express purpose, and provides a layered hierarchy of meaningful terms which can be linked to. Currently the biggest challenge is the issue of content creation: scientists cannot be expected to use the BAO effectively without having access to software tools that make it straightforward to use the vocabulary in a canonical way. We have sought to remove this barrier by: (1) defining a BioAssay Template (BAT) data model; (2) creating a software tool for experts to create or modify templates to suit their needs; and (3) designing a common assay template (CAT) to leverage the most value from the BAO terms. The CAT was carefully assembled by biologists in order to find a balance between the maximum amount of information captured vs. low degrees of freedom in order to keep the user experience as simple as possible. The data format that we use for describing templates and corresponding annotations is the native format of the semantic web (RDF triples), and we demonstrate some of the ways that generated content can be meaningfully queried using the SPARQL language. We have made all of these materials available as open source (http://github.com/cdd/ bioassay-template), in order to encourage community input and use within diverse projects, including but not limited to our own commercial electronic lab notebook products. © 2016 Clark et al.","Assay protocols; BioAssay Ontology; Common assay template; Machine learning; Semantic web",,"Clark, A.M.; Collaborative Drug Discovery, Inc.United States; email: aclark.xyz@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84979638036
"Toet A.","Alternating guided image filtering",2016,"PeerJ Computer Science","2016","6", e72,"","",,2,10.7717/peerj-cs.72,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021455880&doi=10.7717%2fpeerj-cs.72&partnerID=40&md5=e5c2e0c3dcf1d35da787466f6e80ac63","TNO, Soesterberg, Netherlands","Toet, A., TNO, Soesterberg, Netherlands","Edge preserving filters aim to simplify the representation of images (e.g., by reducing noise or eliminating irrelevant detail) while preserving their most significant edges. These filters are typically nonlinear and locally smooth the image structure while minimizing both blurring and over-sharpening of visually important edges. Here we present the Alternating Guided Filter (AGF) that achieves edge preserving smoothing by combining two recently introduced filters: the Rolling Guided Filter (RGF) and the Smooth and iteratively Restore Filter (SiR). We show that the integration of RGF and SiR in an alternating iterative framework results in a new smoothing operator that preserves significant image edges while effectively eliminating small scale details. The AGF combines the large scale edge and local intensity preserving properties of the RGF with the edge restoring properties of the SiR while eliminating the drawbacks of both previous methods (i.e., edge curvature smoothing by RGF and local intensity reduction and restoration of small scale details near large scale edges by SiR). The AGF is simple to implement and efficient, and produces high-quality results. We demonstrate the effectiveness of AGF on a variety of images, and provide a public code to facilitate future studies.","Alternating Guided Filter; Bilateral filter; Edge enhancement; Edge preserving filter; Guided Filter; Image enhancement; Image filtering; Image smoothing; Noise reduction; Rolling Guided Filter",,"Toet, A.; TNONetherlands; email: lextoet@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85021455880
"Davis C.A., Ciampaglia G.L., Aiello L.M., Chung K., Conover M.D., Ferrara E., Flammini A., Fox G.C., Gao X., Gonçalves B., Grabowicz P.A., Hong K., Hui P.-M., McCaulay S., McKelvey K., Meiss M.R., Patil S., Kankanamalage C.P., Pentchev V., Qiu J., Ratkiewicz J., Rudnick A., Serrette B., Shiralkar P., Varol O., Weng L., Wu T.-L., Younge A.J., Menczer F.","OSoMe: The IUNI observatory on social media",2016,"PeerJ Computer Science","2016","10", e87,"","",,2,10.7717/peerj-cs.87,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030102405&doi=10.7717%2fpeerj-cs.87&partnerID=40&md5=e08aaa0372ca8aabfd00c370fac1119c","Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States; School of Informatics and Computing, Indiana University, Bloomington, United States; Network Science Institute, Indiana University, Bloomington, United States; Bell Labs, London, United Kingdom; LinkedIn Inc, Mountain View, CA, United States; Information Sciences Institute, University of Southern California, Marina Del Rey, CA, United States; Facebook Inc, Boston, MA, United States; Center for Data Science, New York University, New York, NY, United States; Max Planck Institute for Software Systems Saarbrücken, Germany; US Open Data, Oakland, CA, United States; Google Inc, Mountain View, CA, United States; Yahoo Inc, Sunnyvale, CA, United States; Affirm Inc, San Francisco, CA, United States; Amazon Inc, Seattle, WA, United States","Davis, C.A., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, School of Informatics and Computing, Indiana University, Bloomington, United States; Ciampaglia, G.L., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, Network Science Institute, Indiana University, Bloomington, United States; Aiello, L.M., Bell Labs, London, United Kingdom; Chung, K., School of Informatics and Computing, Indiana University, Bloomington, United States; Conover, M.D., LinkedIn Inc, Mountain View, CA, United States; Ferrara, E., Information Sciences Institute, University of Southern California, Marina Del Rey, CA, United States; Flammini, A., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, School of Informatics and Computing, Indiana University, Bloomington, United States, Network Science Institute, Indiana University, Bloomington, United States; Fox, G.C., School of Informatics and Computing, Indiana University, Bloomington, United States; Gao, X., Facebook Inc, Boston, MA, United States; Gonçalves, B., Center for Data Science, New York University, New York, NY, United States; Grabowicz, P.A., Max Planck Institute for Software Systems Saarbrücken, Germany; Hong, K., School of Informatics and Computing, Indiana University, Bloomington, United States; Hui, P.-M., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, School of Informatics and Computing, Indiana University, Bloomington, United States; McCaulay, S., Network Science Institute, Indiana University, Bloomington, United States; McKelvey, K., US Open Data, Oakland, CA, United States; Meiss, M.R., Google Inc, Mountain View, CA, United States; Patil, S., Yahoo Inc, Sunnyvale, CA, United States; Kankanamalage, C.P., Network Science Institute, Indiana University, Bloomington, United States; Pentchev, V., Network Science Institute, Indiana University, Bloomington, United States; Qiu, J., School of Informatics and Computing, Indiana University, Bloomington, United States; Ratkiewicz, J., Google Inc, Mountain View, CA, United States; Rudnick, A., Google Inc, Mountain View, CA, United States; Serrette, B., Network Science Institute, Indiana University, Bloomington, United States; Shiralkar, P., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, School of Informatics and Computing, Indiana University, Bloomington, United States; Varol, O., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, School of Informatics and Computing, Indiana University, Bloomington, United States; Weng, L., Affirm Inc, San Francisco, CA, United States; Wu, T.-L., Amazon Inc, Seattle, WA, United States; Younge, A.J., School of Informatics and Computing, Indiana University, Bloomington, United States; Menczer, F., Center for Complex Networks and Systems Research, Indiana University, Bloomington, United States, School of Informatics and Computing, Indiana University, Bloomington, United States, Network Science Institute, Indiana University, Bloomington, United States","The study of social phenomena is becoming increasingly reliant on big data from online social networks. Broad access to social media data, however, requires software development skills that not all researchers possess. Here we present the IUNI Observatory on Social Media, an open analytics platform designed to facilitate computational social science. The system leverages a historical, ongoing collection of over 70 billion public messages from Twitter. We illustrate a number of interactive open-source tools to retrieve, visualize, and analyze derived data from this collection. The Observatory, now available at osome.iuni.iu.edu, is the result of a large, six-year collaborative effort coordinated by the Indiana University Network Science Institute. © 2016 Davis et al.","API; Big data; Computational social science; Meme diffusion; Network science; Observatory; OSoMe; Social media; Twitter; Web science",,"Ciampaglia, G.L.; Center for Complex Networks and Systems Research, Indiana UniversityUnited States; email: gciampag@indiana.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030102405
"Newe A.","Enriching scientific publications with interactive 3D PDF: An integrated toolbox for creating ready-to-publish figures",2016,"PeerJ Computer Science","2016","6", e64,"","",,2,10.7717/peerj-cs.64,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013816792&doi=10.7717%2fpeerj-cs.64&partnerID=40&md5=a4e0bdd6e2025657bbf8d72819b9058d","Medical Applications Team, Method Park Engineering GmbH, Erlangen, Germany; Chair of Medical Informatics, Friedrich-Alexander Universität Erlangen-Nürnberg, Erlangen, Germany","Newe, A., Medical Applications Team, Method Park Engineering GmbH, Erlangen, Germany, Chair of Medical Informatics, Friedrich-Alexander Universität Erlangen-Nürnberg, Erlangen, Germany","Three-dimensional (3D) data of many kinds is produced at an increasing rate throughout all scientific disciplines. The Portable Document Format (PDF) is the de-facto standard for the exchange of electronic documents and allows for embedding three-dimensional models. Therefore, it is a well-suited medium for the visualization and the publication of this kind of data. The generation of the appropriate files has been cumbersome so far. This article presents the first release of a software toolbox which integrates the complete workflow for generating 3D model files and ready-to-publish 3D PDF documents for scholarly publications in a consolidated working environment. It can be used out-of-the-box as a simple working tool or as a basis for specifically tailored solutions. A comprehensive documentation, an example project and a project wizard facilitate the customization. It is available royalty-free and for Windows, MacOS and Linux. © 2016 Newe.","3D-PDF; Application; PDF; Portable Document Format; U3D; Universal 3D",,"Newe, A.; Medical Applications Team, Method Park Engineering GmbHGermany; email: axel.newe@fau.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85013816792
"Schwery O., O'Meara B.C.","MonoPhy: A simple R package to find and visualize monophyly issues",2016,"PeerJ Computer Science","2016","3", e56,"","",,2,10.7717/peerj-cs.56,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030123700&doi=10.7717%2fpeerj-cs.56&partnerID=40&md5=99ace0f8b2b84c78615b3b6da1e40246","Department of Ecology and Evolutionary Biology, University of Tennessee, Knoxville, TN, United States","Schwery, O., Department of Ecology and Evolutionary Biology, University of Tennessee, Knoxville, TN, United States; O'Meara, B.C., Department of Ecology and Evolutionary Biology, University of Tennessee, Knoxville, TN, United States","Background. The monophyly of taxa is an important attribute of a phylogenetic tree. A lack of it may hint at shortcomings of either the tree or the current taxonomy, or can indicate cases of incomplete lineage sorting or horizontal gene transfer. Whichever is the reason, a lack of monophyly can misguide subsequent analyses. While monophyly is conceptually simple, it is manually tedious and time consuming to assess on modern phylogenies of hundreds to thousands of species. Results. The R package MonoPhy allows assessment and exploration of monophyly of taxa in a phylogeny. It can assess themonophyly of genera using the phylogeny only, and with an additional input file any other desired higher order taxa or unranked groups can be checked as well. Conclusion. Summary tables, easily subsettable results and several visualization options allow quick and convenient exploration of monophyly issues, thus making MonoPhy a valuable tool for any researcher working with phylogenies. © 2016 Schwery and O'Meara.","Evolution; Horizontal gene transfer; Incomplete lineage sorting; Monophyly; Phylogeny; R package; Rogue taxa; Taxonomy; Tree conflict",,"Schwery, O.; Department of Ecology and Evolutionary Biology, University of TennesseeUnited States; email: oschwery@vols.utk.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030123700
"Picone M., Amoretti M., Ferrari G., Zanichelli F.","D4V: A peer-to-peer architecture for data dissemination in smartphone-based vehicular applications",2015,"PeerJ Computer Science","2015","8", e15,"","",,2,10.7717/peerj-cs.15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029289342&doi=10.7717%2fpeerj-cs.15&partnerID=40&md5=19794f7dc29dda0b8b64a141bd838564","Department of Information Engineering, Università degli Studi di Parma, Italy","Picone, M., Department of Information Engineering, Università degli Studi di Parma, Italy; Amoretti, M., Department of Information Engineering, Università degli Studi di Parma, Italy; Ferrari, G., Department of Information Engineering, Università degli Studi di Parma, Italy; Zanichelli, F., Department of Information Engineering, Università degli Studi di Parma, Italy","Vehicular data collection applications are emerging as an appealing technology to monitor urban areas, where a high concentration of connected vehicles with onboard sensors is a near future scenario. In this context, smartphones are, on one side, effective enablers of Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) applications and, on the other side, highly sophisticated sensing platforms. In this paper, we introduce an effective and efficient system, denoted as D4V, to disseminate vehicle-related information and sensed data using smartphones as V2I devices. D4V relies on a Peer-to-Peer (P2P) overlay scheme, denoted as Distributed Geographic Table (DGT), which unifies the concepts of physical and virtual neighborhoods in a scalable and robust infrastructure for application-level services. First, we investigate the discovery procedure of the DGT overlay network, through analytical and simulation results. Then, we present and discuss an extensive simulation-based performance evaluation (considering relevant performance indicators) of the D4V system, in a 4G wireless communication scenario. The simulation methodology combines DEUS (an application-level simulation tool for the study of large-scale systems) with ns-3 (a well-known network simulator, which takes into account lower layers), in order to provide a D4V proof-of-concept. The observed results show that D4V-based information sharing among vehicles allows to significantly reduce risks and nuisances (e.g., due to road defects and congestions). © 2015 Picone et al.","Localization; Peer-to-peer (P2P); Smartphones; Vehicle-to-infrastructure (V2I); Vehicular sensor networks (VSNs)","4G mobile communication systems; Information dissemination; Large scale systems; Sensor networks; Smartphones; Vehicles; Wireless telecommunication systems; Application-level services; Localization; Peer to peer; Peer-to-peer architectures; Performance evaluations; Vehicle to infrastructure (V2I); Vehicular applications; Vehicular Sensor Networks (VSNs); Peer to peer networks","Amoretti, M.; Department of Information Engineering, Università degli Studi di ParmaItaly; email: michele.amoretti@unipr.it",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85029289342
"Bazilinskyy P., deWinter J.","Auditory interfaces in automated driving: An international survey",2015,"PeerJ Computer Science","2015","8", e13,"","",,2,10.7717/peerj-cs.13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029808686&doi=10.7717%2fpeerj-cs.13&partnerID=40&md5=a86d17acba26f0f32fe41a191dd11f90","Department of Biomechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of Technology, Delft, Netherlands","Bazilinskyy, P., Department of Biomechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of Technology, Delft, Netherlands; deWinter, J., Department of Biomechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of Technology, Delft, Netherlands","This study investigated peoples' opinion on auditory interfaces in contemporary cars and their willingness to be exposed to auditory feedback in automated driving. We used an Internet-based survey to collect 1,205 responses from 91 countries. The respondents stated their attitudes towards two existing auditory driver assistance systems, a parking assistant (PA) and a forward collision warning system (FCWS), as well as towards a futuristic augmented sound system (FS) proposed for fully automated driving. The respondents were positive towards the PA and FCWS, and rated the willingness to have automated versions of these systems as 3.87 and 3.77, respectively (on a scale from 1 = disagree strongly to 5 = agree strongly). The respondents tolerated the FS (the mean willingness to use it was 3.00 on the same scale). The results showed that among the available response options, the female voice was the most preferred feedback type for takeover requests in highly automated driving, regardless of whether the respondents' country was English speaking or not. The present results could be useful for designers of automated vehicles and other stakeholders. © 2015 Bazilinskyy and DeWinter.","Auditory feedback; Auditory interface; Crowdsourcing; Driverless car; Fully automated driving; Highly automated driving; Questionnaire; Survey; Warning","Alarm systems; Automobile drivers; Crowdsourcing; Surveying; Surveys; Auditory feedback; Auditory interfaces; Driverless cars; Fully automated; Highly automated drivings; Questionnaire; Warning; Automation","Bazilinskyy, P.; Department of Biomechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of TechnologyNetherlands; email: p.bazilinskyy@tudelft.nl",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85029808686
"Haunschild R., Bornmann L., Leydesdorff L.","Networks of reader and country status: An analysis of Mendeley reader statistics",2015,"PeerJ Computer Science","2015","11", e32,"","",,2,10.7717/peerj-cs.32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020873681&doi=10.7717%2fpeerj-cs.32&partnerID=40&md5=b229635bef387c63e1014aa119fcaa67","Information Retrieval Service, Max Planck Institute for Solid State Research, Stuttgart, Germany; Division for Science and Innovation Studies, Administrative Headquarters of the Max Planck Society, Munich, Germany; Amsterdam School of Communication Research (ASCoR), University of Amsterdam, Amsterdam, Netherlands","Haunschild, R., Information Retrieval Service, Max Planck Institute for Solid State Research, Stuttgart, Germany; Bornmann, L., Division for Science and Innovation Studies, Administrative Headquarters of the Max Planck Society, Munich, Germany; Leydesdorff, L., Amsterdam School of Communication Research (ASCoR), University of Amsterdam, Amsterdam, Netherlands","The number of papers published in journals indexed by the Web of Science core collection is steadily increasing. In recent years, nearly two million new papers were published each year; somewhat more than one million papers when primary research papers are considered only (articles and reviews are the document types where primary research is usually reported or reviewed). However, who reads these papers? More precisely, which groups of researchers from which (self-assigned) scientific disciplines and countries are reading these papers? Is it possible to visualize readership patterns for certain countries, scientific disciplines, or academic status groups? One popular method to answer these questions is a network analysis. In this study, we analyzeMendeley readership data of a set of 1,133,224 articles and 64,960 reviews with publication year 2012 to generate three different networks: (1) The network based on disciplinary affiliations ofMendeley readers contains four groups: (i) biology, (ii) social sciences and humanities (including relevant computer sciences), (iii) bio-medical sciences, and (iv) natural sciences and engineering. In all four groups, the category with the addition ""miscellaneous"" prevails. (2) The network of co-readers in terms of professional status shows that a common interest in papers is mainly shared among PhD students, Master's students, and postdocs. (3) The country network focusses on global readership patterns: a group of 53 nations is identified as core to the scientific enterprise, including Russia and China as well as two thirds of the OECD (Organisation for Economic Co-operation andDevelopment) countries. © 2015 Haunschild et al.","Altmetrics; Bibliometrics; Mendeley; Network; Pajek; VOSviewer","International cooperation; Networks (circuits); Altmetrics; Bibliometrics; Mendeley; Pajek; VOSviewer; Paper","Haunschild, R.; Information Retrieval Service, Max Planck Institute for Solid State ResearchGermany; email: R.Haunschild@fkf.mpg.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85020873681
"Alshahrani M., Soufan O., Magana-Mora A., Bajic V.B.","DANNP: An efficient artificial neural network pruning tool",2017,"PeerJ Computer Science","2017","11", e137,"","",,1,10.7717/peerj-cs.137,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035746853&doi=10.7717%2fpeerj-cs.137&partnerID=40&md5=a584de9b1488da16a2cbc162dd7775f4","Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL), National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan","Alshahrani, M., Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Soufan, O., Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Magana-Mora, A., Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia, Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL), National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; Bajic, V.B., Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","Background. Artificial neural networks (ANNs) are a robust class of machine learning models and are a frequent choice for solving classification problems. However, determining the structure of the ANNs is not trivial as a large number of weights (connection links) may lead to overfitting the training data. Although several ANN pruning algorithms have been proposed for the simplification of ANNs, these algorithms are not able to efficiently cope with intricateANNstructures required for complex classification problems. Methods. We developed DANNP, a web-based tool, that implements parallelized versions of several ANN pruning algorithms. The DANNP tool uses a modified version of the Fast Compressed Neural Network software implemented in C++ to considerably enhance the running time of theANNpruning algorithms we implemented. In addition to the performance evaluation of the pruned ANNs, we systematically compared the set of features that remained in the pruned ANN with those obtained by different stateof- the-art feature selection (FS) methods. Results. Although the ANN pruning algorithms are not entirely parallelizable, DANNP was able to speed up the ANN pruning up to eight times on a 32-core machine, compared to the serial implementations. To assess the impact of the ANN pruning by DANNPtool, we used 16 datasets from different domains. In eight out of the 16 datasets, DANNP significantly reduced the number of weights by 70%-99%, while maintaining a competitive or better model performance compared to the unpruned ANN. Finally, we used a naïve Bayes classifier derived with the features selected as a byproduct of the ANN pruning and demonstrated that its accuracy is comparable to those obtained by the classifiers trained with the features selected by several state-of-the-art FS methods. The FS ranking methodology proposed in this study allows the users to identify the most discriminant features of the problem at hand. To the best of our knowledge, DANNP (publicly available at www.cbrc.kaust.edu.sa/dannp) is the only available and on-line accessible tool that provides multiple parallelized ANN pruning options. Datasets and DANNP code can be obtained at www.cbrc.kaust.edu.sa/dannp/data.php and https://doi.org/10.5281/zenodo.1001086. © 2017 Alshahrani et al.","Artificial inteligence; Artificial neural networks; Classification problems; Feature selection; Machine learning; Parallelization; Pruning",,"Bajic, V.B.; Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST)Saudi Arabia; email: vladimir.bajic@kaust.edu.sa",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85035746853
"Terrell J., Kofink A., Middleton J., Rainear C., Murphy-Hill E., Parnin C., Stallings J.","Gender differences and bias in open source: Pull request acceptance of women versus men",2017,"PeerJ Computer Science","2017","5", e111,"","",,1,10.7717/peerj-cs.111,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028652618&doi=10.7717%2fpeerj-cs.111&partnerID=40&md5=0752e0c7d33f2adf84159ee52a385483","Department of Computer Science, California Polytechnic State University-San Luis Obispo, San Luis Obispo, CA, United States; Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Department of Statistics, North Carolina State University, Raleigh, NC, United States","Terrell, J., Department of Computer Science, California Polytechnic State University-San Luis Obispo, San Luis Obispo, CA, United States; Kofink, A., Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Middleton, J., Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Rainear, C., Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Murphy-Hill, E., Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Parnin, C., Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Stallings, J., Department of Statistics, North Carolina State University, Raleigh, NC, United States","Biases against women in the workplace have been documented in a variety of studies. This paper presents a large scale study on gender bias, where we compare acceptance rates of contributions from men versus women in an open source software community. Surprisingly, our results show that women's contributions tend to be accepted more often than men's. However, for contributors who are outsiders to a project and their gender is identifiable, men's acceptance rates are higher. Our results suggest that although women on GitHub may be more competent overall, bias against them exists nonetheless. © 2017 Terrell et al.","Bias; Gender; Open source; Software development; Software engineering",,"Murphy-Hill, E.; Department of Computer Science, North Carolina State UniversityUnited States; email: emerson@csc.ncsu.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85028652618
"Dimou A., Vahdati S., Iorio A.D., Lange C., Verborgh R., Mannens E.","Challenges as enablers for high quality linked data: Insights from the semantic publishing challenge",2017,"PeerJ Computer Science","2017","1", e105,"","",,1,10.7717/peerj-cs.105,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029807301&doi=10.7717%2fpeerj-cs.105&partnerID=40&md5=8cb706d88178d9718c4e2e67b8557f0a","Faculty of Engineering and Architecture, Ghent University, Ghent, Belgium; imec, Leuven, Belgium; Department of Intelligent Systems, University of Bonn, Bonn, Germany; Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Enterprise Information Systems, Fraunhofer IAIS, Sankt Augustin, Germany","Dimou, A., Faculty of Engineering and Architecture, Ghent University, Ghent, Belgium, imec, Leuven, Belgium; Vahdati, S., Department of Intelligent Systems, University of Bonn, Bonn, Germany; Iorio, A.D., Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Lange, C., Department of Intelligent Systems, University of Bonn, Bonn, Germany, Enterprise Information Systems, Fraunhofer IAIS, Sankt Augustin, Germany; Verborgh, R., Faculty of Engineering and Architecture, Ghent University, Ghent, Belgium, imec, Leuven, Belgium; Mannens, E., Faculty of Engineering and Architecture, Ghent University, Ghent, Belgium, imec, Leuven, Belgium","While most challenges organized so far in the Semantic Web domain are focused on comparing tools with respect to different criteria such as their features and competencies, or exploiting semantically enriched data, the Semantic Web Evaluation Challenges series, co-located with the ESWC Semantic Web Conference, aims to compare them based on their output, namely the produced dataset. The Semantic Publishing Challenge is one of these challenges. Its goal is to involve participants in extracting data from heterogeneous sources on scholarly publications, and producing Linked Data that can be exploited by the community itself. This paper reviews lessons learned from both (i) the overall organization of the Semantic Publishing Challenge, regarding the definition of the tasks, building the input dataset and forming the evaluation, and (ii) the results produced by the participants, regarding the proposed approaches, the used tools, the preferred vocabularies and the results produced in the three editions of 2014, 2015 and 2016. We compared these lessons to other Semantic Web Evaluation Challenges. In this paper, we (i) distill best practices for organizing such challenges that could be applied to similar events, and (ii) report observations on Linked Data publishing derived from the submitted solutions. We conclude that higher quality may be achieved when Linked Data is produced as a result of a challenge, because the competition becomes an incentive, while solutions become better with respect to Linked Data publishing best practices when they are evaluated against the rules of the challenge. © 2017 Dimou et al.","Challenge; Linked Data; Linked Data publishing; Semantic Publishing; Semantic Web; Survey",,"Dimou, A.; Faculty of Engineering and Architecture, Ghent UniversityBelgium; email: anastasia.dimou@ugent.be",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85029807301
"Fagerholm F., Kuhrmann M., Münch J.","Guidelines for using empirical studies in software engineering education",2017,"PeerJ Computer Science","2017","9", e131,"","",,1,10.7717/peerj-cs.131,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030151172&doi=10.7717%2fpeerj-cs.131&partnerID=40&md5=95c72ef783d7b4387c87bbb035a6d541","Department of Computer Science, University of Helsinki, Helsinki, Finland; Institute for Applied Software Systems Engineering, Clausthal University of Technology, Goslar, Germany; Herman Hollerith Center (HHZ), Reutlingen University, Böblingen, Germany","Fagerholm, F., Department of Computer Science, University of Helsinki, Helsinki, Finland; Kuhrmann, M., Institute for Applied Software Systems Engineering, Clausthal University of Technology, Goslar, Germany; Münch, J., Department of Computer Science, University of Helsinki, Helsinki, Finland, Herman Hollerith Center (HHZ), Reutlingen University, Böblingen, Germany","Software engineering education is under constant pressure to provide students with industry-relevant knowledge and skills. Educators must address issues beyond exercises and theories that can be directly rehearsed in small settings. Industry training has similar requirements of relevance as companies seek to keep their workforce up to date with technological advances. Real-life software development often deals with large, software-intensive systems and is influenced by the complex effects of teamwork and distributed software development, which are hard to demonstrate in an educational environment. A way to experience such effects and to increase the relevance of software engineering education is to apply empirical studies in teaching. In this paper, we show how different types of empirical studies can be used for educational purposes in software engineering. We give examples illustrating how to utilize empirical studies, discuss challenges, and derive an initial guideline that supports teachers to include empirical studies in software engineering courses. Furthermore, we give examples that show how empirical studies contribute to high-quality learning outcomes, to student motivation, and to the awareness of the advantages of applying software engineering principles. Having awareness, experience, and understanding of the actions required, students are more likely to apply such principles under real-life constraints in their working life. © 2017 Fagerholm et al.","Computer science curricula; Education; Empirical studies; Experimentation; Guideline; Software engineering education; Teaching methods",,"Fagerholm, F.; Department of Computer Science, University of HelsinkiFinland; email: fabian.fagerholm@helsinki.fi",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030151172
"Kim J., Cha M., Lee J.G.","Nowcasting commodity prices using social media",2017,"PeerJ Computer Science","2017","7", e126,"","",,1,10.7717/peerj-cs.126,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030160294&doi=10.7717%2fpeerj-cs.126&partnerID=40&md5=818dd74208663170f19af8eb69c26f2e","Graduate School of Culture Technology, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; United Nations Global Pulse, United States","Kim, J., Graduate School of Culture Technology, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Cha, M., Graduate School of Culture Technology, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Lee, J.G., United Nations Global Pulse, United States","Gathering up-to-date information on food prices is critical in developing regions, as it allows policymakers and development practitioners to rely on accurate data on food security. This study explores the feasibility of utilizing social media as a new data source for predicting food security landscape in developing countries. Through a case study of Indonesia, we developed a nowcast model that monitors mentions of food prices on Twitter and forecasts daily price fluctuations of four major food commodities: beef, chicken, onion, and chilli. A longitudinal test over 15 months of data demonstrates that not only that the proposed model accurately predicts food prices, but it is also resilient to data scarcity. The high accuracy of the nowcast model is attributed to the observed trend that the volume of tweets mentioning food prices tends to increase on days when food prices change sharply. We discuss factors that affect the veracity of price quotations such as social network-wide sensitivity and user influence. © 2017 Kim et al.","Developing countries; Food security; Nowcast; Price monitoring; Price prediction; Real-time; Social media; Twitter",,"Cha, M.; Graduate School of Culture Technology, Korea Advanced Institute of Science and TechnologySouth Korea; email: meeyoungcha@kaist.ac.kr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030160294
"McCusker J.P., Dumontier M., Yan R., He S., Dordick J.S., McGuinness D.L.","Finding melanoma drugs through a probabilistic knowledge graph",2017,"PeerJ Computer Science","2017","2", e106,"","",,1,10.7717/peerj-cs.106,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028923063&doi=10.7717%2fpeerj-cs.106&partnerID=40&md5=20415d26a59fcbcc31bb2a5e1243ee38","Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, United States; Stanford Center for Biomedical Informatics Research, Stanford University School of Medicine, Stanford, CA, United States; Department of Chemical and Biological Engineering, Rensselaer Polytechnic Institute, Troy, NY, United States; Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY, United States","McCusker, J.P., Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, United States; Dumontier, M., Stanford Center for Biomedical Informatics Research, Stanford University School of Medicine, Stanford, CA, United States; Yan, R., Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, United States; He, S., Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, United States; Dordick, J.S., Department of Chemical and Biological Engineering, Rensselaer Polytechnic Institute, Troy, NY, United States, Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY, United States; McGuinness, D.L., Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, United States, Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY, United States","Metastatic cutaneous melanoma is an aggressive skin cancer with some progressionslowing treatments but no known cure. The omics data explosion has created many possible drug candidates; however, filtering criteria remain challenging, and systems biology approaches have become fragmented with many disconnected databases. Using drug, protein and disease interactions, we built an evidence-weighted knowledge graph of integrated interactions. Our knowledge graph-based system, ReDrugS, can be used via an application programming interface or web interface, and has generated 25 high-quality melanoma drug candidates. We show that probabilistic analysis of systems biology graphs increases drug candidate quality compared to non-probabilistic methods. Four of the 25 candidates are novel therapies, three of which have been tested with other cancers. All other candidates have current or completed clinical trials, or have been studied in in vivo or in vitro. This approach can be used to identify candidate therapies for use in research or personalized medicine. © 2017 McCusker et al.","Drug repositioning; Knowledge graphs; Melanoma; Uncertainty reasoning",,"McCusker, J.P.; Department of Computer Science, Rensselaer Polytechnic InstituteUnited States; email: mccusj@cs.rpi.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85028923063
"Cowley B.U., Korpela J., Torniainen J.","Computational testing for automated preprocessing: A matlab toolbox to enable large scale electroencephalography data processing",2017,"PeerJ Computer Science","2017","3", e108,"","",,1,10.7717/peerj-cs.108,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030121202&doi=10.7717%2fpeerj-cs.108&partnerID=40&md5=fe0f34cc27cf42a58ba3e6c7c6772f86","BrainWork Research Centre, Finnish Institute of Occupational Health, Helsinki, Finland; Cognitive Brain Research Unit, Faculty of Medicine, University of Helsinki, Helsinki, Finland; Biophysics of Bone and Cartilage Group, Department of Applied Physics, University of Eastern Finland, Kuopio, Finland","Cowley, B.U., BrainWork Research Centre, Finnish Institute of Occupational Health, Helsinki, Finland, Cognitive Brain Research Unit, Faculty of Medicine, University of Helsinki, Helsinki, Finland; Korpela, J., BrainWork Research Centre, Finnish Institute of Occupational Health, Helsinki, Finland; Torniainen, J., Biophysics of Bone and Cartilage Group, Department of Applied Physics, University of Eastern Finland, Kuopio, Finland","Electroencephalography (EEG) is a rich source of information regarding brain function. However, the preprocessing of EEG data can be quite complicated, due to several factors. For example, the distinction between true neural sources and noise is indeterminate; EEG data can also be very large. The various factors create a large number of subjective decisions with consequent risk of compound error. Existing tools present the experimenter with a large choice of analysis methods. Yet it remains a challenge for the researcher to integrate methods for batch-processing of the average large datasets, and compare methods to choose an optimal approach across the many possible parameter configurations. Additionally, many tools still require a high degree of manual decision making for, e.g. the classification of artefacts in channels, epochs or segments. This introduces extra subjectivity, is slow and is not reproducible. Batching and well-designed automation can help to regularise EEG preprocessing, and thus reduce human effort, subjectivity and consequent error. We present the computational testing for automated preprocessing (CTAP) toolbox, to facilitate: (i) batch-processing that is easy for experts and novices alike; (ii) testing and manual comparison of preprocessing methods. CTAP extends the existing data structure and functions from the well-known EEGLAB toolbox, based on Matlab and produces extensive quality control outputs. CTAP is available under MIT licence from https://github.com/bwrc/ctap. © 2017 Cowley et al.","Automation; Computation; EEGLAB; Electroencephalography; Preprocessing; Signal processing; Testing",,"Cowley, B.U.; BrainWork Research Centre, Finnish Institute of Occupational HealthFinland; email: benjamin.cowley@ttl.fi",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030121202
"Wu Y., Wang N., Kropczynski J., Carroll J.M.","The appropriation of GitHub for curation",2017,"PeerJ Computer Science","2017","10", e134,"","",,1,10.7717/peerj-cs.134,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032747778&doi=10.7717%2fpeerj-cs.134&partnerID=40&md5=d89e1b4de356d399ec0205276e21b62f","Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States; Samsung Research America, Mountain View, CA, United States; School of Information Technology, University of Cincinnati, Cincinnati, OH, United States","Wu, Y., Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States; Wang, N., Samsung Research America, Mountain View, CA, United States; Kropczynski, J., School of Information Technology, University of Cincinnati, Cincinnati, OH, United States; Carroll, J.M., Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States","GitHub is a widely used online collaborative software development environment. In this paper, we describe curation projects as a new category of GitHub project that collects, evaluates, and preserves resources for software developers. We investigate: (1) what motivates software developers to curate resources; (2) why curation has occurred on GitHub; (3) how curated resources are used by software developers; and (4) how the GitHub platform could better support these practices. We conduct in- depth interviews with 16 software developers, each of whom hosts curation projects on GitHub. Our results suggest that the motivators that inspire software developers to curate resources on GitHub are similar to those that motivate them to participate in the development of open source projects. Convenient tools (e.g., Markdown syntax and Git version control system) and the opportunity to address professional needs of a large number of peers attract developers to engage in curation projects on GitHub. Benefits of curating on GitHub include learning opportunities, support for development work, and professional interaction. However, curation is limited by GitHub's document structure, format, and a lack of key features, such as search. In light of this, we propose design possibilities to encourage and improve appropriations of GitHub for curation. © 2017 Wu et al.","Appropriation; Curation; GitHub",,"Wu, Y.; Information Sciences and Technology, Pennsylvania State UniversityUnited States; email: yuw132@psu.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85032747778
"Wilkinson M.D., Verborgh R., da Silva Santos L.O.B., Clark T., Swertz M.A., Kelpin F.D.L., Gray A.J.G., Schultes E.A., van Mulligen E.M., Ciccarese P., Kuzniar A., Gavai A., Thompson M., Kaliyaperumal R., Bolleman J.T., Dumontier M.","Interoperability and FAIRness through a novel combination of Web technologies",2017,"PeerJ Computer Science","2017","4", e110,"","",,1,10.7717/peerj-cs.110,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025116787&doi=10.7717%2fpeerj-cs.110&partnerID=40&md5=39954ef9a03171d4c153a9270a112b93","Center for Plant Biotechnology and Genomics UPM-INIA, Universidad Politécnica de Madrid, Madrid, Spain; IMEC, Ghent University, Ghent, Belgium; Dutch Techcentre for Life Sciences, Utrecht, Netherlands; Department of Neurology, Massachusetts General Hospital, Boston, MA, United States; Department of Neurology, Harvard Medical School, Boston, United States; Genomics Coordination Center and Department of Genetics, University Medical Center Groningen, Groningen, Netherlands; Department of Computer Science, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, United Kingdom; FAIR Data, Dutch TechCenter for Life Science, Utrecht, Netherlands; Department of Medical Informatics, Erasmus University Medical Center, Rotterdam, Netherlands; Elmer Innovation Lab, Harvard Medical School, Boston, United States; Netherlands eScience Center, Amsterdam, Netherlands; Department of Human Genetics, Leiden University Medical Center, Leiden, Netherlands; Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Centre Medical Universitaire, Geneva, Switzerland; Stanford Center for Biomedical Informatics Research, Stanford University School of Medicine, Stanford, CA, United States","Wilkinson, M.D., Center for Plant Biotechnology and Genomics UPM-INIA, Universidad Politécnica de Madrid, Madrid, Spain; Verborgh, R., IMEC, Ghent University, Ghent, Belgium; da Silva Santos, L.O.B., Dutch Techcentre for Life Sciences, Utrecht, Netherlands; Clark, T., Department of Neurology, Massachusetts General Hospital, Boston, MA, United States, Department of Neurology, Harvard Medical School, Boston, United States; Swertz, M.A., Genomics Coordination Center and Department of Genetics, University Medical Center Groningen, Groningen, Netherlands; Kelpin, F.D.L., Genomics Coordination Center and Department of Genetics, University Medical Center Groningen, Groningen, Netherlands; Gray, A.J.G., Department of Computer Science, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, United Kingdom; Schultes, E.A., FAIR Data, Dutch TechCenter for Life Science, Utrecht, Netherlands; van Mulligen, E.M., Department of Medical Informatics, Erasmus University Medical Center, Rotterdam, Netherlands; Ciccarese, P., Elmer Innovation Lab, Harvard Medical School, Boston, United States; Kuzniar, A., Netherlands eScience Center, Amsterdam, Netherlands; Gavai, A., Netherlands eScience Center, Amsterdam, Netherlands; Thompson, M., Department of Human Genetics, Leiden University Medical Center, Leiden, Netherlands; Kaliyaperumal, R., Department of Human Genetics, Leiden University Medical Center, Leiden, Netherlands; Bolleman, J.T., Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Centre Medical Universitaire, Geneva, Switzerland; Dumontier, M., Stanford Center for Biomedical Informatics Research, Stanford University School of Medicine, Stanford, CA, United States","Data in the life sciences are extremely diverse and are stored in a broad spectrum of repositories ranging from those designed for particular data types (such as KEGG for pathway data or UniProt for protein data) to those that are general-purpose (such as FigShare, Zenodo, Dataverse or EUDAT). These data have widely different levels of sensitivity and security considerations. For example, clinical observations about genetic mutations in patients are highly sensitive, while observations of species diversity are generally not. The lack of uniformity in data models from one repository to another, and in the richness and availability of metadata descriptions, makes integration and analysis of these data a manual, time-consuming task with no scalability. Here we explore a set of resource-orientedWeb design patterns for data discovery, accessibility, transformation, and integration that can be implemented by any general- or special- purpose repository as a means to assist users in finding and reusing their data holdings. We show that by using off-the-shelf technologies, interoperability can be achieved atthe level of an individual spreadsheet cell.We note that the behaviours of this architecture compare favourably to the desiderata defined by the FAIR Data Principles, and can therefore represent an exemplar implementation of those principles. The proposed interoperability design patterns may be used to improve discovery and integration of both new and legacy data, maximizing the utility of all scholarly outputs. © 2017Wilkinson et al.","Data integration; FAIR data; Interoperability; Linked data; REST; Semantic web",,"Wilkinson, M.D.; Center for Plant Biotechnology and Genomics UPM-INIA, Universidad Politécnica de MadridSpain; email: markw@illuminae.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85025116787
"Webb A.E., Walsh T.A., O'Connell M.J.","VESPA: Very large-scale evolutionary and selective pressure analyses",2017,"PeerJ Computer Science","2017","6", e118,"","",,1,10.7717/peerj-cs.118,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030128853&doi=10.7717%2fpeerj-cs.118&partnerID=40&md5=1dde4274b1b2c9e526287e46b66e8695","Bioinformatics and Molecular Evolution Group, School of Biotechnology, Faculty of Science and Health, Dublin City University, Dublin, Ireland; Computational and Molecular Evolutionary Biology Group, School of Biology, Faculty of Biological Sciences, The University of Leeds, Leeds, United Kingdom","Webb, A.E., Bioinformatics and Molecular Evolution Group, School of Biotechnology, Faculty of Science and Health, Dublin City University, Dublin, Ireland; Walsh, T.A., Bioinformatics and Molecular Evolution Group, School of Biotechnology, Faculty of Science and Health, Dublin City University, Dublin, Ireland; O'Connell, M.J., Bioinformatics and Molecular Evolution Group, School of Biotechnology, Faculty of Science and Health, Dublin City University, Dublin, Ireland, Computational and Molecular Evolutionary Biology Group, School of Biology, Faculty of Biological Sciences, The University of Leeds, Leeds, United Kingdom","Background. Large-scale molecular evolutionary analyses of protein coding sequences requires a number of preparatory inter-related steps from finding gene families, to generating alignments and phylogenetic trees and assessing selective pressure variation. Each phase of these analyses can represent significant challenges, particularly when working with entire proteomes (all protein coding sequences in a genome) from a large number of species. Methods. We present VESPA, software capable of automating a selective pressure analysis using codeML in addition to the preparatory analyses and summary statistics. VESPA is written in python and Perl and is designed to run within a UNIX environment. Results. We have benchmarked VESPA and our results show that the method is consistent, performs well on both large scale and smaller scale datasets, and produces results in line with previously published datasets. Discussion. Large-scale gene family identification, sequence alignment, and phylogeny reconstruction are all important aspects of large-scale molecular evolutionary analyses. VESPA provides flexible software for simplifying these processes along with downstream selective pressure variation analyses. The software automatically interprets results from codeML and produces simplified summary files to assist the user in better understanding the results. VESPA may be found at the following website: http://www.mol-evol.org/VESPA. © 2017 Webb et al.","Gene family evolution; Large-scale comparative genomics; Positive selection; Protein molecular evolution; Selective pressure analysis",,"O'Connell, M.J.; Bioinformatics and Molecular Evolution Group, School of Biotechnology, Faculty of Science and Health, Dublin City UniversityIreland; email: m.oconnell@leeds.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030128853
"Krewinkel A., Winkler R.","Formatting open science: Agilely creating multiple document formats for academic manuscripts with pandoc scholar",2017,"PeerJ Computer Science","2017","5", e112,"","",,1,10.7717/peerj-cs.112,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030150681&doi=10.7717%2fpeerj-cs.112&partnerID=40&md5=ebf6cb9838c971d74ef9382628d405b1","Pandoc Development Team, Berlin, Germany; Department of Biotechnology and Biochemistry, CINVESTAV Unidad Irapuato, Mexico","Krewinkel, A., Pandoc Development Team, Berlin, Germany; Winkler, R., Department of Biotechnology and Biochemistry, CINVESTAV Unidad Irapuato, Mexico","The timely publication of scientific results is essential for dynamic advances in science. The ubiquitous availability of computers which are connected to a global network made the rapid and low-cost distribution of information through electronic channels possible. New concepts, such as Open Access publishing and preprint servers are currently changing the traditional print media business towards a community-driven peer production. However, the cost of scientific literature generation, which is either charged to readers, authors or sponsors, is still high. The main active participants in the authoring and evaluation of scientific manuscripts are volunteers, and the cost for online publishing infrastructure is close to negligible. A major time and cost factor is the formatting of manuscripts in the production stage. In this article we demonstrate the feasibility of writing scientific manuscripts in plain markdown (MD) text files, which can be easily converted into common publication formats, such as PDF, HTML or EPUB, using Pandoc. The simple syntax of Markdown assures the long-term readability of raw files and the development of software and workflows. We show the implementation of typical elements of scientific manuscripts-formulas, tables, code blocks and citations-and present tools for editing, collaborative writing and version control. We give an example on how to prepare a manuscript with distinct output formats, a DOCX file for submission to a journal, and a LATEX/PDF version for deposition as a PeerJ preprint. Further, we implemented new features for supporting 'semantic web' applications, such as the 'journal article tag suite'- JATS, and the 'citation typing ontology'-CiTO standard. Reducing the work spent on manuscript formatting translates directly to time and cost savings for writers, publishers, readers and sponsors. Therefore, the adoption of theMDformat contributes to the agile production of open science literature. Pandoc Scholar is freely available from https://github.com/pandoc-scholar. © 2017 Krewinkel and Winkler.","Document formats; Latex; Markdown; Open science; Publishing; Typesetting",,"Winkler, R.; Department of Biotechnology and Biochemistry, CINVESTAV Unidad IrapuatoMexico; email: robert.winkler@cinvestav.mx",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030150681
"Ankenbrand M.J., Hohlfeld S., Hackl T., Förster F.","AliTV-interactive visualization of whole genome comparisons",2017,"PeerJ Computer Science","2017","6", e116,"","",,1,10.7717/peerj-cs.116,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030102784&doi=10.7717%2fpeerj-cs.116&partnerID=40&md5=fb65af81c369b1be28cb3171308e906d","Department of Animal Ecology and Tropical Biology, Julius Maximilian University, Würzburg, Germany; Department for Bioinformatics, Julius Maximilian University, Würzburg, Germany; Department of Civil and Environmental Engineering, Massachusetts Institute of Technology, Cambridge, MA, United States; Center for Computational and Theoretical Biology, Julius Maximilian University, Würzburg, Germany","Ankenbrand, M.J., Department of Animal Ecology and Tropical Biology, Julius Maximilian University, Würzburg, Germany; Hohlfeld, S., Department of Animal Ecology and Tropical Biology, Julius Maximilian University, Würzburg, Germany, Department for Bioinformatics, Julius Maximilian University, Würzburg, Germany; Hackl, T., Department for Bioinformatics, Julius Maximilian University, Würzburg, Germany, Department of Civil and Environmental Engineering, Massachusetts Institute of Technology, Cambridge, MA, United States; Förster, F., Department for Bioinformatics, Julius Maximilian University, Würzburg, Germany, Center for Computational and Theoretical Biology, Julius Maximilian University, Würzburg, Germany","Whole genome alignments and comparative analysis are key methods in the quest of unraveling the dynamics of genome evolution. Interactive visualization and exploration of the generated alignments, annotations, and phylogenetic data are important steps in the interpretation of the initial results. Limitations of existing software inspired us to develop our new tool AliTV, which provides interactive visualization of whole genome alignments. AliTV reads multiple whole genome alignments or automatically generates alignments from the provided data. Optional feature annotations and phylogenetic information are supported. The user-friendly, web-browser based and highly customizable interface allows rapid exploration and manipulation of the visualized data as well as the export of publication-ready high-quality figures. AliTV is freely available at https://github.com/AliTVTeam/AliTV. © 2017 Ankenbrand et al.","Alignment; Comparative genomics; Visualization",,"Förster, F.; Center for Computational and Theoretical Biology, Julius Maximilian UniversityGermany; email: frank.foerster@uni-wuerzburg.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030102784
"Swainston N., Currin A., Green L., Breitling R., Day P.J., Kell D.B.","CodonGenie: Optimised ambiguous codon design tools",2017,"PeerJ Computer Science","2017","7", e120,"","",,1,10.7717/peerj-cs.120,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101898&doi=10.7717%2fpeerj-cs.120&partnerID=40&md5=d387c90453cd7620fdfaabc2708ebdfc","Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of Manchester, Manchester, United Kingdom; School of Chemistry, University of Manchester, Manchester, United Kingdom; Faculty of Biology, Medicine and Health, University of Manchester, Manchester, United Kingdom","Swainston, N., Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of Manchester, Manchester, United Kingdom; Currin, A., Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of Manchester, Manchester, United Kingdom; Green, L., Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of Manchester, Manchester, United Kingdom; Breitling, R., Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of Manchester, Manchester, United Kingdom, School of Chemistry, University of Manchester, Manchester, United Kingdom; Day, P.J., Faculty of Biology, Medicine and Health, University of Manchester, Manchester, United Kingdom; Kell, D.B., Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of Manchester, Manchester, United Kingdom, School of Chemistry, University of Manchester, Manchester, United Kingdom","CodonGenie, freely available from http://codon.synbiochem.co.uk, is a simple web application for designing ambiguous codons to support protein mutagenesis applica- tions. Ambiguous codons are derived from specific heterogeneous nucleotide mixtures, which create sequence degeneracy when synthesised in a DNA library. In directed evolution studies, such codons are carefully selected to encode multiple amino acids. For example, the codon NTN, where the code N denotes a mixture of all four nucleotides, will encode a mixture of phenylalanine, leucine, isoleucine, methionine and valine. Given a user-defined target collection of amino acids matched to an intended host organism, CodonGenie designs and analyses all ambiguous codons that encode the required amino acids. The codons are ranked according to their efficiency in encoding the required amino acids while minimising the inclusion of additional amino acids and stop codons. Organism-specific codon usage is also considered. © 2017 Swainston et al.","Codon; Directed evolution; Enzyme engineering; Industrial biotechnology; Mutagenesis; Protein engineering",,"Swainston, N.; Manchester Centre for Synthetic Biology of Fine and Speciality Chemicals (SYNBIOCHEM), University of ManchesterUnited Kingdom; email: neil.swainston@manchester.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030101898
"Zacharaki E.I.","Prediction of protein function using a deep convolutional neural network ensemble",2017,"PeerJ Computer Science","2017","7", 124,"","",,1,10.7717/peerj-cs.124,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029862894&doi=10.7717%2fpeerj-cs.124&partnerID=40&md5=9eaa7e0c4a62eacc5ca5aea119aa5b28","Center for Visual Computing, CentraleSupélec and GALEN Team, INRIA Saclay, France","Zacharaki, E.I., Center for Visual Computing, CentraleSupélec and GALEN Team, INRIA Saclay, France","Background. The availability of large databases containing high resolution threedimensional (3D) models of proteins in conjunction with functional annotation allows the exploitation of advanced supervised machine learning techniques for automatic protein function prediction. Methods. In this work, novel shape features are extracted representing protein structure in the form of local (per amino acid) distribution of angles and amino acid distances, respectively. Each of the multi-channel feature maps is introduced into a deep convolutional neural network (CNN) for function prediction and the outputs are fused through support vector machines or a correlation-based k-nearest neighbor classifier. Two different architectures are investigated employing either one CNN per multichannel feature set, or one CNN per image channel. Results. Cross validation experiments on single-functional enzymes (nD44,661) from thePDBdatabase achieved 90.1% correct classification, demonstrating an improvement over previous results on the same dataset when sequence similarity was not considered. Discussion. The automatic prediction of protein function can provide quick annotations on extensive datasets opening the path for relevant applications, such as pharmacological target identification. The proposed method shows promise for structure-based protein function prediction, but sufficient data may not yet be available to properly assess the method's performance on non-homologous proteins and thus reduce the confounding factor of evolutionary relationships. © 2017 Zacharaki.","Convolutional neural networks; Deep learning; Enzyme classification; Function predition; Structure representation",,"Zacharaki, E.I.; Center for Visual Computing, CentraleSupélec and GALEN Team, INRIA SaclayFrance; email: evangelia.zacharaki@centralesupelec.fr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85029862894
"Schleicher J.M., Vögler M., Inzinger C., Dustdar S.","Smart Brix-a continuous evolution framework for container application deployments",2016,"PeerJ Computer Science","2016","6", e66,"","",,1,10.7717/peerj-cs.66,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030107160&doi=10.7717%2fpeerj-cs.66&partnerID=40&md5=6dbe25bc8badad970a4aa6b3752ddc3a","Distributed Systems Group, TU Wien, Vienna, Austria; S.E.A.L-Software Evolution and Architecture Lab, University of Zürich, Zürich, Switzerland","Schleicher, J.M., Distributed Systems Group, TU Wien, Vienna, Austria; Vögler, M., Distributed Systems Group, TU Wien, Vienna, Austria; Inzinger, C., S.E.A.L-Software Evolution and Architecture Lab, University of Zürich, Zürich, Switzerland; Dustdar, S., Distributed Systems Group, TU Wien, Vienna, Austria","Container-based application deployments have received significant attention in recent years. Operating system virtualization based on containers as a mechanism to deploy and manage complex, large-scale software systems has become a popular mechanism for application deployment and operation. Packaging application components into selfcontained artifacts has brought substantial flexibility to developers and operation teams alike. However, this flexibility comes at a price. Practitioners need to respect numerous constraints ranging from security and compliance requirements, to specific regulatory conditions. Fulfilling these requirements is especially challenging in specialized domains with large numbers of stakeholders. Moreover, the rapidly growing number of container images to be managed due to the introduction of new or updated applications and respective components, leads to significant challenges for container management and adaptation. In this paper, we introduce Smart Brix, a framework for continuous evolution of container application deployments that tackles these challenges. Smart Brix integrates and unifies concepts of continuous integration, runtime monitoring, and operational analytics. Furthermore, it allows practitioners to define generic analytics and compensation pipelines composed of self-assembling processing components to autonomously validate and verify containers to be deployed. We illustrate the feasibility of our approach by evaluating our framework using a case study from the smart city domain. We show that Smart Brix is horizontally scalable and runtime of the implemented analysis and compensation pipelines scales linearly with the number of container application packages. © 2016 Schleicher et al.","Container adaptation; Container evolution; Containers; DevOps; Infrastructure as Code",,"Schleicher, J.M.; Distributed Systems Group, TU WienAustria; email: schleicher@dsg.tuwien.ac.at",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030107160
"Maass M., Sales A., Chung B., Sunshine J.","A systematic analysis of the science of sandboxing",2016,"PeerJ Computer Science","2016","1", e43,"","",,1,10.7717/peerj-cs.43,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978711617&doi=10.7717%2fpeerj-cs.43&partnerID=40&md5=d2023c82fd8f9e3787c7003d836591a1","Institute for Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Statistics Department, Carnegie Mellon University, Pittsburgh, PA, United States","Maass, M., Institute for Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Sales, A., Statistics Department, Carnegie Mellon University, Pittsburgh, PA, United States; Chung, B., Institute for Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Sunshine, J., Institute for Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States","Sandboxes are increasingly important building materials for secure software systems. In recognition of their potential to improve the security posture of many systems at various points in the development lifecycle, researchers have spent the last several decades developing, improving, and evaluating sandboxing techniques. What has been done in this space?Where are the barriers to advancement?What are the gaps in these efforts? We systematically analyze a decade of sandbox research from five top-tier security and systems conferences using qualitative content analysis, statistical clustering, and graph-based metrics to answer these questions and more. We find that the term ""sandbox"" currently has no widely accepted or acceptable definition. We use our broad scope to propose the first concise and comprehensive definition for ""sandbox"" that consistently encompasses research sandboxes.We learn that the sandboxing landscape covers a range of deployment options and policy enforcement techniques collectively capable of defending diverse sets of components while mitigating a wide range of vulnerabilities. Researchers consistently make security, performance, and applicability claims about their sandboxes and tend to narrowly define the claims to ensure they can be evaluated. Those claims are validated using multi-faceted strategies spanning proof, analytical analysis, benchmark suites, case studies, and argumentation. However, we find two cases for improvement: (1) the arguments researchers present are often ad hoc and (2) sandbox usability is mostly uncharted territory. We propose ways to structure arguments to ensure they fully support their corresponding claims and suggest lightweight means of evaluating sandbox usability. © 2016 Maass et al.","Access control; Qualitative content analysis; Sandboxing; Security; Security validation; Software protection",,"Maass, M.; Institute for Software Research, School of Computer Science, Carnegie Mellon UniversityUnited States; email: mmaass@andrew.cmu.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-84978711617
"Durrande N., Hensman J., Rattray M., Lawrence N.D.","Detecting periodicities with gaussian processes",2016,"PeerJ Computer Science","2016","4", e50,"","",,1,10.7717/peerj-cs.50,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030130321&doi=10.7717%2fpeerj-cs.50&partnerID=40&md5=e728ec4817f950d99d53c6b85d3ded93","Institut Fayol-LIMOS, Mines Saint-étienne, Saint-étienne, France; CHICAS, Faculty of Health and Medicine, Lancaster University, Lancaster, United Kingdom; Faculty of Life Sciences, University of Manchester, Manchester, United Kingdom; Department of Computer Science and Sheffield Institute for Translational Neuroscience, University of Sheffield, Sheffield, United Kingdom","Durrande, N., Institut Fayol-LIMOS, Mines Saint-étienne, Saint-étienne, France; Hensman, J., CHICAS, Faculty of Health and Medicine, Lancaster University, Lancaster, United Kingdom; Rattray, M., Faculty of Life Sciences, University of Manchester, Manchester, United Kingdom; Lawrence, N.D., Department of Computer Science and Sheffield Institute for Translational Neuroscience, University of Sheffield, Sheffield, United Kingdom","We consider the problem of detecting and quantifying the periodic component of a function given noise-corrupted observations of a limited number of input/output tuples. Our approach is based on Gaussian process regression, which provides a flexible non-parametric framework for modelling periodic data. We introduce a novel decomposition of the covariance function as the sum of periodic and aperiodic kernels. This decomposition allows for the creation of sub-models which capture the periodic nature of the signal and its complement. To quantify the periodicity of the signal, we derive a periodicity ratio which reflects the uncertainty in the fitted sub-models. Although the method can be applied to many kernels, we give a special emphasis to the Matérn family, from the expression of the reproducing kernel Hilbert space inner product to the implementation of the associated periodic kernels in a Gaussian process toolkit. The proposed method is illustrated by considering the detection of periodically expressed genes in the arabidopsis genome. © 2016 Durrande et al.","Circadian rhythm; Gene expression; Harmonic analysis; Matérn kernels; RKHS",,"Durrande, N.; Institut Fayol-LIMOS, Mines Saint-étienneFrance; email: durrande@emse.fr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030130321
"MacDonald A.","PhilDB: The time series database with built-in change logging",2016,"PeerJ Computer Science","2016","3", e52,"","",,1,10.7717/peerj-cs.52,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030120298&doi=10.7717%2fpeerj-cs.52&partnerID=40&md5=5ab76f125c229d770d28a097a1b0e427","Melbourne Victoria, Australia","MacDonald, A., Melbourne Victoria, Australia","PhilDB is an open-source time series database that supports storage of time series datasets that are dynamic; that is, it records updates to existing values in a log as they occur. PhilDB eases loading of data for the user by utilising an intelligent data write method. It preserves existing values during updates and abstracts the update complexity required to achieve logging of data value changes. It implements fast reads to make it practical to select data for analysis. Recent open-source systems have been developed to indefinitely store long-period high-resolution time series data without change logging. Unfortunately, such systems generally require a large initial installation investment before use because they are designed to operate over a cluster of servers to achieve high-performance writing of static data in real time. In essence, they have a 'big data' approach to storage and access.Other open-source projects for handling time series data that avoid the 'big data' approach are also relatively new and are complex or incomplete. None of these systems gracefully handle revision of existing data while tracking values that change. Unlike 'big data' solutions, PhilDB has been designed for single machine deployment on commodity hardware, reducing the barrier to deployment. PhilDB takes a unique approach to meta-data tracking; optional attribute attachment. This facilitates scaling the complexities of storing a wide variety of data. That is, it allows time series data to be loaded as time series instances with minimal initial meta-data, yet additional attributes can be created and attached to differentiate the time series instances when a wider variety of data is needed. PhilDB was written in Python, leveraging existing libraries. While some existing systems come close to meeting the needs PhilDB addresses, none cover all the needs at once. PhilDB was written to fill this gap in existing solutions. This paper explores existing time series database solutions, discusses the motivation for PhilDB, describes the architecture and philosophy of the PhilDB software, and performs an evaluation between InfluxDB, PhilDB, and SciDB. © 2016 MacDonald.","Data science; Database; Logging; Python; Temporal; Time series",,"MacDonald, A.; Melbourne VictoriaAustralia; email: andrew@maccas.net",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030120298
"Dow E.M.","Decomposed multi-objective bin-packing for virtual machine consolidation",2016,"PeerJ Computer Science","2016","2", e47,"","",,1,10.7717/peerj-cs.47,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013687075&doi=10.7717%2fpeerj-cs.47&partnerID=40&md5=5d072a82bb92b4cad4e79b3eb3e05681","Industries and Solutions, IBM Research, Yorktown Heights, NY, United States; Department of Interdisciplinary Engineering Science, Clarkson University, Potsdam, NY, United States","Dow, E.M., Industries and Solutions, IBM Research, Yorktown Heights, NY, United States, Department of Interdisciplinary Engineering Science, Clarkson University, Potsdam, NY, United States","In this paper, we describe a novel solution to the problem of virtual machine (VM) consolidation, otherwise known as VM-Packing, as applicable to Infrastructure-as- a-Service cloud data centers. Our solution relies on the observation that virtual ma- chines are not infinitely variable in resource consumption. Generally, cloud compute providers offer them in fixed resource allocations. Effectively this makes all VMs of that allocation type (or instance type) generally interchangeable for the purposes of consolidation from a cloud compute provider viewpoint. The main contribution of this work is to demonstrate the advantages to our approach of deconstructing the VM consolidation problem into a two-step process of multidimensional bin packing. The first step is to determine the optimal, but abstract, solution composed of finite groups of equivalent VMs that should reside on each host. The second step selects concrete VMs from the managed compute pool to satisfy the optimal abstract solution while enforcing anti-colocation and preferential colocation of the virtual machines through VM contracts. We demonstrate our high-performance, deterministic packing solution generation, with over 7,500 VMs packed in under 2 min. We demonstrating compara- ble runtimes to other VM management solutions published in the literature allowing for favorable extrapolations of the prior work in the field in order to deal with larger VM management problem sizes our solution scales to. © 2016 Dow.","Consolidation; IaaS; Virtual machine management",,"Dow, E.M.; Industries and Solutions, IBM ResearchUnited States; email: emdow@us.ibm.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85013687075
"Julian Zubek, Plewczynski D.M.","Complexity curve: A graphical measure of data complexity and classifier performance",2016,"PeerJ Computer Science","2016","8", e76,"","",,1,10.7717/peerj-cs.76,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030106837&doi=10.7717%2fpeerj-cs.76&partnerID=40&md5=cf58860a2b420c6ff93cb9f1060d2779","Centre of New Technologies, University of Warsaw, Warsaw, Poland; Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland","Julian Zubek, Centre of New Technologies, University of Warsaw, Warsaw, Poland, Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland; Plewczynski, D.M., Centre of New Technologies, University of Warsaw, Warsaw, Poland","We describe a method for assessing data set complexity based on the estimation of the underlining probability distribution and Hellinger distance. In contrast to some popular complexity measures, it is not focused on the shape of a decision boundary in a classification task but on the amount of available data with respect to the attribute structure. Complexity is expressed in terms of graphical plot, which we call complexity curve. It demonstrates the relative increase of available information with the growth of sample size. We perform theoretical and experimental examination of properties of the introduced complexity measure and show its relation to the variance component of classification error. We then compare it with popular data complexity measures on 81 diverse data sets and show that it can contribute to explaining performance of specific classifiers on these sets. We also apply our methodology to a panel of simple benchmark data sets, demonstrating how it can be used in practice to gain insights into data characteristics. Moreover, we show that the complexity curve is an effective tool for reducing the size of the training set (data pruning), allowing to significantly speed up the learning process without compromising classification accuracy. The associated code is available to download at: https://github.com/zubekj/complexity_curve (open source Python implementation). © 2016 Zubek and Plewczynski.","Bias-variance decomposition; Data complexity; Data pruning; Hellinger distance; Learning curves; Performance measures",,"Plewczynski, D.M.; Centre of New Technologies, University of WarsawPoland; email: dariuszplewczynski@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030106837
"Zhang W., Higham N.J.","Matrix Depot: An extensible test matrix collection for Julia",2016,"PeerJ Computer Science","2016","4", e58,"","",,1,10.7717/peerj-cs.58,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025704567&doi=10.7717%2fpeerj-cs.58&partnerID=40&md5=6bd9b333d02f03d0603cbde60c43c619","School of Mathematics, University of Manchester, Manchester, United Kingdom","Zhang, W., School of Mathematics, University of Manchester, Manchester, United Kingdom; Higham, N.J., School of Mathematics, University of Manchester, Manchester, United Kingdom","Matrix Depot is a Julia software package that provides easy access to a large and diverse collection of test matrices. Its novelty is threefold. First, it is extensible by the user, and so can be adapted to include the user's own test problems. In doing so, it facilitates experimentation and makes it easier to carry out reproducible research. Second, it amalgamates in a single framework two different types of existing matrix collections, comprising parametrized test matrices (including Hansen's set of regularization test problems and Higham's Test Matrix Toolbox) and real-life sparse matrix data (giving access to the University of Florida sparse matrix collection). Third, it fully exploits the Julia language. It uses multiple dispatch to help provide a simple interface and, in particular, to allow matrices to be generated in any of the numeric data types supported by the language. © 2016 Zhang and Higham.","Julia; Matrix algorithm; Software package; Test matrices; Test problems",,"Higham, N.J.; School of Mathematics, University of ManchesterUnited Kingdom; email: nick.higham@manchester.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85025704567
"Zhang C., Chen Y., Li C.","TCP adaptation with network coding and opportunistic data forwarding in multi-hop wireless networks",2016,"PeerJ Computer Science","2016","10", e89,"","",,1,10.7717/peerj-cs.89,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030124797&doi=10.7717%2fpeerj-cs.89&partnerID=40&md5=02867a85b743b02c93dbe82751dfa702","Department of Computer Science, Memorial University of Newfoundland, St John's, Canada; Department of Electrical and Computer Engineering, Memorial University of Newfoundland, St John's, Canada","Zhang, C., Department of Computer Science, Memorial University of Newfoundland, St John's, Canada; Chen, Y., Department of Computer Science, Memorial University of Newfoundland, St John's, Canada; Li, C., Department of Electrical and Computer Engineering, Memorial University of Newfoundland, St John's, Canada","Opportunistic data forwarding significantly increases the throughput in multi-hop wireless mesh networks by utilizing the broadcast nature of wireless transmissions and the fluctuation of link qualities. Network coding strengthens the robustness of data transmissions over unreliable wireless links. However, opportunistic data forwarding and network coding are rarely incorporated with TCP because the frequent occurrences of out-of-order packets in opportunistic data forwarding and long decoding delay in network coding overthrow TCP's congestion control. In this paper, we propose a solution dubbed TCPFender, which supports opportunistic data forwarding and network coding in TCP. Our solution adds an adaptation layer to mask the packet loss caused by wireless link errors and provides early positive feedbacks to trigger a larger congestion window for TCP. This adaptation layer functions over the network layer and reduces the delay of ACKs for each coded packet. The simulation results show that TCPFender significantly outperforms TCP/IP in terms of the network throughput in different topologies of wireless networks. © 2016 Zhang et al.","Multi-hop wireless networks; Network coding; Opportunistic data forwarding; TCP",,"Zhang, C.; Department of Computer Science, Memorial University of NewfoundlandCanada; email: cz5670@mun.ca",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030124797
"Maskeliunas R., Raudonis V.","Are you ashamed? Can a gaze tracker tell?",2016,"PeerJ Computer Science","2016","8", e75,"","",,1,10.7717/peerj-cs.75,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101636&doi=10.7717%2fpeerj-cs.75&partnerID=40&md5=2ba723a120df16889eb1878c5c6d399c","Department of Multimedia Engineering, Faculty of Informatics, Kaunas University of Technology, Kaunas, Lithuania; Department of Automation, Faculty of Electrical and Electronics Engineering, Kaunas University of Technology, Kaunas, Lithuania","Maskeliunas, R., Department of Multimedia Engineering, Faculty of Informatics, Kaunas University of Technology, Kaunas, Lithuania; Raudonis, V., Department of Automation, Faculty of Electrical and Electronics Engineering, Kaunas University of Technology, Kaunas, Lithuania","Our aim was to determine the possibility of detecting cognitive emotion information (neutral, disgust, shameful, ""sensory pleasure"") by using a remote eye tracker within an approximate range of 1 meter. Our implementation was based on a self-learning ANN used for profile building, emotion status identification and recognition. Participants of the experiment were provoked with audiovisual stimuli (videos with sounds) to measure the emotional feedback. The proposed system was able to classify each felt emotion with an average of 90% accuracy (2 second measuring interval). © 2016 Maskeliunas and Raudonis.","Cognitive; Emotions; Gaze-tracking; Recognition",,"Maskeliunas, R.; Department of Multimedia Engineering, Faculty of Informatics, Kaunas University of TechnologyLithuania; email: rytis.maskeliunas@ktu.lt",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030101636
"Habich M., Djuranovic S., Szczesny P.","PATACSDB-the database of polyA translational attenuators in coding sequences",2016,"PeerJ Computer Science","2016","2", e45,"","",,1,10.7717/peerj-cs.45,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026275709&doi=10.7717%2fpeerj-cs.45&partnerID=40&md5=4b1b680e0f018db0e3f12b85e8c24891","Institute of Biochemistry and Biophysics Polish Academy of Sciences, Department of Bioinformatics, Warsaw, Poland; Department of Cell Biology and Physiology, Washington University School of Medicine, Saint Louis, MO, United States; Faculty of Biology, Institute of Experimental Plant Biology and Biotechnology, University ofWarsaw, Warsaw, Poland","Habich, M., Institute of Biochemistry and Biophysics Polish Academy of Sciences, Department of Bioinformatics, Warsaw, Poland; Djuranovic, S., Department of Cell Biology and Physiology, Washington University School of Medicine, Saint Louis, MO, United States; Szczesny, P., Institute of Biochemistry and Biophysics Polish Academy of Sciences, Department of Bioinformatics, Warsaw, Poland, Faculty of Biology, Institute of Experimental Plant Biology and Biotechnology, University ofWarsaw, Warsaw, Poland","Recent additions to the repertoire of gene expression regulatory mechanisms are polyadenylate (polyA) tracks encoding for poly-lysine runs in protein sequences. Such tracks stall the translation apparatus and induce frameshifting independently of the effects of charged nascent poly-lysine sequence on the ribosome exit channel. As such, they substantially influence the stability of mRNA and the amount of protein produced from a given transcript. Single base changes in these regions are enough to exert a measurable response on both protein and mRNA abundance; this makes each of these sequences a potentially interesting case study for the effects of synonymous mutation, gene dosage balance and natural frameshifting. Here we present PATACSDB, a resource that contain a comprehensive list of polyA tracks from over 250 eukaryotic genomes. Our data is based on the Ensembl genomic database of coding sequences and filtered with algorithm of 12A-1 which selects sequences of polyA tracks with a minimal length of 12 A's allowing for one mismatched base. The PATACSDB database is accessible at: http://sysbio.ibb.waw.pl/patacsdb. The source code is available at http://github.com/habich/PATACSDB, and it includes the scripts with which the database can be recreated. © 2016 Habich et al.","Eukaryotic genomes; Gene regulation; mRNA stability; Ribosome stalling; Translation",,"Szczesny, P.; Institute of Biochemistry and Biophysics Polish Academy of Sciences, Department of BioinformaticsPoland; email: szczesny@ibb.waw.pl",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85026275709
"Tamary J., Feitelson D.G.","The rise of chrome",2015,"PeerJ Computer Science","2015","10", e28,"","",,1,10.7717/peerj-cs.28,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027391989&doi=10.7717%2fpeerj-cs.28&partnerID=40&md5=df14cb06fe7cfea1836b86c9bb3fee82","The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel","Tamary, J., The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel; Feitelson, D.G., The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel","Since Chrome's initial release in 2008 it has grown in market share, and now controls roughly half of the desktop browsers market. In contrast with Internet Explorer, the previous dominant browser, this was not achieved by marketing practices such as bundling the browser with a pre-loaded operating system. This raises the question of how Chrome achieved this remarkable feat, while other browsers such as Firefox and Opera were left behind.We show that both the performance of Chrome and its conformance with relevant standards are typically better than those of the two main contending browsers, Internet Explorer and Firefox. In addition, based on a survey of the importance of 25 major features, Chrome product managers seem to have made somewhat better decisions in selecting where to put effort. Thus the rise of Chrome is consistent with technical superiority over the competition. © 2015 Tamary and Feitelson.","Benchmark results; Feature selection; Google chrome; Market share; Web browser","Commerce; Competition; Feature extraction; Marketing; Firefox; Google chrome; Internet explorers; Market share; Product manager; Web browsers","Feitelson, D.G.; The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of JerusalemIsrael; email: feit@cs.huji.ac.il",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85027391989
"Billiet L., Van Huffel S., Van Belle V.","Interval Coded Scoring: A toolbox for interpretable scoring systems",2018,"PeerJ Computer Science","2018","4", e150,"","",,,10.7717/peerj-cs.150,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045052706&doi=10.7717%2fpeerj-cs.150&partnerID=40&md5=1d4332b53e6c5f4f8b4bae99e25caf81","STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Department of Electrical Engineering (ESAT), KU Leuven, Leuven, Belgium; imec, Leuven, Belgium","Billiet, L., STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Department of Electrical Engineering (ESAT), KU Leuven, Leuven, Belgium, imec, Leuven, Belgium; Van Huffel, S., STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Department of Electrical Engineering (ESAT), KU Leuven, Leuven, Belgium, imec, Leuven, Belgium; Van Belle, V., STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Department of Electrical Engineering (ESAT), KU Leuven, Leuven, Belgium","Over the last decades, clinical decision support systems have been gaining importance. They help clinicians to make effective use of the overload of available information to obtain correct diagnoses and appropriate treatments. However, their power often comes at the cost of a black box model which cannot be interpreted easily. This interpretability is of paramount importance in a medical setting with regard to trust and (legal) responsibility. In contrast, existing medical scoring systems are easy to understand and use, but they are often a simplified rule-of-thumb summary of previous medical experience rather than a well-founded system based on available data. Interval Coded Scoring (ICS) connects these two approaches, exploiting the power of sparse optimization to derive scoring systems from training data. The presented toolbox interface makes this theory easily applicable to both small and large datasets. It contains two possible problem formulations based on linear programming or elastic net. Both allow to construct a model for a binary classification problem and establish risk profiles that can be used for future diagnosis. All of this requires only a few lines of code. ICS differs from standard machine learning through its model consisting of interpretable main effects and interactions. Furthermore, insertion of expert knowledge is possible because the training can be semi-automatic. This allows end users to make a tradeoff between complexity and performance based on cross-validation results and expert knowledge. Additionally, the toolbox offers an accessible way to assess classification performance via accuracy and the ROC curve, whereas the calibration of the risk profile can be evaluated via a calibration curve. Finally, the colour-coded model visualization has particular appeal if one wants to apply ICS manually on new observations, as well as for validation by experts in the specific application domains. The validity and applicability of the toolbox is demonstrated by comparing it to standard Machine Learning approaches such as Naive Bayes and Support Vector Machines for several reallife datasets. These case studies on medical problems show its applicability as a decision support system. ICS performs similarly in terms of classification and calibration. Its slightly lower performance is countered by its model simplicity which makes it the method of choice if interpretability is a key issue. © 2018 Billiet et al.","Classification; Decision support; Interpretability; Risk assessment; Scoring systems; Sparse optimization; Toolbox","Artificial intelligence; Calibration; Classification (of information); Computer aided diagnosis; Decision support systems; Learning systems; Linear programming; Medical problems; Risk assessment; Decision supports; Interpretability; Scoring systems; Sparse optimizations; Toolbox; Intelligent control","Billiet, L.; STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Department of Electrical Engineering (ESAT), KU LeuvenBelgium; email: lieven.billiet@esat.kuleuven.be",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85045052706
"Fernique P., Pradal C.","Auto WIG: Automatic generation of python bindings for C++ libraries",2018,"PeerJ Computer Science","2018","4", e149,"","",,,10.7717/peerj-cs.149,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045052866&doi=10.7717%2fpeerj-cs.149&partnerID=40&md5=c329ce32df4e5ad234b6d4f11ad45980","EPI Virtual Plants, Inria, Montpellier, France; AGAP, CIRAD, INRA, Montpellier SupAgro, Univ Montpellier, Montpellier, France","Fernique, P., EPI Virtual Plants, Inria, Montpellier, France, AGAP, CIRAD, INRA, Montpellier SupAgro, Univ Montpellier, Montpellier, France; Pradal, C., EPI Virtual Plants, Inria, Montpellier, France, AGAP, CIRAD, INRA, Montpellier SupAgro, Univ Montpellier, Montpellier, France","Most of Python and R scientific packages incorporate compiled scientific libraries to speed up the code and reuse legacy libraries. While several semi-automatic solutions exist to wrap these compiled libraries, the process of wrapping a large library is cumbersome and time consuming. In this paper, we introduce AutoWIG, a Python package that wraps automatically compiled libraries into high-level languages using LLVM/Clang technologies and the Mako templating engine. Our approach is automatic, extensible, and applies to complex C++ libraries, composed of thousands of classes or incorporating modern meta-programming constructs. © 2018 Fernique and Pradal.","Automatic bindings generation; C++; Python","Cesium; Libraries; Object oriented programming; Automatic bindings generation; Automatic Generation; C++ libraries; Meta Programming; Python; Semi-automatics; Speed up; Templating; C++ (programming language)","Fernique, P.; EPI Virtual Plants, InriaFrance; email: pierre.fernique@inria.fr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85045052866
"Rocher T., Giraud M., Salson M.","Indexing labeled sequences",2018,"PeerJ Computer Science","2018","3", e148,"","",,,10.7717/peerj-cs.148,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045076280&doi=10.7717%2fpeerj-cs.148&partnerID=40&md5=0a5e55eb3c214cbdc3db21b3b188448a","Université de Lille, CNRS, Centrale Lille, Inria, UMR 9189 CRIStAL, Lille, France","Rocher, T., Université de Lille, CNRS, Centrale Lille, Inria, UMR 9189 CRIStAL, Lille, France; Giraud, M., Université de Lille, CNRS, Centrale Lille, Inria, UMR 9189 CRIStAL, Lille, France; Salson, M., Université de Lille, CNRS, Centrale Lille, Inria, UMR 9189 CRIStAL, Lille, France","Background: Labels are a way to add some information on a text, such as functional annotations such as genes on a DNA sequences. V(D)J recombinations are DNA recombinations involving two or three short genes in lymphocytes. Sequencing this short region (500 bp or less) produces labeled sequences and brings insight in the lymphocyte repertoire for onco-hematology or immunology studies. Methods: We present two indexes for a text with non-overlapping labels. They store the text in a Burrows-Wheeler transform (BWT) and a compressed label sequence in a Wavelet Tree. The label sequence is taken in the order of the text (TL-index) or in the order of the BWT (TLBW-index). Both indexes need a space related to the entropy of the labeled text. Results: These indexes allow efficient text-label queries to count and find labeled patterns. The TLBW-index has an overhead on simple label queries but is very efficient on combined pattern-label queries.We implemented the indexes in C++ and compared them against a baseline solution on pseudo-random as well as on V(D)J labeled texts. Discussion: New indexes such as the ones we proposed improve the way we index and query labeled texts as, for instance, lymphocyte repertoire for hematological and immunological studies. © 2018 Rocher et al.","Burrows-Wheeler transform; Data structures; Text indexing; V(D)J recombination; Wavelet Tree","Backward wave tubes; Data structures; Forestry; Genes; Indexing (of information); Lymphocytes; Trees (mathematics); Wavelet transforms; Burrows Wheeler transform; DNA recombination; Functional annotation; Lymphocyte repertoires; Pseudo random; Text labels; Text-indexing; Wavelet tree; DNA sequences","Giraud, M.; Université de Lille, CNRS, Centrale Lille, Inria, UMR 9189 CRIStALFrance; email: mathieu.giraud@univ-lille.fr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85045076280
"Lee J., Muñoz M., Fridman L., Victor T., Reimer B., Mehler B.","Investigating the correspondence between driver head position and glance location",2018,"PeerJ Computer Science","2018","2", e146,"","",,,10.7717/peerj-cs.146,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043402342&doi=10.7717%2fpeerj-cs.146&partnerID=40&md5=fad4facb3f707d307cc4be8b05b53ccf","AgeLab and New England University Transportation Center, Massachusetts Institute of Technology, Cambridge, MA, United States; Technical University of Munich, Munich, Germany; University of Augsburg, Augsburg, Germany; SAFER Vehicle and Traffic Safety Center, Chalmers, Göteborg, Sweden","Lee, J., AgeLab and New England University Transportation Center, Massachusetts Institute of Technology, Cambridge, MA, United States; Muñoz, M., AgeLab and New England University Transportation Center, Massachusetts Institute of Technology, Cambridge, MA, United States, Technical University of Munich, Munich, Germany, University of Augsburg, Augsburg, Germany; Fridman, L., AgeLab and New England University Transportation Center, Massachusetts Institute of Technology, Cambridge, MA, United States; Victor, T., SAFER Vehicle and Traffic Safety Center, Chalmers, Göteborg, Sweden; Reimer, B., AgeLab and New England University Transportation Center, Massachusetts Institute of Technology, Cambridge, MA, United States; Mehler, B., AgeLab and New England University Transportation Center, Massachusetts Institute of Technology, Cambridge, MA, United States","The relationship between a driver's glance orientation and corresponding head rotation is highly complex due to its nonlinear dependence on the individual, task, and driving context. This paper presents expanded analytic detail and findings from an effort that explored the ability of head pose to serve as an estimator for driver gaze by connecting head rotation data with manually coded gaze region data using both a statistical analysis approach and a predictive (i.e., machine learning) approach. For the latter, classification accuracy increased as visual angles between two glance locations increased. In other words, the greater the shift in gaze, the higher the accuracy of classification. This is an intuitive but important concept that we make explicit through our analysis. The highest accuracy achieved was 83% using the method of Hidden Markov Models (HMM) for the binary gaze classification problem of (a) glances to the forward roadway versus (b) glances to the center stack. Results suggest that although there are individual differences in head-glance correspondence while driving, classifier models based on head-rotation data may be robust to these differences and therefore can serve as reasonable estimators for glance location. The results suggest that driver head pose can be used as a surrogate for eye gaze in several key conditions including the identification of high-eccentricity glances. Inexpensive driver head pose tracking may be a key element in detection systems developed to mitigate driver distraction and inattention. © 2018 Lee et al.","Driver distraction; Glance classification; Head movements; Head-glance correspondence","Learning systems; Location; Markov processes; Accuracy of classifications; Classification accuracy; Driver distractions; Head movements; Head-glance correspondence; Head-pose tracking; Individual Differences; Nonlinear dependence; Hidden Markov models","Lee, J.; AgeLab and New England University Transportation Center, Massachusetts Institute of TechnologyUnited States; email: joonbum@mit.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85043402342
"Smith A.M., Niemeyer K.E., Katz D.S., Barba L.A., Githinji G., Gymrek M., Huff K.D., Madan C.R., Mayes A.C., Moerman K.M., Prins P., Ram K., Rokem A., Teal T.K., Guimera R.V., Vanderplas J.T.","Journal of Open Source Software (JOSS): Design and first-year review",2018,"PeerJ Computer Science","2018","2", e147,"","",,,10.7717/peerj-cs.147,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043392618&doi=10.7717%2fpeerj-cs.147&partnerID=40&md5=4130e15920cf9af83dcd6e549f064e21","Data Science Mission Office, Space Telescope Science Institute, Baltimore, MD, United States; School of Mechanical, Industrial and Manufacturing Engineering, Oregon State University, Corvallis, OR, United States; National Center for Supercomputing Applications, Department of Computer Science and Department of Electrical and Computer Engineering, School of Information Sciences, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Department of Mechanical and Aerospace Engineering, The George Washington University, Washington, DC, United States; KEMRI-Wellcome Trust Research Programme, Kilifi, Kenya; Departments of Medicine and Computer Science and Engineering, University of California, San Diego, La Jolla, CA, United States; Department of Nuclear, Plasma and Radiological Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States; School of Psychology, University of Nottingham, Nottingham, United Kingdom; Mozilla Foundation, Toronto, ON, Canada; MIT Media Lab, Massachusetts Institute of Technology, Cambridge, MA, United States; Trinity Centre for Bioengineering, Trinity College, The University of Dublin, Dublin, Ireland; University of Tennessee Health Science Center, Memphis, TN, United States; University Medical Centre Utrecht, Utrecht, Netherlands; Berkeley Institute for Data Science, University of California, Berkeley, CA, United States; eScience Institute, University of Washington, Seattle, WA, United States; Data Carpentry, Davis, CA, United States; University of Melbourne Centre for Cancer Research, University of Melbourne, Melbourne, Australia","Smith, A.M., Data Science Mission Office, Space Telescope Science Institute, Baltimore, MD, United States; Niemeyer, K.E., School of Mechanical, Industrial and Manufacturing Engineering, Oregon State University, Corvallis, OR, United States; Katz, D.S., National Center for Supercomputing Applications, Department of Computer Science and Department of Electrical and Computer Engineering, School of Information Sciences, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Barba, L.A., Department of Mechanical and Aerospace Engineering, The George Washington University, Washington, DC, United States; Githinji, G., KEMRI-Wellcome Trust Research Programme, Kilifi, Kenya; Gymrek, M., Departments of Medicine and Computer Science and Engineering, University of California, San Diego, La Jolla, CA, United States; Huff, K.D., Department of Nuclear, Plasma and Radiological Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Madan, C.R., School of Psychology, University of Nottingham, Nottingham, United Kingdom; Mayes, A.C., Mozilla Foundation, Toronto, ON, Canada; Moerman, K.M., MIT Media Lab, Massachusetts Institute of Technology, Cambridge, MA, United States, Trinity Centre for Bioengineering, Trinity College, The University of Dublin, Dublin, Ireland; Prins, P., University of Tennessee Health Science Center, Memphis, TN, United States, University Medical Centre Utrecht, Utrecht, Netherlands; Ram, K., Berkeley Institute for Data Science, University of California, Berkeley, CA, United States; Rokem, A., eScience Institute, University of Washington, Seattle, WA, United States; Teal, T.K., Data Carpentry, Davis, CA, United States; Guimera, R.V., University of Melbourne Centre for Cancer Research, University of Melbourne, Melbourne, Australia; Vanderplas, J.T., eScience Institute, University of Washington, Seattle, WA, United States","This article describes the motivation, design, and progress of the Journal of Open Source Software (JOSS). JOSS is a free and open-access journal that publishes articles describing research software. It has the dual goals of improving the quality of the software submitted and providing a mechanism for research software developers to receive credit. While designed to work within the current merit system of science, JOSS addresses the dearth of rewards for key contributions to science made in the form of software. JOSS publishes articles that encapsulate scholarship contained in the software itself, and its rigorous peer review targets the software components: functionality, documentation, tests, continuous integration, and the license. A JOSS article contains an abstract describing the purpose and functionality of the software, references, and a link to the software archive. The article is the entry point of a JOSS submission, which encompasses the full set of software artifacts. Submission and review proceed in the open, on GitHub. Editors, reviewers, and authors work collaboratively and openly. Unlike other journals, JOSS does not reject articles requiring major revision; while not yet accepted, articles remain visible and under review until the authors make adequate changes (or withdraw, if unable to meet requirements). Once an article is accepted, JOSS gives it a digital object identifier (DOI), deposits its metadata in Crossref, and the article can begin collecting citations on indexers like Google Scholar and other services. Authors retain copyright of their JOSS article, releasing it under a Creative Commons Attribution 4.0 International License. In its first year, starting in May 2016, JOSS published 111 articles, with more than 40 additional articles under review. JOSS is a sponsored project of the nonprofit organization NumFOCUS and is an affiliate of the Open Source Initiative (OSI). © 2018 Smith et al.","Code review; Computational research; Open-source software; Research software; Scholarly publishing; Software citation","Abstracting; Computer software; Open systems; Publishing; Reviews; Software engineering; Software testing; Code review; Computational researches; Continuous integrations; Non profit organizations; Open access journals; Open source initiatives; Scholarly publishing; Software developer; Open source software","Smith, A.M.; School of Mechanical, Industrial and Manufacturing Engineering, Oregon State UniversityUnited States; email: arfon@stsci.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85043392618
"Chard K., Dart E., Foster I., Shifflett D., Tuecke S., Williams J.","The Modern Research Data Portal: A design pattern for networked, data-intensive science",2018,"PeerJ Computer Science","2018","1", e144,"","",,,10.7717/peerj-cs.144,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041822660&doi=10.7717%2fpeerj-cs.144&partnerID=40&md5=61658368d9a753fbef7dc61ffd4a0135","University of Chicago, Chicago, IL, United States; Argonne National Laboratory, Lemont, IL, United States; Energy Sciences Network, Lawrence Berkeley National Laboratory, Berkeley, CA, United States","Chard, K., University of Chicago, Chicago, IL, United States, Argonne National Laboratory, Lemont, IL, United States; Dart, E., Energy Sciences Network, Lawrence Berkeley National Laboratory, Berkeley, CA, United States; Foster, I., University of Chicago, Chicago, IL, United States, Argonne National Laboratory, Lemont, IL, United States; Shifflett, D., University of Chicago, Chicago, IL, United States, Argonne National Laboratory, Lemont, IL, United States; Tuecke, S., University of Chicago, Chicago, IL, United States, Argonne National Laboratory, Lemont, IL, United States; Williams, J., University of Chicago, Chicago, IL, United States, Argonne National Laboratory, Lemont, IL, United States","We describe best practices for providing convenient, high-speed, secure access to large data via research data portals. We capture these best practices in a new design pattern, the Modern Research Data Portal, that disaggregates the traditional monolithic web-based data portal to achieve orders-of-magnitude increases in data transfer performance, support new deployment architectures that decouple control logic from data storage, and reduce development and operations costs. We introduce the design pattern; explain how it leverages high-performance data enclaves and cloud-based data management services; review representative examples at research laboratories and universities, including both experimental facilities and supercomputer sites; describe how to leverage Python APIs for authentication, authorization, data transfer, and data sharing; and use coding examples to demonstrate how these APIs can be used to implement a range of research data portal capabilities. Sample code at a companion web site, https://docs.globus.org/mrdp, provides application skeletons that readers can adapt to realize their own research data portals. © 2018 Chard et al.","Data transfer node; Globus; High-speed network; Portal; Science DMZ",,"Foster, I.; University of ChicagoUnited States; email: foster@anl.gov",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85041822660
"Bocher E., Ertz O.","A redesign of OGC Symbology Encoding standard for sharing cartography",2018,"PeerJ Computer Science","2018","1", e143,"","",,,10.7717/peerj-cs.143,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041736295&doi=10.7717%2fpeerj-cs.143&partnerID=40&md5=8fae88079321d7b1635e0e93b10720aa","CNRS, Lab-STICC Laboratory, UMR 6285, Vannes, France; Media Engineering Institute, HEIG-VD, University of Applied Sciences and Arts Western Switzerland, Yverdon-les-Bains, Vaud, Switzerland","Bocher, E., CNRS, Lab-STICC Laboratory, UMR 6285, Vannes, France; Ertz, O., Media Engineering Institute, HEIG-VD, University of Applied Sciences and Arts Western Switzerland, Yverdon-les-Bains, Vaud, Switzerland","Despite most Spatial Data Infrastructures offering service-based visualization of geospatial data, requirements are often at a very basic level leading to poor quality of maps. This is a general observation for any geospatial architecture as soon as open standards as those of the Open Geospatial Consortium (OGC) are applied. To improve the situation, this paper does focus on improvements at the portrayal interoperability side by considering standardization aspects. We propose two major redesign recommendations. First to consolidate the cartographic theory at the core of the OGC Symbology Encoding standard. Secondly to build the standard in a modular way so as to be ready to be extended with upcoming future cartographic requirements. Thus, we start by defining portrayal interoperability by means of typical-use cases that frame the concept of sharing cartography. Then we bring to light the strengths and limits of the relevant open standards to consider in this context. Finally we propose a set of recommendations to overcome the limits so as to make these use cases a true reality. Even if the definition of a cartographic-oriented standard is not able to act as a complete cartographic design framework by itself, we argue that pushing forward the standardization work dedicated to cartography is a way to share and disseminate good practices and finally to improve the quality of the visualizations. © 2018 Bocher and Ertz.","Cartography; Open Geospatial Consortium; Open standards; Portrayal interoperability; Spatial Data Infrastructure",,"Ertz, O.; Media Engineering Institute, HEIG-VD, University of Applied Sciences and Arts Western SwitzerlandSwitzerland; email: olivier.ertz@heig-vd.ch",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85041736295
"Alcaide D., Aerts J.","MCLEAN: Multilevel clustering exploration as network",2018,"PeerJ Computer Science","2018","1", e145,"","",,,10.7717/peerj-cs.145,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041851709&doi=10.7717%2fpeerj-cs.145&partnerID=40&md5=f3a5d191b6116009e5efb29639d55043","Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium; imec, KU Leuven, Leuven, Belgium","Alcaide, D., Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium; Aerts, J., imec, KU Leuven, Leuven, Belgium","Finding useful patterns in datasets has attracted considerable interest in the field of visual analytics. One of the most common tasks is the identification and representation of clusters. However, this is non-trivial in heterogeneous datasets since the data needs to be analyzed from different perspectives. Indeed, highly variable patterns may mask underlying trends in the dataset. Dendrograms are graphical representations resulting from agglomerative hierarchical clustering and provide a framework for viewing the clustering at different levels of detail. However, dendrograms become cluttered when the dataset gets large, and the single cut of the dendrogram to demarcate different clusters can be insufficient in heterogeneous datasets. In this work, we propose a visual analytics methodology called MCLEAN that offers a general approach for guiding the user through the exploration and detection of clusters. Powered by a graph- based transformation of the relational data, it supports a scalable environment for representation of heterogeneous datasets by changing the spatialization. We thereby combine multilevel representations of the clustered dataset with community finding algorithms. Our approach entails displaying the results of the heuristics to users, providing a setting from which to start the exploration and data analysis. To evaluate our proposed approach, we conduct a qualitative user study, where participants are asked to explore a heterogeneous dataset, comparing the results obtained by MCLEAN with the dendrogram. These qualitative results reveal that MCLEAN is an effective way of aiding users in the detection of clusters in heterogeneous datasets. The proposed methodology is implemented in an R package available at https://bitbucket.org/vda-lab/mclean. © 2018 Alcaide and Aerts.","Exploratory data analysis; Graph and network visualization; Hierarchical clustering; Visual analytics",,"Alcaide, D.; Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU LeuvenBelgium; email: daniel.alcaide@kuleuven.be",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85041851709
"Pataky T.C.","Power1D: A Python toolbox for numerical power estimates in experiments involving one-dimensional continua",2017,"PeerJ Computer Science","2017","7", e125,"","",,,10.7717/peerj-cs.125,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030163688&doi=10.7717%2fpeerj-cs.125&partnerID=40&md5=0ee64c41563cb7344c5f280e5390aaaf","Institute for Fiber Engineering, Shinshu University, Ueda, Japan","Pataky, T.C., Institute for Fiber Engineering, Shinshu University, Ueda, Japan","The unit of experimental measurement in a variety of scientific applications is the one-dimensional (1D) continuum: a dependent variable whose value is measured repeatedly, often at regular intervals, in time or space. A variety of software packages exist for computing continuum-level descriptive statistics and also for conducting continuum-level hypothesis testing, but very few offer power computing capabilities, where 'power' is the probability that an experiment will detect a true continuum signal given experimental noise. Moreover, no software package yet exists for arbitrary continuum-level signal/noise modeling. This paper describes a package called power1d which implements (a) two analytical 1D power solutions based on random field theory (RFT) and (b) a high-level framework for computational power analysis using arbitrary continuum-level signal/noise modeling. First power1d's two RFT-based analytical solutions are numerically validated using its random continuum generators. Second arbitrary signal/noise modeling is demonstrated to show how power1d can be used for flexible modeling well beyond the assumptions of RFT-based analytical solutions. Its computational demands are non-excessive, requiring on the order of only 30 s to execute on standard desktop computers, but with approximate solutions available much more rapidly. Its broad signal/noise modeling capabilities along with relatively rapid computations imply that power1d may be a useful tool for guiding experimentation involving multiple measurements of similar 1D continua, and in particular to ensure that an adequate number of measurements is made to detect assumed continuum signals. © 2017 Pataky.","Computational statistics; Data modeling; Gaussian random fields; Hypothesis testing; Random field theory; Time series",,"Pataky, T.C.; Institute for Fiber Engineering, Shinshu UniversityJapan; email: tpataky@shinshu-u.ac.jp",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030163688
"Contrino B., Miele E., Tomlinson R., Paola Castaldi M., Ricchiuto P.","DOSCHEDA: A web application for interactive chemoproteomics data analysis",2017,"PeerJ Computer Science","2017","8", e129,"","",,,10.7717/peerj-cs.129,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029829709&doi=10.7717%2fpeerj-cs.129&partnerID=40&md5=e9ff67df167d9533a3ebab3bf7dd3ff6","Department of Quantitative Biology, Discovery Sciences, AstraZeneca, Cambridge, United Kingdom; Department of Chemical Biology, Discovery Biology, Discovery Sciences, AstraZeneca, Waltham, MA, United States","Contrino, B., Department of Quantitative Biology, Discovery Sciences, AstraZeneca, Cambridge, United Kingdom; Miele, E., Department of Chemical Biology, Discovery Biology, Discovery Sciences, AstraZeneca, Waltham, MA, United States; Tomlinson, R., Department of Chemical Biology, Discovery Biology, Discovery Sciences, AstraZeneca, Waltham, MA, United States; Paola Castaldi, M., Department of Chemical Biology, Discovery Biology, Discovery Sciences, AstraZeneca, Waltham, MA, United States; Ricchiuto, P., Department of Quantitative Biology, Discovery Sciences, AstraZeneca, Cambridge, United Kingdom","Background. Mass Spectrometry (MS) based chemoproteomics has recently become a main tool to identify and quantify cellular target protein interactions with ligands/drugs in drug discovery. The complexity associated with these new types of data requires scientists with a limited computational background to perform systematic data quality controls as well as to visualize the results derived from the analysis to enable rapid decision making. To date, there are no readily accessible platforms specifically designed for chemoproteomics data analysis. Results. We developed a Shiny-based web application named DOSCHEDA (Down Stream Chemoproteomics Data Analysis) to assess the quality of chemoproteomics experiments, to filter peptide intensities based on linear correlations between replicates, and to perform statistical analysis based on the experimental design. In order to increase its accessibility, DOSCHEDA is designed to be used with minimal user input and it does not require programming knowledge. Typical inputs can be protein fold changes or peptide intensities obtained from Proteome Discover, MaxQuant or other similar software. DOSCHEDA aggregates results from bioinformatics analyses performed on the input dataset into a dynamic interface, it encompasses interactive graphics and enables customized output reports. Conclusions. DOSCHEDA is implemented entirely in R language. It can be launched by any system with R installed, including Windows, Mac OS and Linux distributions. DOSCHEDA is hosted on a shiny-server at https://doscheda.shinyapps.io/doscheda and is also available as a Bioconductor package (http://www.bioconductor.org/). © 2017 Contrino et al.","Drug dose-response; iTRAQ; Protein drug profiling; Proteomics; Quantitative chemical biology; Quantitative chemoproteomics; Shiny; Statistical models; TMT; Web interface",,"Ricchiuto, P.; Department of Quantitative Biology, Discovery Sciences, AstraZenecaUnited Kingdom; email: ricchiuto.piero@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85029829709
"Silva I.M., Moioli R.C.","A method for creating interactive, userresembling avatars",2017,"PeerJ Computer Science","2017","7", e128,"","",,,10.7717/peerj-cs.128,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030148296&doi=10.7717%2fpeerj-cs.128&partnerID=40&md5=aa25474d01dba9c878f8c5f838864c7b","Centro de Tecnologia, Universidade Federal do Rio Grande do Norte, Natal, Rio Grande do Norte, Brazil; Graduate Program in Neuroengineering, Edmond and Lily Safra International Institute of Neuroscience, Santos Dumont Institute, Macaiba, Rio Grande do Norte, Brazil","Silva, I.M., Centro de Tecnologia, Universidade Federal do Rio Grande do Norte, Natal, Rio Grande do Norte, Brazil, Graduate Program in Neuroengineering, Edmond and Lily Safra International Institute of Neuroscience, Santos Dumont Institute, Macaiba, Rio Grande do Norte, Brazil; Moioli, R.C., Graduate Program in Neuroengineering, Edmond and Lily Safra International Institute of Neuroscience, Santos Dumont Institute, Macaiba, Rio Grande do Norte, Brazil","Virtual reality (VR) applications have disseminated throughout several fields, with a special quest for immersion. The avatar is one of the key constituents of immersive applications, and avatar resemblance can provoke diverse emotional responses from the user. Yet a lot a virtual reality systems struggle to implement real life-like avatars. In this work, we propose a novel method for creating interactive, user-resembling avatars using available commercial hardware and software. Avatar visualization is possible with a point-cloud or a contiguous polygon surface, and avatar interactions with the virtual scenario happens through a body joint-approximation for contact. In addition, the implementation could be easily extended to other systems and its modular architecture admits improvement both on visualization and physical interactions. The code is under Apache License 2.0 and is freely available as Supplemental Information 1 in this article. © 2017 Macedo Silva and Moioli.","Avatar embodiment; Immersion; Kinect; Oculus rift; Virtual reality",,"Moioli, R.C.; Graduate Program in Neuroengineering, Edmond and Lily Safra International Institute of Neuroscience, Santos Dumont InstituteBrazil; email: moioli@isd.org.br",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030148296
"Konstantinidis K., Papadopoulos S., Kompatsiaris Y.","Exploring twitter communication dynamics with evolving community analysis",2017,"PeerJ Computer Science","2017","2", e107,"","",,,10.7717/peerj-cs.107,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030123727&doi=10.7717%2fpeerj-cs.107&partnerID=40&md5=fbad4bcb6b8546c9078948c3a2b574d1","Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece","Konstantinidis, K., Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece; Papadopoulos, S., Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece; Kompatsiaris, Y., Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece","Online Social Networks (OSNs) have been widely adopted as a means of news dissemination, event reporting, opinion expression and discussion. As a result, news and events are being constantly reported and discussed online through OSNs such as Twitter. However, the variety and scale of all the information renders manual analysis extremely cumbersome, and therefore creating a storyline for an event or news story is an effort-intensive task. The main challenge pertains to the magnitude of data to be analyzed. To this end, we propose a framework for ranking the resulting communities and their metadata on the basis of structural, contextual and evolutionary characteristics such as community centrality, textual entropy, persistence and stability. We apply the proposed framework on three Twitter datasets and demonstrate that the analysis that followed enables the extraction of new insights with respect to influential user accounts, topics of discussion and emerging trends. These insights could primarily assist the work of social and political analysis scientists and the work of journalists in their own story telling, but also highlight the limitations of existing analysis methods and pose new research questions. To our knowledge, this study is the first to investigate the ranking of dynamic communities. In addition, our findings suggest future work regarding the determination of the general context of the communities based on structure and evolutionary behavior alone. © 2017 Konstantinidis et al.","Community evolution detection; Community ranking; Data mining; Online social networks",,"Konstantinidis, K.; Information Technologies Institute, Centre for Research and Technology HellasGreece; email: konkonst@iti.gr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030123727
"Ramadani J., Wagner S.","Are suggestions from coupled file changes useful for perfective maintenance tasks?",2017,"PeerJ Computer Science","2017","10", e135,"","",,,10.7717/peerj-cs.135,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032722997&doi=10.7717%2fpeerj-cs.135&partnerID=40&md5=32db286f84cce2d7c9ed4e90fbd71320","Institute of Software Technology, University of Stuttgart, Stuttgart, Germany","Ramadani, J., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany; Wagner, S., Institute of Software Technology, University of Stuttgart, Stuttgart, Germany","Background. Software maintenance is an important activity in the development process where maintenance team members leave and new members join over time. The identification of files which are changed together frequently has been proposed several times. Yet, existing studies about coupled file changes ignore the feedback from developers as well as the impact of these changes on the performance of maintenance and rather these studies rely on the analysis findings and expert evaluation. Methods. We investigate the usefulness of coupled file changes during perfective maintenance tasks when developers are inexperienced in programming or when they were new on the project. Using data mining on software repositories we identify files that are changed most frequently together in the past. We extract coupled file changes from the Git repository of a Java software system and join them with corresponding attributes from the versioning and issue tracking system and the project documentation. We present a controlled experiment involving 36 student participants in which we investigate if coupled file change suggestions influence the correctness of the task solutions and the required time to complete them. Results. The results show that the use of coupled file change suggestions significantly increases the correctness of the solutions. However, there is only a minor effect on the time required to complete the perfective maintenance tasks. We also derived a set of the most useful attributes based on the developers' feedback. Discussion. Coupled file changes and a limited number of the proposed attributes are useful for inexperienced developers working on perfective maintenance tasks where although the developers using these suggestions solved more tasks, they still need time to understand and organize this information. © 2017 Ramadani and Wagner.","Coupled changes; Data mining; Git; Software repositories",,"Ramadani, J.; Institute of Software Technology, University of StuttgartGermany; email: jasmin.ramadani@informatik.unistuttgart.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85032722997
"Sateli B., Löffler F., König-Ries B., Witte R.","ScholarLens: Extracting competences from research publications for the automatic generation of semantic user profiles",2017,"PeerJ Computer Science","2017","7", e121,"","",,,10.7717/peerj-cs.121,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030097558&doi=10.7717%2fpeerj-cs.121&partnerID=40&md5=dd858ea8b2fdcf1f5031ef1c04f31f3f","Semantic Software Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Heinz-Nixdorf-Chair for Distributed Information Systems, Department of Mathematics and Computer Science, Friedrich Schiller University Jena, Jena, Germany","Sateli, B., Semantic Software Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Löffler, F., Heinz-Nixdorf-Chair for Distributed Information Systems, Department of Mathematics and Computer Science, Friedrich Schiller University Jena, Jena, Germany; König-Ries, B., Heinz-Nixdorf-Chair for Distributed Information Systems, Department of Mathematics and Computer Science, Friedrich Schiller University Jena, Jena, Germany; Witte, R., Semantic Software Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada","Motivation. Scientists increasingly rely on intelligent information systems to help them in their daily tasks, in particular for managing research objects, like publications or datasets. The relatively young research field of Semantic Publishing has been addressing the question how scientific applications can be improved through semantically rich representations of research objects, in order to facilitate their discovery and re-use. To complement the efforts in this area, we propose an automatic workflow to construct semantic user profiles of scholars, so that scholarly applications, like digital libraries or data repositories, can better understand their users' interests, tasks, and competences, by incorporating these user profiles in their design. To make the user profiles sharable across applications, we propose to build them based on standard semantic web technologies, in particular the Resource Description Framework (RDF) for representing user profiles and Linked Open Data (LOD) sources for representing competence topics. To avoid the cold start problem, we suggest to automatically populate these profiles by analyzing the publications (co-)authored by users, which we hypothesize reflect their research competences. Results. We developed a novel approach, ScholarLens, which can automatically generate semantic user profiles for authors of scholarly literature. For modeling the competences of scholarly users and groups, we surveyed a number of existing linked open data vocabularies. In accordance with the LOD best practices, we propose an RDF Schema (RDFS) based model for competence records that reuses existing vocabularies where appropriate. To automate the creation of semantic user profiles, we developed a complete, automated workflow that can generate semantic user profiles by analyzing full-text research articles through various natural language processing (NLP) techniques. In our method, we start by processing a set of research articles for a given user. Competences are derived by text mining the articles, including syntactic, semantic, and LOD entity linking steps. We then populate a knowledge base in RDF format with user profiles containing the extracted competences.We implemented our approach as an open source library and evaluated our system through two user studies, resulting in mean average precision (MAP) of up to 95%. As part of the evaluation, we also analyze the impact of semantic zoning of research articles on the accuracy of the resulting profiles. Finally, we demonstrate how these semantic user profiles can be applied in a number of use cases, including article ranking for personalized search and finding scientists competent in a topic -e.g., to find reviewers for a paper. Availability. All software and datasets presented in this paper are available under open source licenses in the supplements and documented at http://www.semanticsoftware. info/semantic-user-profiling-peerj-2016-supplements. Additionally, development releases of ScholarLens are available on our GitHub page: https://github.com/ SemanticSoftwareLab/ScholarLens. © 2017 Sateli et al.","Linked open data; Natural language processing; Scholarly user modeling; Semantic publishing; Semantic user profile",,"Sateli, B.; Semantic Software Lab, Department of Computer Science and Software Engineering, Concordia UniversityCanada; email: sateli@semanticsoftware.info",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030097558
"Schleicher J.M., Vögler M., Inzinger C., Dustdar S.","Modeling and management of usage-aware distributed datasets for global smart city application ecosystems",2017,"PeerJ Computer Science","2017","5", e115,"","",,,10.7717/peerj-cs.115,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030126307&doi=10.7717%2fpeerj-cs.115&partnerID=40&md5=633a676c1ae1b29f56e25c7c802e72e6","Distributed Systems Group, TU Wien, Vienna, Austria; Software Evolution and oArchitecture Lab, University of Zürich, Zürich, Switzerland","Schleicher, J.M., Distributed Systems Group, TU Wien, Vienna, Austria; Vögler, M., Distributed Systems Group, TU Wien, Vienna, Austria; Inzinger, C., Software Evolution and oArchitecture Lab, University of Zürich, Zürich, Switzerland; Dustdar, S., Distributed Systems Group, TU Wien, Vienna, Austria","The ever-growing amount of data produced by and in today's smart cities offers significant potential for novel applications created by city stakeholders as well as third parties. Current smart city application models mostly assume that data is exclusively managed by and bound to its original application and location. We argue that smart city data must not be constrained to such data silos so that future smart city applications can seamlessly access and integrate data from multiple sources across multiple cities. In this paper, we present a methodology and toolset to model available smart city data sources and enable efficient, distributed data access in smart city environments. We introduce a modeling abstraction to describe the structure and relevant properties, such as security and compliance constraints, of smart city data sources along with independently accessible subsets in a technology-agnostic way. Based on this abstraction, we present a middleware toolset for efficient and seamless data access through autonomous relocation of relevant subsets of available data sources to improve Quality of Service for smart city applications based on a configurable mechanism. We evaluate our approach using a case study in the context of a distributed city infrastructure decision support system and show that selective relocation of data subsets can significantly reduce application response times. © 2017 Schleicher et al.","Data management; Data migration; Quality of service; Smart city application engineering",,"Schleicher, J.M.; Distributed Systems Group, TU WienAustria; email: schleicher@dsg.tuwien.ac.at",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030126307
"Salatino A.A., Osborne F., Motta E.","How are topics born? Understanding the research dynamics preceding the emergence of new areas",2017,"PeerJ Computer Science","2017","6", e119,"","",,,10.7717/peerj-cs.119,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030148928&doi=10.7717%2fpeerj-cs.119&partnerID=40&md5=b390401248a9900f27fe45de21822be7","Knowledge Media Institute, The Open University, Milton Keynes, United Kingdom","Salatino, A.A., Knowledge Media Institute, The Open University, Milton Keynes, United Kingdom; Osborne, F., Knowledge Media Institute, The Open University, Milton Keynes, United Kingdom; Motta, E., Knowledge Media Institute, The Open University, Milton Keynes, United Kingdom","The ability to promptly recognise new research trends is strategic for many stakeholders, including universities, institutional funding bodies, academic publishers and companies. While the literature describes several approaches which aim to identify the emergence of new research topics early in their lifecycle, these rely on the assumption that the topic in question is already associated with a number of publications and consistently referred to by a community of researchers. Hence, detecting the emergence of a new research area at an embryonic stage, i.e., before the topic has been consistently labelled by a community of researchers and associated with a number of publications, is still an open challenge. In this paper, we begin to address this challenge by performing a study of the dynamics preceding the creation of new topics. This study indicates that the emergence of a new topic is anticipated by a significant increase in the pace of collaboration between relevant research areas, which can be seen as the 'parents' of the new topic. These initial findings (i) confirm our hypothesis that it is possible in principle to detect the emergence of a new topic at the embryonic stage, (ii) provide new empirical evidence supporting relevant theories in Philosophy of Science, and also (iii) suggest that new topics tend to emerge in an environment in which weakly interconnected research areas begin to cross-fertilise. © 2017 Salatino et al.","Digital libraries; Empirical study; Research trend detection; Scholarly data; Topic discovery; Topic emergence detection",,"Salatino, A.A.; Knowledge Media Institute, The Open UniversityUnited Kingdom; email: angelo.salatino@open.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030148928
"Leblanc-Latour M., Bryan C., Pelling A.E.","Utilizing social media and video games to control #DIY microscopes",2017,"PeerJ Computer Science","2017","12", e139,"","",,,10.7717/peerj-cs.139,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040172453&doi=10.7717%2fpeerj-cs.139&partnerID=40&md5=2625ed08de9c69af1019f600d0a15453","Department of Physics, University of Ottawa, Ottawa, ON, Canada; Department of Biology, University of Ottawa, Ottawa, ON, Canada; Institute for Science, Society and Policy, University of Ottawa, Ottawa, ON, Canada; SymbioticA and the School of Anatomy, Physiology and Human Biology, University of Western Australia, Perth, WA, Australia","Leblanc-Latour, M., Department of Physics, University of Ottawa, Ottawa, ON, Canada; Bryan, C., Department of Physics, University of Ottawa, Ottawa, ON, Canada; Pelling, A.E., Department of Physics, University of Ottawa, Ottawa, ON, Canada, Department of Biology, University of Ottawa, Ottawa, ON, Canada, Institute for Science, Society and Policy, University of Ottawa, Ottawa, ON, Canada, SymbioticA and the School of Anatomy, Physiology and Human Biology, University of Western Australia, Perth, WA, Australia","Open-source lab equipment is becoming more widespread with the popularization of fabrication tools such as 3D printers, laser cutters, CNC machines, open source microcontrollers and open source software. Although many pieces of common laboratory equipment have been developed, software control of these items is sometimes lacking. Specifically, control software that can be easily implemented and enable user-input and control over multiple platforms (PC, smartphone, web, etc.). The aim of this proof-of principle study was to develop and implement software for the control of a low-cost, 3D printed microscope. Here, we present two approaches which enable microscope control by exploiting the functionality of the social media platform Twitter or player actions inside of the videogame Minecraft. The microscope was constructed from a modified web-camera and implemented on a Raspberry Pi computer. Three aspects of microscope control were tested, including single image capture, focus control and time-lapse imaging. The Twitter embodiment enabled users to send `tweets' directly to the microscope. Image data acquired by the microscope was then returned to the user through a Twitter reply and stored permanently on the photo-sharing platform Flickr, along with any relevant metadata. Local control of the microscope was also implemented by utilizing the video game Minecraft, in situations where Internet connectivity is not present or stable. A virtual laboratory was constructed inside the Minecraft world and player actions inside the laboratory were linked to specific microscope functions. Here, we present the methodology and results of these experiments and discuss possible limitations and future extensions of this work. © 2017 Leblanc-Latour et al.","Do-It-Yourself; Flickr; Microscope; Open source; Raspberry Pi; Twitter",,"Pelling, A.E.; Department of Physics, University of OttawaCanada; email: a@pellinglab.net",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85040172453
"Burlet G., Hindle A.","Isolated guitar transcription using a deep belief network",2017,"PeerJ Computer Science","2017","3", e109,"","",,,10.7717/peerj-cs.109,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030088629&doi=10.7717%2fpeerj-cs.109&partnerID=40&md5=58be720e7c82d27e87768e9f6325f732","Department of Computing Science, University of Alberta, Edmonton, AB, Canada","Burlet, G., Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Hindle, A., Department of Computing Science, University of Alberta, Edmonton, AB, Canada","Music transcription involves the transformation of an audio recording to common music notation, colloquially referred to as sheet music. Manually transcribing audio recordings is a difficult and time-consuming process, even for experienced musicians. In response, several algorithms have been proposed to automatically analyze and transcribe the notes sounding in an audio recording; however, these algorithms are often general-purpose, attempting to process any number of instruments producing any number of notes sounding simultaneously. This paper presents a polyphonic transcription algorithm that is constrained to processing the audio output of a single instrument, specifically an acoustic guitar. The transcription system consists of a novel note pitch estimation algorithmthat uses a deep belief network andmulti-label learning techniques to generate multiple pitch estimates for each analysis frame of the input audio signal. Using a compiled dataset of synthesized guitar recordings for evaluation, the algorithmdescribed in this work results in an 11%increase in the f-measure of note transcriptions relative to Zhou et al.'s (2009) transcription algorithm in the literature. This paper demonstrates the effectiveness of deep, multi-label learning for the task of polyphonic transcription. © 2017 Burlet and Hindle.","Deep learning; Instrument transcription; Music information retrieval",,"Burlet, G.; Department of Computing Science, University of AlbertaCanada; email: gburlet@ualberta.ca",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030088629
"Schreiber J.M., Noble W.S.","Finding the optimal Bayesian network given a constraint graph",2017,"PeerJ Computer Science","2017","7", e122,"","",,,10.7717/peerj-cs.122,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029880892&doi=10.7717%2fpeerj-cs.122&partnerID=40&md5=d9f1352e9246a0791f525c14ee51f074","Department of Computer Science, University of Washington, Seattle, WA, United States; Department of Genome Science, University of Washington, Seattle, WA, United States","Schreiber, J.M., Department of Computer Science, University of Washington, Seattle, WA, United States; Noble, W.S., Department of Genome Science, University of Washington, Seattle, WA, United States","Despite recent algorithmic improvements, learning the optimal structure of a Bayesian network from data is typically infeasible past a few dozen variables. Fortunately, domain knowledge can frequently be exploited to achieve dramatic computational savings, and in many cases domain knowledge can even make structure learning tractable. Several methods have previously been described for representing this type of structural prior knowledge, including global orderings, super-structures, and constraint rules. While super-structures and constraint rules are flexible in terms of what prior knowledge they can encode, they achieve savings in memory and computational time simply by avoiding considering invalid graphs. We introduce the concept of a ``constraint graph'' as an intuitive method for incorporating rich prior knowledge into the structure learning task. We describe how this graph can be used to reduce the memory cost and computational time required to find the optimal graph subject to the encoded constraints, beyond merely eliminating invalid graphs. In particular, we show that a constraint graph can break the structure learning task into independent subproblems even in the presence of cyclic prior knowledge. These subproblems are well suited to being solved in parallel on a single machine or distributed across many machines without excessive communication cost. © 2017 Schreiber and and Noble.","Bayesian network; Big data; Discrete optimization; Parallel processing; Structure learning",,"Schreiber, J.M.; Department of Computer Science, University of WashingtonUnited States; email: jmschr@cs.washington.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85029880892
"Fan R., Xu K., Zhao J.","A GPU-based solution for fast calculation of the betweenness centrality in large weighted networks",2017,"PeerJ Computer Science","2017","12", e140,"","",,,10.7717/peerj-cs.140,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042558197&doi=10.7717%2fpeerj-cs.140&partnerID=40&md5=9c47c73e3a86d2bd2ed717670bc3379c","State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; School of Economics and Management, Beihang University, Beijing, China","Fan, R., State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; Xu, K., State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; Zhao, J., School of Economics and Management, Beihang University, Beijing, China","Betweenness, a widely employed centrality measure in network science, is a decent proxy for investigating network loads and rankings. However, its extremely high computational cost greatly hinders its applicability in large networks. Although several parallel algorithms have been presented to reduce its calculation cost for unweighted networks, a fast solution for weighted networks, which are commonly encountered in many realistic applications, is still lacking. In this study, we develop an efficient parallel GPU-based approach to boost the calculation of the betweenness centrality (BC) for large weighted networks. We parallelize the traditional Dijkstra algorithm by selecting more than one frontier vertex each time and then inspecting the frontier vertices simultaneously. By combining the parallel SSSP algorithm with the parallel BC framework, our GPU-based betweenness algorithm achieves much better performance than its CPU counterparts. Moreover, to further improve performance, we integrate the work-efficient strategy, and to address the loadimbalance problem, we introduce a warp-centric technique, which assigns many threads rather than one to a single frontier vertex. Experiments on both realistic and synthetic networks demonstrate the efficiency of our solution, which achieves 2.9×to 8.44× speedups over the parallel CPU implementation. Our algorithm is open-source and free to the community; it is publicly available through https://dx.doi.org/10.6084/m9.figshare.4542405. Considering the pervasive deployment and declining price of GPUs in personal computers and servers, our solution will offer unprecedented opportunities for exploring betweenness-related problems and will motivate follow-up efforts in network science. © 2017 Fan et al.","Betweenness centrality; GPU computing; Parallel computing; Weighted networkss",,"Zhao, J.; School of Economics and Management, Beihang UniversityChina; email: jichang@buaa.edu.cn",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85042558197
"Kashfi P., Nilsson A., Feldt R.","Integrating user eXperience practices into software development processes: Implications of the UX characteristics",2017,"PeerJ Computer Science","2017","10", e130,"","",,,10.7717/peerj-cs.130,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032724085&doi=10.7717%2fpeerj-cs.130&partnerID=40&md5=293ff0c6c0e3c9ba004e6c33fa2cb513","Department of Computer Science and Engineering, Chalmers University of Technology and Gothenburg University, Gothenburg, Sweden","Kashfi, P., Department of Computer Science and Engineering, Chalmers University of Technology and Gothenburg University, Gothenburg, Sweden; Nilsson, A., Department of Computer Science and Engineering, Chalmers University of Technology and Gothenburg University, Gothenburg, Sweden; Feldt, R., Department of Computer Science and Engineering, Chalmers University of Technology and Gothenburg University, Gothenburg, Sweden","User eXperience (UX) is a key factor in the success of software systems. Many software companies face challenges in their work with UX. Existing research does not analyze UX practices and challenges in relation to other software quality characteristics or, in particular, in relation to usability. A better understanding of these challenges can help researchers and practitioners better address them in the future. In this empirical study, we have interviewed 17 practitioners with different backgrounds and occupations from eight software development companies. Their responses are coded, and analyzed with thematic analysis. We report eight themes of challenges that practitioners face in their work with UX. While some of these challenges partly overlap with those reported in existing literature about usability or other software quality characteristics, the participants of our study either view many of the challenges as unique to UX, or more severe in the case of UX. Although at a superficial level challenges of UX and other quality characteristics overlap, we differentiate these challenges at a deeper level through the five main characteristics of UX: subjective, holistic, dynamic, contextdependent and worthwhile. In particular, we identified that these characteristics have at least 20 implications (i.e. additional difficulties) for day-to-day work of practitioners. We found that 11 of these implications have been previously reported in literature. However, to the best of our knowledge, the remaining nine implications are unique to our study. These implications can explain why practitioners perceive the challenges to be more severe than for other quality characteristics. Most importantly, they can explain the industry's lopsided focus on the pragmatic aspect of UX. Our findings can be useful for researchers in identifying new and industry-relevant research areas and for practitioners to learn from empirically investigated challenges in UX work, and base their improvement efforts on such knowledge. Identifying and investigating the overlaps underlines the importance of these challenges, and can also help finding research areas not only for enhancing UX work but also software quality in general. It also makes it easier for practitioners to spot, better understand as well as find mitigation strategies for UX, through learning from past experiences and developments in the area of software quality. © 2017 Kashfiet al.","Non-functional requirements; Quality requirements; Software quality; Usability; User experience",,"Kashfi, P.; Department of Computer Science and Engineering, Chalmers University of Technology and Gothenburg UniversitySweden; email: pariya.kashfi@chalmers.se",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85032724085
"Xi J., Wang M., Li A.","DGPathinter: A novel model for identifying driver genes via knowledge-driven matrix factorization with prior knowledge from interactome and pathways",2017,"PeerJ Computer Science","2017","10", 133,"","",,,10.7717/peerj-cs.133,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032728865&doi=10.7717%2fpeerj-cs.133&partnerID=40&md5=dc12a69bf8af802834d4a842553367fc","School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Centers for Biomedical Engineering, University of Science and Technology of China, Hefei, China","Xi, J., School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Wang, M., School of Information Science and Technology, University of Science and Technology of China, Hefei, China, Centers for Biomedical Engineering, University of Science and Technology of China, Hefei, China; Li, A., School of Information Science and Technology, University of Science and Technology of China, Hefei, China, Centers for Biomedical Engineering, University of Science and Technology of China, Hefei, China","Cataloging mutated driver genes that confer a selective growth advantage for tumor cells from sporadic passenger mutations is a critical problem in cancer genomic research. Previous studies have reported that some driver genes are not highly frequently mutated and cannot be tested as statistically significant, which complicates the identification of driver genes. To address this issue, some existing approaches incorporate prior knowledge from an interactome to detect driver genes which may be dysregulated by interaction network context. However, altered operations of many pathways in cancer progression have been frequently observed, and prior knowledge from pathways is not exploited in the driver gene identification task. In this paper, we introduce a driver gene prioritization method called driver gene identification through pathway and interactome information (DGPathinter), which is based on knowledge-based matrix factorization model with prior knowledge from both interactome and pathways incorporated. When DGPathinter is applied on somatic mutation datasets of three types of cancers and evaluated by known driver genes, the prioritizing performances of DGPathinter are better than the existing interactome driven methods. The top ranked genes detected by DGPathinter are also significantly enriched for known driver genes. Moreover, most of the top ranked scored pathways given by DGPathinter are also cancer progressionassociated pathways. These results suggest that DGPathinter is a useful tool to identify potential driver genes. © 2017 Xi et al.","Bioinformatics; Data mining; Matrix factorization; Prior knowledge",,"Li, A.; School of Information Science and Technology, University of Science and Technology of ChinaChina; email: aoli@ustc.edu.cn",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85032728865
"Rougier N.P., Hinsen K., Alexandre F., Arildsen T., Barba L.A., C.Y.Benureau A., Brown C.T., deBuy P., Caglayan O., Davison A.P., Delsuc M., Detorakis G., Diem A.K., Drix D., Enel P., Girard B., Guest O., Hall M.G., Henriques R.N., Hinaut X., Jaron K.S., Khamassi M., Klein A., Manninen T., Marchesi P., McGlinn D., Metzner C., Petchey O., Plesser H.E., Poisot T., Ram K., Ram Y., Roesch E., Rossant C., Rostami V., Shifman A., Stachelek J., Stimberg M., Stollmeier F., Vaggi F., Viejo G., Vitay J., Vostinar A.E., Yurchak R., Zito T.","Sustainable computational science: The ReScience Initiative",2017,"PeerJ Computer Science","2017","12", e142,"","",,,10.7717/peerj-cs.142,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040188790&doi=10.7717%2fpeerj-cs.142&partnerID=40&md5=08ef49cf8330697d4d595f041a2e9268","INRIA Bordeaux Sud-Ouest, Talence, France; Centre de Biophysique Moléculaire UPR4301, CNRS, Orléans, France; Department of Electronic Systems, Technical Faculty of IT and Design, Aalborg University, Aalborg, Denmark; Department of Mechanical and Aerospace Engineering, The George Washington University, Washington, DC, United States; Department of Population Health and Reproduction, University of California Davis, Davis, CA, United States; Instituut voor Theoretische Fysica, KU Leuven, Leuven, Belgium; Laboratoire d'Informatique (LIUM), Le Mans University, Le Mans, France; UNIC FRE 3693, CNRS, Gif-sur-Yvette, France; Institut de Génétique et de Biologie Moléculaire et Cellulaire, Illkirch, France; Department of Cognitive Sciences, University of California Irvine, Irvine, CA, United States; Computational Engineering and Design, University of Southampton, Southampton, United Kingdom; Humboldt Universität zu Berlin, Berlin, Germany; Department of Neuroscience, Mount Sinai School of Medicine, New York, NY, United States; Institute of Intelligent Systems and Robotics, Sorbonne Universités - UPMC Univ Paris 06 - CNRS, Paris, France; Experimental Psychology, University College London, London,Greater London, United Kingdom; UCL Great Ormond St Institute of Child Health, London, United Kingdom; Champalimaud Centre for the Unknown, Champalimaud Neuroscience Program, Lisbon, Portugal; Department of Ecology and Evolution, University of Lausanne, Lausanne, Switzerland; Independent scholar, Enschede, Netherlands; BioMediTech Institute and Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland; Swammerdam Institute for Life Sciences, University of Amsterdam, Amsterdam, Netherlands; Department of Biology, College of Charleston, Charleston, SC, United States; Centre for Computer Science and Informatics Research, University of Hertfordshire, Hatfield, United Kingdom; Department of Evolutionary Biology and Environmental Studies, University of Zurich, Zurich, Switzerland; Faculty of Science and Technology, Norwegian University of Life Sciences, Aas, Norway; Département de Sciences Biologiques, Université de Montréal, Montréal, QC, Canada; Berkeley Institute for Data Science, University of California, Berkeley, CA, United States; Department of Biology, Stanford University, Stanford, CA, United States; Centre for Integrative Neuroscience, University of Reading, Reading, United Kingdom; Institute of Neurology, University College London, London, United Kingdom; Institute of Neuroscience and oMedicine, Juelich Forschungszentrum, Jülich, Germany; Department of Biology, University of Ottawa, Ottawa,Ontario, Canada; Department of Fisheries and Wildlife, Michigan State University, East LansingMI, United States; Sorbonne Universités/UPMC Univ Paris 06/INSERM/CNRS/Institut de la Vision, Paris, France; Max Planck Institute for Dynamics and Self-Organization, Göttingen,Lower Saxony, Germany; Amazon, Seattle, WA, United States; Department of Computer Science, Chemnitz University of Technology, Chemnitz,Saxony, Germany; Department of Computer Science, Grinnell College, Grinnell, IA, United States; Symerio, Palaiseau, France; Neural Information Processing Group, Eberhard Karls Universität Tübingen, Tübingen, Germany","Rougier, N.P., INRIA Bordeaux Sud-Ouest, Talence, France; Hinsen, K., Centre de Biophysique Moléculaire UPR4301, CNRS, Orléans, France; Alexandre, F., INRIA Bordeaux Sud-Ouest, Talence, France; Arildsen, T., Department of Electronic Systems, Technical Faculty of IT and Design, Aalborg University, Aalborg, Denmark; Barba, L.A., Department of Mechanical and Aerospace Engineering, The George Washington University, Washington, DC, United States; C.Y.Benureau, A., INRIA Bordeaux Sud-Ouest, Talence, France; Brown, C.T., Department of Population Health and Reproduction, University of California Davis, Davis, CA, United States; deBuy, P., Instituut voor Theoretische Fysica, KU Leuven, Leuven, Belgium; Caglayan, O., Laboratoire d'Informatique (LIUM), Le Mans University, Le Mans, France; Davison, A.P., UNIC FRE 3693, CNRS, Gif-sur-Yvette, France; Delsuc, M., Institut de Génétique et de Biologie Moléculaire et Cellulaire, Illkirch, France; Detorakis, G., Department of Cognitive Sciences, University of California Irvine, Irvine, CA, United States; Diem, A.K., Computational Engineering and Design, University of Southampton, Southampton, United Kingdom; Drix, D., Humboldt Universität zu Berlin, Berlin, Germany; Enel, P., Department of Neuroscience, Mount Sinai School of Medicine, New York, NY, United States; Girard, B., Institute of Intelligent Systems and Robotics, Sorbonne Universités - UPMC Univ Paris 06 - CNRS, Paris, France; Guest, O., Experimental Psychology, University College London, London,Greater London, United Kingdom; Hall, M.G., UCL Great Ormond St Institute of Child Health, London, United Kingdom; Henriques, R.N., Champalimaud Centre for the Unknown, Champalimaud Neuroscience Program, Lisbon, Portugal; Hinaut, X., INRIA Bordeaux Sud-Ouest, Talence, France; Jaron, K.S., Department of Ecology and Evolution, University of Lausanne, Lausanne, Switzerland; Khamassi, M., Institute of Intelligent Systems and Robotics, Sorbonne Universités - UPMC Univ Paris 06 - CNRS, Paris, France; Klein, A., Independent scholar, Enschede, Netherlands; Manninen, T., BioMediTech Institute and Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland; Marchesi, P., Swammerdam Institute for Life Sciences, University of Amsterdam, Amsterdam, Netherlands; McGlinn, D., Department of Biology, College of Charleston, Charleston, SC, United States; Metzner, C., Centre for Computer Science and Informatics Research, University of Hertfordshire, Hatfield, United Kingdom; Petchey, O., Department of Evolutionary Biology and Environmental Studies, University of Zurich, Zurich, Switzerland; Plesser, H.E., Faculty of Science and Technology, Norwegian University of Life Sciences, Aas, Norway; Poisot, T., Département de Sciences Biologiques, Université de Montréal, Montréal, QC, Canada; Ram, K., Berkeley Institute for Data Science, University of California, Berkeley, CA, United States; Ram, Y., Department of Biology, Stanford University, Stanford, CA, United States; Roesch, E., Centre for Integrative Neuroscience, University of Reading, Reading, United Kingdom; Rossant, C., Institute of Neurology, University College London, London, United Kingdom; Rostami, V., Institute of Neuroscience and oMedicine, Juelich Forschungszentrum, Jülich, Germany; Shifman, A., Department of Biology, University of Ottawa, Ottawa,Ontario, Canada; Stachelek, J., Department of Fisheries and Wildlife, Michigan State University, East LansingMI, United States; Stimberg, M., Sorbonne Universités/UPMC Univ Paris 06/INSERM/CNRS/Institut de la Vision, Paris, France; Stollmeier, F., Max Planck Institute for Dynamics and Self-Organization, Göttingen,Lower Saxony, Germany; Vaggi, F., Amazon, Seattle, WA, United States; Viejo, G., Institute of Intelligent Systems and Robotics, Sorbonne Universités - UPMC Univ Paris 06 - CNRS, Paris, France; Vitay, J., Department of Computer Science, Chemnitz University of Technology, Chemnitz,Saxony, Germany; Vostinar, A.E., Department of Computer Science, Grinnell College, Grinnell, IA, United States; Yurchak, R., Symerio, Palaiseau, France; Zito, T., Neural Information Processing Group, Eberhard Karls Universität Tübingen, Tübingen, Germany","Computer science offers a large set of tools for prototyping, writing, running, testing, validating, sharing and reproducing results; however, computational science lags behind. In the best case, authors may provide their source code as a compressed archive and they may feel confident their research is reproducible. But this is not exactly true. James Buckheit and David Donoho proposed more than two decades ago that an article about computational results is advertising, not scholarship. The actual scholarship is the full software environment, code, and data that produced the result. This impliesnew workflows, in particular in peer-reviews. Existing journals have been slow to adapt: source codes are rarely requested and are hardly ever actually executed to check that they produce the results advertised in the article. ReScience is a peer-reviewed journal that targets computational research and encourages the explicit replication of already published research, promoting new and open-source implementations in order to ensure that the original research can be replicated from its description. To achieve this goal, the whole publishing chain is radically different from other traditional scientific journals. ReScience resides on GitHub where each new implementation of a computational study is made available together with comments, explanations, and software tests. © 2017 Rougier et al.","Computational science; GitHub; Open peer-review; Open science; Publication; Replicable; Reproducible; Sustainable",,"Rougier, N.P.; INRIA Bordeaux Sud-OuestFrance; email: Nicolas.Rougier@inria.fr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85040188790
"Mitropoulos D., Spinellis D.","Fatal injection: A survey of modern code injection attack countermeasures",2017,"PeerJ Computer Science","2017","11", e136,"","",,,10.7717/peerj-cs.136,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036526235&doi=10.7717%2fpeerj-cs.136&partnerID=40&md5=d758faeb7922fee2484a95416e4eb275","Department of Management Science and Technology, Athens University of Economics and Business, Greece","Mitropoulos, D., Department of Management Science and Technology, Athens University of Economics and Business, Greece; Spinellis, D., Department of Management Science and Technology, Athens University of Economics and Business, Greece","With a code injection attack (CIA) an attacker can introduce malicious code into a computer program or system that fails to properly encode data that comes from an untrusted source. A CIA can have different forms depending on the execution context of the application and the location of the programming flaw that leads to the attack. Currently, CIAs are considered one of the most damaging classes of application attacks since they can severely affect an organisation's infrastructure and cause financial and reputational damage to it. In this paper we examine and categorize the countermeasures developed to detect the various attack forms. In particular, we identify two distinct categories. The first incorporates static program analysis tools used to eliminate flaws that can lead to such attacks during the development of the system. The second involves the use of dynamic detection safeguards that prevent code injection attacks while the system is in production mode. Our analysis is based on nonfunctional characteristics that are considered critical when creating security mechanisms. Such characteristics involve usability, overhead, implementation dependencies, false positives and false negatives. Our categorization and analysis can help both researchers and practitioners either to develop novel approaches, or use the appropriate mechanisms according to their needs. © 2017 Mitropoulos and Spinellis.","Application security; Code injection attacks; Countermeasures; Cross-site scripting; Dynamic prevention; Software vulnerabilities; Static analysis",,"Mitropoulos, D.; Department of Management Science and Technology, Athens University of Economics and BusinessGreece; email: dimitro@aueb.gr",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85036526235
"Peroni S., Osborne F., Iorio A.D., Nuzzolese A.G., Poggi F., Vitali F., Motta E.","Research Articles in Simplified HTML: A Web-first format for HTML-based scholarly articles",2017,"PeerJ Computer Science","2017","10", e132,"","",,,10.7717/peerj-cs.132,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032720922&doi=10.7717%2fpeerj-cs.132&partnerID=40&md5=058f47699039a7b72257e9fe4932eb7e","Digital and Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Knowledge Media Institute, Open University, Milton Keynes, United Kingdom; Semantic Technologies Laboratory, Institute of Cognitive Sciences and Technologies, Italian National Research Council, Rome, Italy","Peroni, S., Digital and Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Osborne, F., Knowledge Media Institute, Open University, Milton Keynes, United Kingdom; Iorio, A.D., Digital and Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Nuzzolese, A.G., Semantic Technologies Laboratory, Institute of Cognitive Sciences and Technologies, Italian National Research Council, Rome, Italy; Poggi, F., Digital and Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Vitali, F., Digital and Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Motta, E., Knowledge Media Institute, Open University, Milton Keynes, United Kingdom","Purpose. This paper introduces the Research Articles in Simplified HTML (or RASH), which is a Web-first format for writing HTML-based scholarly papers; it is accompanied by the RASH Framework, a set of tools for interacting with RASH-based articles. The paper also presents an evaluation that involved authors and reviewers of RASH articles submitted to the SAVE-SD 2015 and SAVE-SD 2016 workshops. Design. RASH has been developed aiming to: be easy to learn and use; share scholarly documents (and embedded semantic annotations) through the Web; support its adoption within the existing publishing workflow. Findings. The evaluation study confirmed that RASH is ready to be adopted in workshops, conferences, and journals and can be quickly learnt by researchers who are familiar with HTML. Research Limitations. The evaluation study also highlighted some issues in the adoption of RASH, and in general of HTML formats, especially by less technically savvy users. Moreover, additional tools are needed, e.g., for enabling additional conversions from/to existing formats such as OpenXML. Practical Implications. RASH (and its Framework) is another step towards enabling the definition of formal representations of the meaning of the content of an article, facilitating its automatic discovery, enabling its linking to semantically related articles, providing access to data within the article in actionable form, and allowing integration of data between papers. Social Implications. RASH addresses the intrinsic needs related to the various users of a scholarly article: researchers (focussing on its content), readers (experiencing new ways for browsing it), citizen scientists (reusing available data formally defined within it through semantic annotations), publishers (using the advantages of new technologies as envisioned by the Semantic Publishing movement). Value. RASH helps authors to focus on the organisation of their texts, supports them in the task of semantically enriching the content of articles, and leaves all the issues about validation, visualisation, conversion, and semantic data extraction to the various tools developed within its Framework. © 2017 Peroni et al.","Digital Publishing; Document conversion; RASH; Semantic Publishing; Semantic Web; XSLT",,"Peroni, S.; Digital and Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of BolognaItaly; email: silvio.peroni@unibo.it",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85032720922
"Ohori K.A., Ledoux H., Stoter J.","Visualising higher-dimensional spacetime and space-scale objects as projections to R3",2017,"PeerJ Computer Science","2017","7", e123,"","",,,10.7717/peerj-cs.123,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030171479&doi=10.7717%2fpeerj-cs.123&partnerID=40&md5=a3fd3f9d9402d6fc4f0c4ab17a42f554","3D Geoinformation, Delft University of Technology, Delft, Netherlands","Ohori, K.A., 3D Geoinformation, Delft University of Technology, Delft, Netherlands; Ledoux, H., 3D Geoinformation, Delft University of Technology, Delft, Netherlands; Stoter, J., 3D Geoinformation, Delft University of Technology, Delft, Netherlands","Objects of more than three dimensions can be used to model geographic phenomena that occur in space, time and scale. For instance, a single 4D object can be used to represent the changes in a 3D object's shape across time or all its optimal representations at various levels of detail. In this paper, we look at how such higher-dimensional spacetime and space-scale objects can be visualised as projections from R4 to R3. We present three projections that we believe are particularly intuitive for this purpose: (i) a simple 'long axis' projection that puts 3D objects side by side; (ii) the well-known orthographic and perspective projections; and (iii) a projection to a 3-sphere (S3) followed by a stereographic projection to R3, which results in an inwards-outwards fourth axis. Our focus is in using these projections from R4 to R3, but they are formulated from Rn to Rn-1 so as to be easily extensible and to incorporate other non-spatial characteristics. We present a prototype interactive visualiser that applies these projections from 4D to 3D in real-time using the programmable pipeline and compute shaders of the Metal graphics API. © 2017 Arroyo Ohori et al.","4D visualisation; Nd gis; Projections; Space-scale; Space-time",,"Ohori, K.A.; 3D Geoinformation, Delft University of TechnologyNetherlands; email: g.a.k.arroyoohori@tudelft.nl",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030171479
"Szénási S.","Solving the inverse heat conduction problem using NVLink capable Power architecture",2017,"PeerJ Computer Science","2017","11", e138,"","",,,10.7717/peerj-cs.138,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036525982&doi=10.7717%2fpeerj-cs.138&partnerID=40&md5=4954222f566c2e449cdcdb07406f8cc5","John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary","Szénási, S., John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary","The accurate knowledge of Heat Transfer Coefficients is essential for the design of precise heat transfer operations. The determination of these values requires Inverse Heat Transfer Calculations, which are usually based on heuristic optimisation techniques, like Genetic Algorithms or Particle Swarm Optimisation. The main bottleneck of these heuristics is the high computational demand of the cost function calculation, which is usually based on heat transfer simulations producing the thermal history of the workpiece at given locations. This Direct Heat Transfer Calculation is a well parallelisable process, making it feasible to implement an efficient GPU kernel for this purpose. This paper presents a novel step forward: based on the special requirements of the heuristics solving the inverse problem (executing hundreds of simulations in a parallel fashion at the end of each iteration), it is possible to gain a higher level of parallelism using multiple graphics accelerators. The results show that this implementation (running on 4 GPUs) is about 120 times faster than a traditional CPU implementation using 20 cores. The latest developments of the GPU-based High Power Computations area were also analysed, like the new NVLink connection between the host and the devices, which tries to solve the long time existing data transfer handicap of GPU programming. © 2017 Szénási.","CUDA; Dataparallel algorithm; GPU; Graphics accelerator; Heat transfer; Inverse heat conduction problem; NVLink; Optimisation; Parallelisation; Simulation",,"Szénási, S.; John von Neumann Faculty of Informatics, Óbuda UniversityHungary; email: szenasi.sandor@nik.uni-obuda.hu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85036525982
"Hochreiner C., Vögler M., Schulte S., Dustdar S.","Cost-efficient enactment of stream processing topologies",2017,"PeerJ Computer Science","2017","12", e141,"","",,,10.7717/peerj-cs.141,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040190578&doi=10.7717%2fpeerj-cs.141&partnerID=40&md5=84ddc0d9a3825a946c535049527e60ce","Distributed Systems Group, TU Wien, Vienna, Austria; TU Wien, Vienna, Austria","Hochreiner, C., Distributed Systems Group, TU Wien, Vienna, Austria; Vögler, M., TU Wien, Vienna, Austria; Schulte, S., Distributed Systems Group, TU Wien, Vienna, Austria; Dustdar, S., Distributed Systems Group, TU Wien, Vienna, Austria","The continuous increase of unbound streaming data poses several challenges to established data stream processing engines. One of the most important challenges is the cost-efficient enactment of stream processing topologies under changing data volume. These data volume pose different loads to stream processing systems whose resource provisioning needs to be continuously updated at runtime. First approaches already allow for resource provisioning on the level of virtual machines (VMs), but this only allows for coarse resource provisioning strategies. Based on current advances and benefits for containerized software systems, we have designed a cost-efficient resource provisioning approach and integrated it into the runtime of the Vienna ecosystem for elastic stream processing. Our resource provisioning approach aims to maximize the resource usage for VMs obtained from cloud providers. This strategy only releases processing capabilities at the end of the VMs minimal leasing duration instead of releasing them eagerly as soon as possible as it is the case for threshold-based approaches. This strategy allows us to improve the service level agreement compliance by up to 25% and a reduction for the operational cost of up to 36%. © 2017 Hochreiner et al.","Cloud computing; Data stream processing; Resource elasticity; Resource optimization",,"Hochreiner, C.; Distributed Systems Group, TU WienAustria; email: c.hochreiner@infosys.tuwien.ac.at",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85040190578
"Dröge J., Schönhuth A., McHardy A.C.","A probabilistic model to recover individual genomes from metagenomes",2017,"PeerJ Computer Science","2017","5", e117,"","",,,10.7717/peerj-cs.117,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030092167&doi=10.7717%2fpeerj-cs.117&partnerID=40&md5=adc8f3a487f4e2917e773f1f637c0fd2","Computational Biology of Infection Research, Helmholtz Centre for Infection Research, Braunschweig, Germany; Centrum Wiskunde and Informatica, Amsterdam, Netherlands","Dröge, J., Computational Biology of Infection Research, Helmholtz Centre for Infection Research, Braunschweig, Germany; Schönhuth, A., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; McHardy, A.C., Computational Biology of Infection Research, Helmholtz Centre for Infection Research, Braunschweig, Germany","Shotgun metagenomics of microbial communities reveal information about strains of relevance for applications in medicine, biotechnology and ecology. Recovering their genomes is a crucial but very challenging step due to the complexity of the underlying biological system and technical factors. Microbial communities are heterogeneous, with oftentimes hundreds of present genomes deriving from different species or strains, all at varying abundances and with different degrees of similarity to each other and reference data. We present a versatile probabilistic model for genome recovery and analysis, which aggregates three types of information that are commonly used for genome recovery from metagenomes. As potential applications we showcase metagenome contig classification, genome sample enrichment and genome bin comparisons. The open source implementation MGLEX is available via the Python Package Index and on GitHub and can be embedded into metagenome analysis workflows and programs. © 2017 Dröge et al.","Binning; Metagenomics",,"McHardy, A.C.; Computational Biology of Infection Research, Helmholtz Centre for Infection ResearchGermany; email: alice.mchardy@helmholtz-hzi.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030092167
"Bravo C.J.C., Berríos R.Á., Aide T.M.","Species-specific audio detection: A comparison of three template-based detection algorithms using random forests",2017,"PeerJ Computer Science","2017","4", e113,"","",,,10.7717/peerj-cs.113,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030170844&doi=10.7717%2fpeerj-cs.113&partnerID=40&md5=6a59f9a02e02c2f028753e0ac636e392","Department of Computer Science, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico; Sieve Analytics Inc., San Juan, Puerto Rico; Department of Biology, University of Puerto Rico-Río Piedras, San Juan, Puerto Rico","Bravo, C.J.C., Department of Computer Science, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, Sieve Analytics Inc., San Juan, Puerto Rico; Berríos, R.Á., Sieve Analytics Inc., San Juan, Puerto Rico; Aide, T.M., Sieve Analytics Inc., San Juan, Puerto Rico, Department of Biology, University of Puerto Rico-Río Piedras, San Juan, Puerto Rico","We developed a web-based cloud-hosted system that allow users to archive, listen, visualize, and annotate recordings. The system also provides tools to convert these annotations into datasets that can be used to train a computer to detect the presence or absence of a species. The algorithm used by the system was selected after comparing the accuracy and efficiency of three variants of a template-based detection. The algorithm computes a similarity vector by comparing a template of a species call with time increments across the spectrogram. Statistical features are extracted from this vector and used as input for a Random Forest classifier that predicts presence or absence of the species in the recording. The fastest algorithm variant had the highest average accuracy and specificity; therefore, it was implemented in the ARBIMON web-based system. © 2017 Corrada Bravo et al.","Acoustic monitoring; Animal vocalizations; Generic species algorithm; Machine learning; Random Forest classifier; Recording annotation; Recording visualization; Species prediction; Species-specific audio detection; Web-based cloud-hosted system",,"Bravo, C.J.C.; Department of Computer Science, University of Puerto Rico-Rio PiedrasPuerto Rico; email: carlos.corrada2@upr.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030170844
"Chamikara M.A.P., Galappaththi A., Yapa R.D., Nawarathna R.D., Kodituwakku S.R., Gunatilake J., Jayathilake A.A.C.A., Liyanage L.","Fuzzy based binary feature profiling for modus operandi analysis",2016,"PeerJ Computer Science","2016","6", e65,"","",,,10.7717/peerj-cs.65,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030178993&doi=10.7717%2fpeerj-cs.65&partnerID=40&md5=9ad4a533a630c4ef1de86bad40b2756f","Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka; Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; School of Computing, Engineering and Mathematics, University of Western Sydney, Western Sydney, NSW, Australia","Chamikara, M.A.P., Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka, Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; Galappaththi, A., Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka; Yapa, R.D., Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka, Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; Nawarathna, R.D., Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka, Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; Kodituwakku, S.R., Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka, Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; Gunatilake, J., Postgraduate Institute of Science (PGIS), University of Peradeniya, Peradeniya, Sri Lanka, Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; Jayathilake, A.A.C.A., Faculty of Science, University of Peradeniya, Peradeniya, Sri Lanka; Liyanage, L., School of Computing, Engineering and Mathematics, University of Western Sydney, Western Sydney, NSW, Australia","It is a well-known fact that some criminals follow perpetual methods of operations known as modi operandi. Modus operandi is a commonly used term to describe the habits in committing crimes. These modi operandi are used in relating criminals to crimes for which the suspects have not yet been recognized. This paper presents the design, implementation and evaluation of a new method to find connections between crimes and criminals using modi operandi. The method involves generating a feature matrix for a particular criminal based on the flow of events of his/her previous convictions. Then, based on the feature matrix, two representative modi operandi are generated: complete modus operandi and dynamic modus operandi. These two representative modi operandi are compared with the flow of events of the crime at hand, in order to generate two other outputs: completeness probability (CP) and deviation probability (DP). CP and DP are used as inputs to a fuzzy inference system to generate a score which is used in providing a measurement for the similarity between the suspect and the crime at hand. The method was evaluated using actual crime data and ten other open data sets. In addition, comparison with nine other classification algorithms showed that the proposed method performs competitively with other related methods proving that the performance of the new method is at an acceptable level. © 2016 Chamikara et al.","Association rule mining; Binary feature analysis; Classification; Fuzzy inference systems; Modus operandi analysis",,"Chamikara, M.A.P.; Postgraduate Institute of Science (PGIS), University of PeradeniyaSri Lanka; email: pathumchamikara@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030178993
"Cuadrado J., Vilaplana J., Mateo J., Solsona F., Solsona S., Rius J., Alves R., Camafort M., Torres G., Betriu A., Gutierrez J.M., Fernández E.","HBPF: A Home Blood Pressure Framework with SLA guarantees to follow up hypertensive patients",2016,"PeerJ Computer Science","2016","6", e69,"","",,,10.7717/peerj-cs.69,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030092474&doi=10.7717%2fpeerj-cs.69&partnerID=40&md5=5ea2e985f4e815c8e1045f9152d749cc","Hesoft Group, Lleida, Spain; Department of Computer Science, University of Lleida, Lleida, Spain; Department of Basic Medical Sciences, University of Lleida, Lleida, Spain; Department of Medicine, Clinic Hospital, Barcelona, Spain; Department of Medicine, Universitat de Barcelona, Barcelona, Spain; Hospital Universitari Santa Maria, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain; Unit for the Detection and Treatment of Atherothrombotic Diseases (UDETMA), Hospital Universitari Arnau de Vilanova de Lleida, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain; Nephrology Department, Hospital Universitari Arnau de Vilanova, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain","Cuadrado, J., Hesoft Group, Lleida, Spain; Vilaplana, J., Department of Computer Science, University of Lleida, Lleida, Spain; Mateo, J., Department of Computer Science, University of Lleida, Lleida, Spain; Solsona, F., Hesoft Group, Lleida, Spain, Department of Computer Science, University of Lleida, Lleida, Spain; Solsona, S., Hesoft Group, Lleida, Spain; Rius, J., Department of Computer Science, University of Lleida, Lleida, Spain; Alves, R., Department of Basic Medical Sciences, University of Lleida, Lleida, Spain; Camafort, M., Department of Medicine, Clinic Hospital, Barcelona, Spain, Department of Medicine, Universitat de Barcelona, Barcelona, Spain; Torres, G., Hospital Universitari Santa Maria, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain; Betriu, A., Unit for the Detection and Treatment of Atherothrombotic Diseases (UDETMA), Hospital Universitari Arnau de Vilanova de Lleida, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain; Gutierrez, J.M., Nephrology Department, Hospital Universitari Arnau de Vilanova, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain; Fernández, E., Nephrology Department, Hospital Universitari Arnau de Vilanova, Institut de Recerca Biomèdica de Lleida (IRBLleida), Catalonia, Spain","Hypertension or high blood pressure is a condition on the rise. Not only does it affect the elderly but is also increasingly spreading to younger sectors of the population. Treating it involves exhaustive monitoring of patients. A tool adapted to the particular requirements of hypertension can greatly facilitate monitoring and diagnosis. This paper presents HBPF, an efficient cloud-based Home Blood Pressure Framework. This allows hypertensive patients to communicate with their health-care centers, thus facilitating monitoring for both patients and clinicians. HBPF provides a complete, efficient, and cross-platform framework to follow up hypertensive patients with an SLA guarantee. Response time below one second for 80,000 requests and 28% increase in peak throughput going from one to three virtual machines were obtained. In addition, a mobile app (BP) for Android and iOS with a user-friendly interface is also provided to facilitate following up hypertensive patients. Among them, between 54% and 87% favorably evaluated the tool. BP can be downloaded for free from the website Hesoft Group repository (http://www.hesoftgroup.eu). © 2016 Cuadrado et al.","eHealth; Healtcare; Hypertension",,"Solsona, F.; Hesoft GroupSpain; email: francesc@diei.udl.cat",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030092474
"Kozlov K., Samsonov A.M., Samsonova M.","A software for parameter optimization with differential evolution entirely parallel method",2016,"PeerJ Computer Science","2016","8", e74,"","",,,10.7717/peerj-cs.74,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030182744&doi=10.7717%2fpeerj-cs.74&partnerID=40&md5=9cd5b89abedd7f6427186b9b3cce9737","Mathematical Biology and Bioinformatics Lab, IAMM, Peter the Great St. Petersburg Polytechnic University, St. Petersburg, Russian Federation; Ioffe Institute, Saint Petersburg, Russian Federation","Kozlov, K., Mathematical Biology and Bioinformatics Lab, IAMM, Peter the Great St. Petersburg Polytechnic University, St. Petersburg, Russian Federation; Samsonov, A.M., Mathematical Biology and Bioinformatics Lab, IAMM, Peter the Great St. Petersburg Polytechnic University, St. Petersburg, Russian Federation, Ioffe Institute, Saint Petersburg, Russian Federation; Samsonova, M., Mathematical Biology and Bioinformatics Lab, IAMM, Peter the Great St. Petersburg Polytechnic University, St. Petersburg, Russian Federation","Differential Evolution Entirely Parallel (DEEP) package is a software for finding unknown real and integer parameters in dynamical models of biological processes by minimizing one or even several objective functions that measure the deviation of model solution from data. Numerical solutions provided by the most efficient global optimization methods are often problem-specific and cannot be easily adapted to other tasks. In contrast, DEEP allows a user to describe both mathematical model and objective function in any programming language, such as R, Octave or Python and others. Being implemented in C, DEEP demonstrates as good performance as the top three methods from CEC-2014 (Competition on evolutionary computation) benchmark and was successfully applied to several biological problems. Availability. DEEP method is an open source and free software distributed under the terms of GPL licence version 3. The sources are available at http://deepmethod. sourceforge.net/ and binary packages for Fedora GNU/Linux are provided for RPM package manager at https://build.opensuse.org/project/repositories/home:mackoel: compbio. © 2016 Kozlov et al.","Bioinformatics; Differential Evolution; Mathematical modeling; Open source software; Parallelization; Parameter optimization",,"Kozlov, K.; Mathematical Biology and Bioinformatics Lab, IAMM, Peter the Great St. Petersburg Polytechnic UniversityRussian Federation; email: kozlov_kn@spbstu.ru",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030182744
"Vohl D., Barnes D.G., Fluke C.J., Poudel G., Georgiou-Karistianis N., Hassan A.H., Benovitski Y., Wong T.H., Kaluza O.L., Nguyen T.D., Bonnington C.P.","Large-scale comparative visualisation of sets of multidimensional data",2016,"PeerJ Computer Science","2016","10", e88,"","",,,10.7717/peerj-cs.88,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030111180&doi=10.7717%2fpeerj-cs.88&partnerID=40&md5=5ef5ed74ce3e335418c2cd7e38f23930","Centre for Astrophysics and Supercomputing, Swinburne University of Technology, Hawthorn, VIC, Australia; Monash eResearch Centre, Monash University, Clayton, VIC, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Psychological Sciences, Monash University, Clayton, VIC, Australia","Vohl, D., Centre for Astrophysics and Supercomputing, Swinburne University of Technology, Hawthorn, VIC, Australia; Barnes, D.G., Monash eResearch Centre, Monash University, Clayton, VIC, Australia, Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Fluke, C.J., Centre for Astrophysics and Supercomputing, Swinburne University of Technology, Hawthorn, VIC, Australia, Monash eResearch Centre, Monash University, Clayton, VIC, Australia; Poudel, G., School of Psychological Sciences, Monash University, Clayton, VIC, Australia; Georgiou-Karistianis, N., School of Psychological Sciences, Monash University, Clayton, VIC, Australia; Hassan, A.H., Centre for Astrophysics and Supercomputing, Swinburne University of Technology, Hawthorn, VIC, Australia; Benovitski, Y., Monash eResearch Centre, Monash University, Clayton, VIC, Australia; Wong, T.H., Monash eResearch Centre, Monash University, Clayton, VIC, Australia; Kaluza, O.L., Monash eResearch Centre, Monash University, Clayton, VIC, Australia; Nguyen, T.D., Monash eResearch Centre, Monash University, Clayton, VIC, Australia; Bonnington, C.P., Centre for Astrophysics and Supercomputing, Swinburne University of Technology, Hawthorn, VIC, Australia","We present encube-a qualitative, quantitative and comparative visualisation and analysis system, with application to high-resolution, immersive three-dimensional environments and desktop displays. encube extends previous comparative visualisation systems by considering: (1) the integration of comparative visualisation and analysis into a unified system; (2) the documentation of the discovery process; and (3) an approach that enables scientists to continue the research process once back at their desktop. Our solution enables tablets, smartphones or laptops to be used as interaction units for manipulating, organising, and querying data. We highlight the modularity of encube, allowing additional functionalities to be included as required. Additionally, our approach supports a high level of collaboration within the physical environment. We show how our implementation of encube operates in a large-scale, hybrid visualisation and supercomputing environment using the CAVE2 at Monash University, and on a local desktop, making it a versatile solution. We discuss how our approach can help accelerate the discovery rate in a variety of research scenarios. © 2016 Vohl et al.","CAVE2; Comparative visualisation; Immersive environments; Scientific data visualisation; Tiled-display",,"Vohl, D.; Centre for Astrophysics and Supercomputing, Swinburne University of TechnologyAustralia; email: dvohl@swin.edu.au",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030111180
"Metatla O., Bryan-Kinns N., Stockman T., Martin F.","Sonification of reference markers for auditory graphs: Effects on non-visual point estimation tasks",2016,"PeerJ Computer Science","2016","4", e51,"","",,,10.7717/peerj-cs.51,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030154406&doi=10.7717%2fpeerj-cs.51&partnerID=40&md5=458b8f46ec8b3224de82e062549d70d6","School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom","Metatla, O., School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom; Bryan-Kinns, N., School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom; Stockman, T., School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom; Martin, F., School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom","Research has suggested that adding contextual information such as reference markers to data sonification can improve interaction with auditory graphs. This paper presents results of an experiment that contributes to quantifying and analysing the extent of such benefits for an integral part of interacting with graphed data: point estimation tasks. We examine three pitch-based sonification mappings; pitch-only, one-reference, and multiple-references that we designed to provide information about distance from an origin. We assess the effects of these sonifications on users' performances when completing point estimation tasks in a between-subject experimental design against visual and speech control conditions. Results showed that the addition of reference tones increases users accuracy with a trade-off for task completion times, and that the multiple-references mapping is particularly effective when dealing with points that are positioned at the midrange of a given axis. © 2016 Metatla et al.","Auditory graphs; Non-visual interaction; Point estimation; Reference markers; Sonification",,"Metatla, O.; School of Electronic Engineering and Computer Science, Queen Mary University of LondonUnited Kingdom; email: o.metatla@qmul.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030154406
"Vega G., Corrada-Bravo C.J., Mitchell Aide T.","Audio segmentation using Flattened Local Trimmed Range for ecological acoustic space analysis",2016,"PeerJ Computer Science","2016","6", e70,"","",,,10.7717/peerj-cs.70,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030129706&doi=10.7717%2fpeerj-cs.70&partnerID=40&md5=4b6c2696a6848a741df11b3e1acfe6b2","Department of Mathematics, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, United States; Department of Computer Science, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, United States; Department of Biology, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, United States","Vega, G., Department of Mathematics, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, United States; Corrada-Bravo, C.J., Department of Computer Science, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, United States; Mitchell Aide, T., Department of Biology, University of Puerto Rico-Rio Piedras, San Juan, Puerto Rico, United States","The acoustic space in a given environment is filled with footprints arising from three processes: biophony, geophony and anthrophony. Bioacoustic research using passive acoustic sensors can result in thousands of recordings. An important component of processing these recordings is to automate signal detection. In this paper, we describe a new spectrogram-based approach for extracting individual audio events. Spectrogram-based audio event detection (AED) relies on separating the spectrogram into background (i.e., noise) and foreground (i.e., signal) classes using a threshold such as a global threshold, a per-band threshold, or one given by a classifier. These methods are either too sensitive to noise, designed for an individual species, or require prior training data. Our goal is to develop an algorithm that is not sensitive to noise, does not need any prior training data and works with any type of audio event. To do this, we propose: (1) a spectrogram filtering method, the Flattened Local Trimmed Range (FLTR) method, which models the spectrogram as a mixture of stationary and non-stationary energy processes and mitigates the effect of the stationary processes, and (2) an unsupervised algorithm that uses the filter to detect audio events. We measured the performance of the algorithm using a set of six thoroughly validated audio recordings and obtained a sensitivity of 94% and a positive predictive value of 89%. These sensitivity and positive predictive values are very high, given that the validated recordings are diverse and obtained from field conditions. The algorithm was then used to extract audio events in three datasets. Features of these audio events were plotted and showed the unique aspects of the three acoustic communities. © 2016 Vega et al.","Audio event detection; Bioacoustic; Flattened Local Trimmed Range",,"Vega, G.; Department of Mathematics, University of Puerto Rico-Rio PiedrasUnited States; email: aleph.omega@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030129706
"Shaw L.A., Buckley J., Corballis P.M., Lutteroth C., Wuensche B.C.","Competition and cooperation with virtual players in an exergame",2016,"PeerJ Computer Science","2016","10", e92,"","",,,10.7717/peerj-cs.92,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030183859&doi=10.7717%2fpeerj-cs.92&partnerID=40&md5=6c80d749f24e555f95fc690705702dc8","Department of Computer Science, University of Auckland, Auckland, New Zealand; School of Psychology, University of Auckland, Auckland, New Zealand; Department of Computer Science, University of Bath, Bath, United Kingdom","Shaw, L.A., Department of Computer Science, University of Auckland, Auckland, New Zealand; Buckley, J., School of Psychology, University of Auckland, Auckland, New Zealand; Corballis, P.M., School of Psychology, University of Auckland, Auckland, New Zealand; Lutteroth, C., Department of Computer Science, University of Auckland, Auckland, New Zealand, Department of Computer Science, University of Bath, Bath, United Kingdom; Wuensche, B.C., Department of Computer Science, University of Auckland, Auckland, New Zealand","Two cross-sectional studies investigated the effects of competition and cooperationwith virtual players on exercise performance in an immersive virtual reality (VR) cycle exergame. Study 1 examined the effects of: (1) self-competition whereby participants played the exergamewhile competing against a replay of their previous exergame session (Ghost condition), and (2) playing the exergame with a virtual trainer present (Trainer condition) on distance travelled and calories expended while cycling. Study 2 examined the effects of (1) competition with a virtual trainer system (Competitive condition) and (2) cooperation with a virtual trainer system (Cooperative condition). Post exergame enjoyment and motivation were also assessed. The results of Study 1 showed that the trainer system elicited a lesser distance travelled than when playing with a ghost or on one's own. These results also showed that competing against a ghost was more enjoyable than playing on one's own or with the virtual trainer. There was no significant difference between the participants' rated enjoyment and motivation and their distance travelled or calories burned. The findings of Study 2 showed that the competitive trainer elicited a greater distance travelled and caloric expenditure, and was rated as more motivating. As in Study 1, enjoyment and motivation were not correlated with distance travelled and calories burned. Conclusion: Taken together, these results demonstrate that a competitive experience in exergaming is an effective tool to elicit higher levels of exercise from the user, and can be achieved through virtual substitutes for another human player. © 2016 Shaw et al.","Competition; Cooperation; Exergame; Motivation; Virtual reality",,"Shaw, L.A.; Department of Computer Science, University of AucklandNew Zealand; email: lsha074@aucklanduni.ac.nz",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030183859
"Dolev S., Goldfeld J., Puzis R., Muni Venkateswarlu K.","Efficient online detection of temporal patterns",2016,"PeerJ Computer Science","2016","4", e53,"","",,,10.7717/peerj-cs.53,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030085480&doi=10.7717%2fpeerj-cs.53&partnerID=40&md5=adfcbe55b91205633975464f507fd01e","Department of Computer Science, Ben-Gurion University, Beer-Sheva, Israel; Telekom Innovation Laboratories, Ben-Gurion University, Beer Sheva, Israel; Department of Information Systems Engineering, Ben-Gurion University, Beer-Sheva, Israel","Dolev, S., Department of Computer Science, Ben-Gurion University, Beer-Sheva, Israel; Goldfeld, J., Department of Computer Science, Ben-Gurion University, Beer-Sheva, Israel; Puzis, R., Telekom Innovation Laboratories, Ben-Gurion University, Beer Sheva, Israel, Department of Information Systems Engineering, Ben-Gurion University, Beer-Sheva, Israel; Muni Venkateswarlu, K., Department of Computer Science, Ben-Gurion University, Beer-Sheva, Israel","Identifying a temporal pattern of events is a fundamental task of online (real- time) verification. We present efficient schemes for online monitoring of events for identifying desired/undesired patterns of events. The schemes use preprocessing to ensure that the number of comparisons during run-time is minimized. In particular, the first comparison following the time point when an execution sub-sequence cannot be further extended to satisfy the temporal requirements halts the process that monitors the sub-sequence. © 2016 Dolev et al.","Pattern matching; Time series; Verification",,"Puzis, R.; Telekom Innovation Laboratories, Ben-Gurion UniversityIsrael; email: puzis@bgu.ac.il",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030085480
"Kazemzadeh A., Gibson J., Georgiou P., Lee S., Narayanan S.","A Socratic epistemology for verbal emotional intelligence",2016,"PeerJ Computer Science","2016","1", e40,"","",,,10.7717/peerj-cs.40,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030104783&doi=10.7717%2fpeerj-cs.40&partnerID=40&md5=6eb316ffa3e44c6c63fd2139c8be5783","Signal Analysis and Interpretation Laboratory, University of Southern California, Los Angeles, CA, United States","Kazemzadeh, A., Signal Analysis and Interpretation Laboratory, University of Southern California, Los Angeles, CA, United States; Gibson, J., Signal Analysis and Interpretation Laboratory, University of Southern California, Los Angeles, CA, United States; Georgiou, P., Signal Analysis and Interpretation Laboratory, University of Southern California, Los Angeles, CA, United States; Lee, S., Signal Analysis and Interpretation Laboratory, University of Southern California, Los Angeles, CA, United States; Narayanan, S., Signal Analysis and Interpretation Laboratory, University of Southern California, Los Angeles, CA, United States","We describe and experimentally validate a question-asking framework for machinelearned linguistic knowledge about human emotions. Using the Socratic method as a theoretical inspiration, we develop an experimental method and computational model for computers to learn subjective information about emotions by playing emotion twenty questions (EMO20Q), a game of twenty questions limited to words denoting emotions. Using human-human EMO20Q data we bootstrap a sequential Bayesian model that drives a generalized pushdown automaton-based dialog agent that further learns from 300 human-computer dialogs collected on Amazon Mechanical Turk. The human-human EMO20Q dialogs show the capability of humans to use a large, rich, subjective vocabulary of emotion words. Training on successive batches of human-computer EMO20Q dialogs shows that the automated agent is able to learn fromsubsequent human-computer interactions. Our results show that the training procedure enables the agent to learn a large set of emotion words. The fully trained agent successfully completes EMO20Q at 67% of human performance and 30% better than the bootstrapped agent. Even when the agent fails to guess the human opponent's emotion word in the EMO20Q game, the agent's behavior of searching for knowledge makes it appear human-like, which enables the agent to maintain user engagement and learn new, out-of-vocabulary words. These results lead us to conclude that the question-asking methodology and its implementation as a sequential Bayes pushdown automaton are a successful model for the cognitive abilities involved in learning, retrieving, and using emotion words by an automated agent in a dialog setting. © 2016 Kazemzadeh et al.","Affective computing; Artificial intelligence; Cognitive science; Dialog agents; Dialog systems; Emotions; Games; Natural language processing; Question-asking; Sequential Bayesian",,"Kazemzadeh, A.; Signal Analysis and Interpretation Laboratory, University of Southern CaliforniaUnited States; email: abe.kazemzadeh@gmail.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030104783
"Bedo J., Goudey B., Wazny J., Zhou Z.","Information theoretic alignment free variant calling",2016,"PeerJ Computer Science","2016","7", e71,"","",,,10.7717/peerj-cs.71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030173151&doi=10.7717%2fpeerj-cs.71&partnerID=40&md5=270dd3b22e3938d34c2c7de898bf428d","IBM Research-Australia, Carlton, VIC, Australia; Department of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; Centre For Epidemiology and Biostatistics, The University of Melbourne, Parkville, VIC, Australia; School of Mathematics and Statistics, The University of Melbourne, Parkville, VIC, Australia","Bedo, J., IBM Research-Australia, Carlton, VIC, Australia, Department of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; Goudey, B., IBM Research-Australia, Carlton, VIC, Australia, Centre For Epidemiology and Biostatistics, The University of Melbourne, Parkville, VIC, Australia; Wazny, J., IBM Research-Australia, Carlton, VIC, Australia; Zhou, Z., IBM Research-Australia, Carlton, VIC, Australia, School of Mathematics and Statistics, The University of Melbourne, Parkville, VIC, Australia","While traditional methods for calling variants across whole genome sequence data rely on alignment to an appropriate reference sequence, alternative techniques are needed when a suitable reference does not exist. We present a novel alignment and assembly free variant calling method based on information theoretic principles designed to detect variants have strong statistical evidence for their ability to segregate samples in a given dataset. Our method uses the context surrounding a particular nucleotide to define variants. Given a set of reads, we model the probability of observing a given nucleotide conditioned on the surrounding prefix and suffixes of length k as a multinomial distribution. We then estimate which of these contexts are stable intra-sample and varying inter-sample using a statistic based on the Kullback-Leibler divergence. The utility of the variant calling method was evaluated through analysis of a pair of bacterial datasets and a mouse dataset. We found that our variants are highly informa- tive for supervised learning tasks with performance similar to standard reference based calls and another reference free method (DiscoSNP++). Comparisons against reference based calls showed our method was able to capture very similar population structure on the bacterial dataset. The algorithm's focus on discriminatory variants makes it suitable for many common analysis tasks for organisms that are too diverse to be mapped back to a single reference sequence. © 2016 Bedo et al.","Acteria; Alignment free; Assembly free; Feature extraction; Genome; Variant",,"Bedo, J.; IBM Research-AustraliaAustralia; email: cu@cua0.org",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030173151
"Farup I.","A computational framework for colour metrics and colour space transforms",2016,"PeerJ Computer Science","2016","3", e48,"","",,,10.7717/peerj-cs.48,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030165678&doi=10.7717%2fpeerj-cs.48&partnerID=40&md5=8154a0ec5ff9f5fe865c7291b09fbf8f","Faculty of Computer Science and Media Technology, Gjøvik University College, Norway","Farup, I., Faculty of Computer Science and Media Technology, Gjøvik University College, Norway","An object-oriented computational framework for the transformation of colour data and colour metric tensors is presented. The main idea of the design is to represent the transforms between spaces as compositions of objects from a class hierarchy providing the methods for both the transforms themselves and the corresponding Jacobian matrices. In this way, new colour spaces can be implemented on the fly by transforming from any existing colour space, and colour data in various formats as well as colour metric tensors and colour difference data can easily be transformed between the colour spaces. This reduces what normally requires several days of coding to a few lines of code without introducing a significant computational overhead. The framework is implemented in the Python programming language. © 2016 Farup.","Colour metrics; Colour space; Object-oriented; Python; Transform",,"Farup, I.; Faculty of Computer Science and Media Technology, Gjøvik University CollegeNorway; email: Ivar Farup, ivar.farup@ntnu.no",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85030165678
"Hills D.J.A., Grütter A.M., Hudson J.J.","An algorithm for discovering Lagrangians automatically fromdata",2015,"PeerJ Computer Science","2015","11", e31,"","",,,10.7717/peerj-cs.31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044198427&doi=10.7717%2fpeerj-cs.31&partnerID=40&md5=f171d5b4c05f1bd1c1d4fb2c7c86be91","Department of Physics, Imperial College of Science, Technology and Medicine, London, United Kingdom","Hills, D.J.A., Department of Physics, Imperial College of Science, Technology and Medicine, London, United Kingdom; Grütter, A.M., Department of Physics, Imperial College of Science, Technology and Medicine, London, United Kingdom; Hudson, J.J., Department of Physics, Imperial College of Science, Technology and Medicine, London, United Kingdom","An activity fundamental to science is building mathematical models. These models are used to both predict the results of future experiments and gain insight into the structure of the system under study. We present an algorithm that automates the model building process in a scientifically principled way. The algorithm can take observed trajectories froma wide variety of mechanical systems and, without any other prior knowledge or tuning of parameters, predict the future evolution of the system. It does this by applying the principle of least action and searching for the simplest Lagrangian that describes the system's behaviour. By generating this Lagrangian in a human interpretable form, it can also provide insight into the workings of the system. © 2015 Hills et al.","Discovery; Lagrangian; Least-action; Physics","Computer science; Computers; Physics; Building process; Discovery; Lagrangian; Least actions; Mechanical systems; Principle of least action; Prior knowledge; Tuning of parameters; Lagrange multipliers","Hudson, J.J.; Department of Physics, Imperial College of Science, Technology and MedicineUnited Kingdom; email: jony.hudson@imperial.ac.uk",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85044198427
"Roberson E.D.","Identification of high-efficiency 3'GG gRNA motifs in indexed FASTA files with ngg2",2015,"PeerJ Computer Science","2015","11", e33,"","",,,10.7717/peerj-cs.33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044223767&doi=10.7717%2fpeerj-cs.33&partnerID=40&md5=60a9e05f300a63cb6a44c0dd64889cc2","Departments of Medicine and Genetics, Division of Rheumatology, Washington University in Saint Louis, Saint Louis, MO, United States","Roberson, E.D., Departments of Medicine and Genetics, Division of Rheumatology, Washington University in Saint Louis, Saint Louis, MO, United States","CRISPR/Cas9 is emerging as one of the most-used methods of genome modification in organisms ranging frombacteria to human cells. However, the efficiency of editing varies tremendously site-to-site. A recent report identified a novel motif, called the 3'GG motif, which substantially increases the efficiency of editing at all sites tested in C. elegans. Furthermore, they highlighted that previously published gRNAs with high editing efficiency also had this motif. I designed a Python command-line tool, ngg2, to identify 3'GG gRNA sites from indexed FASTA files. As a proof-of-concept, I screened for these motifs in six model genomes: Saccharomyces cerevisiae, Caenorhabditis elegans, Drosophila melanogaster, Danio rerio, Mus musculus, and Homo sapiens. I also scanned the genomes of pig (Sus scrofa) and African elephant (Loxodonta africana) to demonstrate the utility in non-model organisms. I identified more than 60 million single match 3'GG motifs in these genomes. Greater than 61% of all protein coding genes in the reference genomes had at least one unique 3'GG gRNA site overlapping an exon. In particular, more than 96% of mouse and 93% of human protein coding genes have at least one unique, overlapping 3'GG gRNA. These identified sites can be used as a starting point in gRNA selection, and the ngg2 tool provides an important ability to identify 3'GG editing sites in any species with an available genome sequence. © 2015 Roberson.","3'GG; CRISPR/Cas9; gRNA; Motif discovery; Open-source; Python","Efficiency; High level languages; Proteins; Yeast; 3'GG; CRISPR/Cas9; gRNA; Motif discovery; Open sources; Python; Genes","Roberson, E.D.; Departments of Medicine and Genetics, Division of Rheumatology, Washington University in Saint LouisUnited States; email: eroberso@dom.wustl.edu",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85044223767
"Li Z., Gu W.","A redundancy-removing feature selection algorithm for nominal data",2015,"PeerJ Computer Science","2015","10", e24,"","",,,10.7717/peerj-cs.24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044133080&doi=10.7717%2fpeerj-cs.24&partnerID=40&md5=ac6ac06a83d37922c41dd5500fac2a2f","Key Laboratory of Advanced Process Control for Light Industry Ministry of Education, JiangSu, China; Engineering Research Center of Internet of Things Technology, Application Ministry of Education, JiangSu, China; Department of Computer Science, Engineering School of Internet of Things Engineering, Jiangnan University, JiangSu, China; Department of Computer Science, Georgia State University, Atlanta, GA, United States","Li, Z., Key Laboratory of Advanced Process Control for Light Industry Ministry of Education, JiangSu, China, Engineering Research Center of Internet of Things Technology, Application Ministry of Education, JiangSu, China, Department of Computer Science, Engineering School of Internet of Things Engineering, Jiangnan University, JiangSu, China, Department of Computer Science, Georgia State University, Atlanta, GA, United States; Gu, W., Engineering Research Center of Internet of Things Technology, Application Ministry of Education, JiangSu, China, Department of Computer Science, Engineering School of Internet of Things Engineering, Jiangnan University, JiangSu, China","No order correlation or similarity metric exists in nominal data, and there will always be more redundancy in a nominal dataset, which means that an efficient mutual information-based nominal-data feature selection method is relatively difficult to find. In this paper, a nominal-data feature selection method based on mutual information without data transformation, called the redundancy-removing more relevance less redundancy algorithm, is proposed. By forming several new information-related definitions and the corresponding computational methods, the proposed method can compute the information-related amount of nominal data directly. Furthermore, by creating a new evaluation function that considers both the relevance and the redundancy globally, the new feature selection method can evaluate the importance of each nominal-data feature. Although the presented feature selection method takes commonly used MIFS-like forms, it is capable of handling high-dimensional datasets without expensive computations.We perform extensive experimental comparisons of the proposed algorithm and other methods using three benchmarking nominal datasets with two different classifiers. The experimental results demonstrate the average advantage of the presented algorithm over the well-known NMIFS algorithm in terms of the feature selection and classification accuracy, which indicates that the proposed method has a promising performance. © 2015 Li and Gu.","Feature selection; Mutual information; Nominal data; Redundancy-removing","Classification (of information); Metadata; Redundancy; Experimental comparison; Feature selection algorithm; Feature selection and classification; Feature selection methods; High dimensional datasets; Mutual informations; Nominal datum; Redundancy algorithm; Feature extraction","Li, Z.; Key Laboratory of Advanced Process Control for Light Industry Ministry of EducationChina; email: zhli@jiangnan.edu.cn",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85044133080
"Marquart G., De Winter J.","Workload assessment for mental arithmetic tasks using the task-evoked pupillary response",2015,"PeerJ Computer Science","2015","8", e16,"","",,,10.7717/peerj-cs.16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029821329&doi=10.7717%2fpeerj-cs.16&partnerID=40&md5=660f0b6064664d74b300cfeb61e75576","Department of BioMechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of Technology, Delft, Netherlands","Marquart, G., Department of BioMechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of Technology, Delft, Netherlands; De Winter, J., Department of BioMechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of Technology, Delft, Netherlands","Pupillometry is a promising method for assessing mental workload and could be helpful in the optimization of systems that involve human-computer interaction. The present study focuses on replicating the studies by Ahern (1978) and Klingner (2010), which found that for three levels of difficulty of mental multiplications, the more difficult multiplications yielded larger dilations of the pupil. Using a remote eye tracker, our research expands upon these two previous studies by statistically testing for each 1.5 s interval of the calculation period (1) the mean absolute pupil diameter (MPD), (2) the mean pupil diameter change (MPDC) with respect to the pupil diameter during the pre-stimulus accommodation period, and (3) the mean pupil diameter change rate (MPDCR). An additional novelty of our research is that we compared the pupil diameter measures with a self-report measure of workload, the NASA Task Load Index (NASA-TLX), and with the mean blink rate (MBR). The results showed that the findings of Ahern and Klingner were replicated, and that the MPD and MPDC discriminated just as well between the lowest and highest difficulty levels as did the NASA-TLX. The MBR, on the other hand, did not differentiate between the difficulty levels. Moderate to strong correlations were found between the MPDC and the proportion of incorrect responses, indicating that the MPDC was higher for participants with a poorer performance. For practical applications, validity could be improved by combining pupillometry with other physiological techniques. © 2015 Marquart and deWinter.","Cognitive load; Human factors; Pupil diameter; Pupillometry","Eye tracking; Human engineering; NASA; Cognitive loads; Mental arithmetic; Mental workload; Pupil diameter; Pupillary response; Pupillometry; Strong correlation; Workload assessment; Human computer interaction","De Winter, J.; Department of BioMechanical Engineering, Faculty of Mechanical, Maritime and Materials Engineering, Delft University of TechnologyNetherlands; email: j.c.f.dewinter@tudelft.nl",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,,Scopus,2-s2.0-85029821329
"Nageldinger G.","A framework for cut-over management",2015,"PeerJ Computer Science","2015","11", e29,"","",,,10.7717/peerj-cs.29,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044209575&doi=10.7717%2fpeerj-cs.29&partnerID=40&md5=1443865a43c58067e2194a7d973cda42","Department of Testing and Release Management, Otto (GmbH and Co KG), Hamburg, Germany","Nageldinger, G., Department of Testing and Release Management, Otto (GmbH and Co KG), Hamburg, Germany","The purpose of this paper is to provide a governance structure for IT-related projects in order to assure a safeguarded and timely transition to a productive environment. This transitioning, which rarely exceeds a weekend, is colloquially called 'cut-over', 'rollout' or 'deployment'. The governance structure is defined in accordance with a set of project-specific deliverables for a cascade-type procedural project-management model, which is integrated within an Information Technology Infrastructure Library (ITIL)-orientated service organization. This integration is illustrated by the use of a semi-agile release model. Due to the release model selected, which is particularly characterized by its bundling of projects for a release-specific rollout (as it is referred to in the project documentation), a new definition and interpretation of deployment from a generic ITIL perspective is required. The facilitated release model requires a distinction between a project-specific cut-over and a release-specific rollout. This separation gives rise to two types of go-live scenarios: one for each participating project and one for each release. Additionally, an interplay between cut-over planning for a project and rollout planning for a release becomes apparent. Projects should already incorporate cut-over related deliverables in the initial planning phase. Even though consulting methodologies such as ASAP (Accelerated SAP), recommend scattered, project-specific deliverables useful for cut-over planning, this publication offers an integrated approach on how to prepare systematically for a project-specific cut-over with all required deliverables. The framework provided maps out ITIL's release and deployment process by means of IT projects; furthermore it allows IT projects to interface easily with the ITIL change-management process. © 2015 Nageldinger.","Application-specific cut-over; Deployment; Go-live; Go-live preparation; IT project management; IT service management; ITIL; Project-specific cut-over; Release; Release-specific rollout","Project management; Application specific; Deployment; Go-live; Go-live preparation; It project managements; IT service management; ITIL; Project-specific cut-over; Release; Release-specific rollout; Information management","Nageldinger, G.; Department of Testing and Release Management, Otto (GmbH and Co KG)Germany; email: guido.nageldinger@ottogroup.com",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85044209575
"Klimach H.G., Zudrop J., Roller S.P.","Generation of high order geometry representations in Octree meshes",2015,"PeerJ Computer Science","2015","11", e35,"","",,,10.7717/peerj-cs.35,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044197948&doi=10.7717%2fpeerj-cs.35&partnerID=40&md5=656c45a1ab4352b09508b3279ff22e74","Maschinenbau, University of Siegen, Siegen, Germany","Klimach, H.G., Maschinenbau, University of Siegen, Siegen, Germany; Zudrop, J., Maschinenbau, University of Siegen, Siegen, Germany; Roller, S.P., Maschinenbau, University of Siegen, Siegen, Germany","We propose a robust method to convert triangulated surface data into polynomial volume data. Such polynomial representations are required for high-order partial differential solvers, as low-order surface representations would diminish the accuracy of their solution. Our proposed method deploys a first order spatial bisection algorithm to find robustly an approximation of given geometries. The resulting voxelization is then used to generate Legendre polynomials of arbitrary degree. By embedding the locally defined polynomials in cubical elements of a coarser mesh, this method can reliably approximate even complex structures, like porous media. It thereby is possible to provide appropriate material definitions for high order discontinuous Galerkin schemes. We describe the method to construct the polynomial and how it fits into the overall mesh generation. Our discussion includes numerical properties of the method and we show some results from applying it to various geometries.We have implemented the described method in our mesh generator Seeder, which is publically available under a permissive open-source license. © 2015 Klimach et al.","Discontinuous galerkin; High-order; Mesh generation; Polynomial approximation","Approximation algorithms; Data handling; Galerkin methods; Mesh generation; Numerical methods; Polynomial approximation; Porous materials; Appropriate materials; Discontinuous galerkin; Discontinuous galerkin schemes; Geometry representation; High-order; Polynomial representations; Surface representation; Triangulated surfaces; Polynomials","Klimach, H.G.; Maschinenbau, University of SiegenGermany; email: harald.klimach@uni-siegen.de",,"PeerJ Inc.",23765992,,,,"English","PeerJ Comput. Sci.",Article,Open Access,Scopus,2-s2.0-85044197948
